export default {
  "v": {
    "01_basic.re": {
      "content": "// re2v $INPUT -o $OUTPUT -i\n\nfn lex(yyinput string) {\n    mut yycursor := 0\n    /*!re2c\n        re2c:yyfill:enable = 0;\n\n        [1-9][0-9]* { return }\n        *           { panic(\"error!\") }\n    */\n}\n\nfn main() {\n    lex(\"1234\\x00\")\n}\n",
      "extraCommandLineArguments": "-i"
    },
    "fill/01_fill.re": {
      "content": "// re2v $INPUT -o $OUTPUT\n\nimport os\nimport strings\n\nconst bufsize = 4096\n\nstruct State {\n    file     os.File\nmut:\n    yyinput  []u8\n    yycursor int\n    yymarker int\n    yylimit  int\n    token    int\n    eof      bool\n}\n\nfn fill(mut st &State) int {\n    if st.eof { return -1 } // unexpected EOF\n\n    // Error: lexeme too long. In real life can reallocate a larger buffer.\n    if st.token < 1 { return -2 }\n\n    // Shift buffer contents (discard everything up to the current token).\n    copy(mut &st.yyinput, st.yyinput[st.token..st.yylimit])\n    st.yycursor -= st.token\n    st.yymarker -= st.token\n    st.yylimit -= st.token\n    st.token = 0\n\n    // Fill free space at the end of buffer with new data from file.\n    pos := st.file.tell() or { 0 }\n    if n := st.file.read_bytes_into(u64(pos), mut st.yyinput[st.yylimit..bufsize]) {\n        st.yylimit += n\n    }\n    st.yyinput[st.yylimit] = 0 // append sentinel symbol\n\n    // If read less than expected, this is the end of input.\n    st.eof = st.yylimit < bufsize\n\n    return 0\n}\n\nfn lex(mut yyrecord &State) int {\n    mut count := 0\nloop:\n    yyrecord.token = yyrecord.yycursor\n    /*!re2c\n        re2c:api = record;\n        re2c:eof = 0;\n        re2c:YYFILL = \"fill(mut yyrecord) == 0\";\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        *    { return -1 }\n        $    { return count }\n        str  { count += 1; unsafe { goto loop } }\n        [ ]+ { unsafe { goto loop } }\n    */\n}\n\nfn main() {\n    fname := \"input\"\n    content := \"'qu\\0tes' 'are' 'fine: \\\\'' \";\n\n    // Prepare input file: a few times the size of the buffer, containing\n    // strings with zeroes and escaped quotes.\n    mut fw := os.create(fname)!\n    fw.write_string(strings.repeat_string(content, bufsize))!\n    fw.close()\n    count := 3 * bufsize // number of quoted strings written to file\n\n    // Prepare lexer state: all offsets are at the end of buffer.\n    mut fr := os.open(fname)!\n    mut st := &State{\n        file:     fr,\n        // Sentinel at `yylimit` offset is set to zero, which triggers YYFILL.\n        yyinput:  []u8{len: bufsize + 1},\n        yycursor: bufsize,\n        yymarker: bufsize,\n        yylimit:  bufsize,\n        token:    bufsize,\n        eof:      false,\n    }\n\n    // Run the lexer.\n    n := lex(mut st)\n    if n != count { panic(\"expected $count, got $n\") }\n\n    // Cleanup: remove input file.\n    fr.close()\n    os.rm(fname)!\n}\n",
      "extraCommandLineArguments": ""
    },
    "fill/02_fill.re": {
      "content": "// re2v $INPUT -o $OUTPUT\n\nimport os\nimport strings\n\n/*!max:re2c*/\nconst bufsize = 4096\n\nstruct State {\n    file     os.File\nmut:\n    yyinput  []u8\n    yycursor int\n    yylimit  int\n    token    int\n    eof      bool\n}\n\nfn fill(mut st &State, need int) int {\n    if st.eof { return -1 } // unexpected EOF\n\n    // Error: lexeme too long. In real life can reallocate a larger buffer.\n    if st.token < need { return -2 }\n\n    // Shift buffer contents (discard everything up to the current token).\n    copy(mut &st.yyinput, st.yyinput[st.token..st.yylimit])\n    st.yycursor -= st.token\n    st.yylimit -= st.token\n    st.token = 0\n\n    // Fill free space at the end of buffer with new data from file.\n    pos := st.file.tell() or { 0 }\n    if n := st.file.read_bytes_into(u64(pos), mut st.yyinput[st.yylimit..bufsize]) {\n        st.yylimit += n\n    }\n\n    // If read less than expected, this is the end of input.\n    if st.yylimit < bufsize {\n        st.eof = true\n        for i := 0; i < yymaxfill; i += 1 { st.yyinput[st.yylimit + i] = 0 }\n        st.yylimit += yymaxfill\n    }\n\n    return 0\n}\n\nfn lex(mut yyrecord &State) int {\n    mut count := 0\nloop:\n    yyrecord.token = yyrecord.yycursor\n    /*!re2c\n        re2c:api = record;\n        re2c:YYFILL = \"r := fill(mut yyrecord, @@); if r != 0 { return r }\";\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        [\\x00] {\n            // Check that it is the sentinel, not some unexpected null.\n            return if yyrecord.token == (yyrecord.yylimit - yymaxfill) { count } else { -1 }\n        }\n        str  { count += 1; unsafe { goto loop } }\n        [ ]+ { unsafe { goto loop } }\n        *    { return -1 }\n    */\n}\n\nfn main() {\n    fname := \"input\"\n    content := \"'qu\\0tes' 'are' 'fine: \\\\'' \";\n\n    // Prepare input file: a few times the size of the buffer, containing\n    // strings with zeroes and escaped quotes.\n    mut fw := os.create(fname)!\n    fw.write_string(strings.repeat_string(content, bufsize))!\n    fw.close()\n    count := 3 * bufsize // number of quoted strings written to file\n\n    // Prepare lexer state: all offsets are at the end of buffer.\n    // This immediately triggers YYFILL, as the YYLESSTHAN condition is true.\n    mut fr := os.open(fname)!\n    mut st := &State{\n        file:     fr,\n        yyinput:  []u8{len: bufsize + yymaxfill},\n        yycursor: bufsize,\n        yylimit:  bufsize,\n        token:    bufsize,\n        eof:      false,\n    }\n\n    // Run the lexer.\n    n := lex(mut st)\n    if n != count { panic(\"expected $count, got $n\") }\n\n    // Cleanup: remove input file.\n    fr.close()\n    os.rm(fname)!\n}\n",
      "extraCommandLineArguments": ""
    },
    "conditions/parse_u32_conditions.re": {
      "content": "// re2v $INPUT -o $OUTPUT -ci\n\n/*!conditions:re2c*/\n\nconst u32_lim = u64(1) << 32\n\nfn parse_u32(yyinput string) ?u32 {\n    mut yycursor, mut yymarker := 0, 0\n    mut n := u64(0)\n    mut yycond := YYCONDTYPE.yycinit\n\n    adddgt := fn (num u64, base u64, digit u8) u64 {\n        n := num * base + u64(digit)\n        return if n >= u32_lim { u32_lim } else { n }\n    }\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n\n        <*> * { return none }\n\n        <init> '0b' / [01]        :=> bin\n        <init> \"0\"                :=> oct\n        <init> \"\"   / [1-9]       :=> dec\n        <init> '0x' / [0-9a-fA-F] :=> hex\n\n        <bin, oct, dec, hex> \"\\x00\" { return if n < u32_lim { u32(n) } else { none } }\n\n        <bin> [01]  { n = adddgt(n, 2,  yyinput[yycursor-1] - 48); unsafe{ goto yyc_bin } }\n        <oct> [0-7] { n = adddgt(n, 8,  yyinput[yycursor-1] - 48); unsafe{ goto yyc_oct } }\n        <dec> [0-9] { n = adddgt(n, 10, yyinput[yycursor-1] - 48); unsafe{ goto yyc_dec } }\n        <hex> [0-9] { n = adddgt(n, 16, yyinput[yycursor-1] - 48); unsafe{ goto yyc_hex } }\n        <hex> [a-f] { n = adddgt(n, 16, yyinput[yycursor-1] - 87); unsafe{ goto yyc_hex } }\n        <hex> [A-F] { n = adddgt(n, 16, yyinput[yycursor-1] - 55); unsafe{ goto yyc_hex } }\n    */\n}\n\nfn main() {\n    test := fn (num ?u32, str string) {\n        if n := parse_u32(str) {\n            if m := num { if n != m { panic(\"wrong number\") } }\n        } else {\n            if _ := num { panic(\"expected none\") }\n        }\n    }\n    test(1234567890, \"1234567890\\0\")\n    test(13, \"0b1101\\0\")\n    test(0x7fe, \"0x007Fe\\0\")\n    test(0o644, \"0644\\0\")\n    test(none, \"9999999999\\0\")\n    test(none, \"123??\\0\")\n}\n",
      "extraCommandLineArguments": "-ci"
    },
    "conditions/parse_u32_blocks.re": {
      "content": "// re2v $INPUT -o $OUTPUT -i\n\nconst u32_lim = u64(1) << 32\n\nfn parse_u32(yyinput string) ?u32 {\n    mut yycursor, mut yymarker := 0, 0\n    mut n := u64(0)\n    mut yych := 0\n\n    adddgt := fn (num u64, base u64, digit u8) u64 {\n        n := num * base + u64(digit)\n        return if n >= u32_lim { u32_lim } else { n }\n    }\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:yych:emit = 0;\n\n        end = \"\\x00\";\n\n        '0b' / [01]        { unsafe{ goto bin } }\n        \"0\"                { unsafe{ goto oct } }\n        \"\"   / [1-9]       { unsafe{ goto dec } }\n        '0x' / [0-9a-fA-F] { unsafe{ goto hex } }\n        *                  { return none }\n    */\nbin:\n    /*!re2c\n        end   { unsafe{ goto end } }\n        [01]  { n = adddgt(n, 2, yyinput[yycursor-1] - 48); unsafe{ goto bin } }\n        *     { return none }\n    */\noct:\n    /*!re2c\n        end   { unsafe{ goto end } }\n        [0-7] { n = adddgt(n, 8, yyinput[yycursor-1] - 48); unsafe{ goto oct } }\n        *     { return none }\n    */\ndec:\n    /*!re2c\n        end   { unsafe{ goto end } }\n        [0-9] { n = adddgt(n, 10, yyinput[yycursor-1] - 48); unsafe{ goto dec } }\n        *     { return none }\n    */\nhex:\n    /*!re2c\n        end   { unsafe{ goto end } }\n        [0-9] { n = adddgt(n, 16, yyinput[yycursor-1] - 48); unsafe{ goto hex } }\n        [a-f] { n = adddgt(n, 16, yyinput[yycursor-1] - 87); unsafe{ goto hex } }\n        [A-F] { n = adddgt(n, 16, yyinput[yycursor-1] - 55); unsafe{ goto hex } }\n        *     { return none }\n    */\nend:\n    if n < u32_lim {\n        return u32(n)\n    }\n    return none\n}\n\nfn main() {\n    test := fn (num ?u32, str string) {\n        if n := parse_u32(str) {\n            if m := num { if n != m { panic(\"wrong number\") } }\n        } else {\n            if _ := num { panic(\"expected none\") }\n        }\n    }\n    test(1234567890, \"1234567890\\0\")\n    test(13, \"0b1101\\0\")\n    test(0x7fe, \"0x007Fe\\0\")\n    test(0o644, \"0644\\0\")\n    test(none, \"9999999999\\0\")\n    test(none, \"123??\\0\")\n}\n",
      "extraCommandLineArguments": "-i"
    },
    "state/push.re": {
      "content": "// re2v -f $INPUT -o $OUTPUT\n\nimport log\nimport os\n\n// Use a small buffer to cover the case when a lexeme doesn't fit.\n// In real world use a larger buffer.\nconst bufsize = 10\n\nstruct State {\nmut:\n    file     os.File\n    yyinput  []u8\n    yycursor int\n    yymarker int\n    yylimit  int\n    token    int\n    yystate  int\n}\n\nenum Status {\n    lex_end\n    lex_ready\n    lex_waiting\n    lex_bad_packet\n    lex_big_packet\n}\n\nfn fill(mut st &State) Status {\n    shift := st.token\n    used := st.yylimit - st.token\n    free := bufsize - used\n\n    // Error: no space. In real life can reallocate a larger buffer.\n    if free < 1 { return .lex_big_packet }\n\n    // Shift buffer contents (discard already processed data).\n    copy(mut &st.yyinput, st.yyinput[shift..shift+used])\n    st.yycursor -= shift\n    st.yymarker -= shift\n    st.yylimit -= shift\n    st.token -= shift\n\n    // Fill free space at the end of buffer with new data.\n    pos := st.file.tell() or { 0 }\n    if n := st.file.read_bytes_into(u64(pos), mut st.yyinput[st.yylimit..bufsize]) {\n        st.yylimit += n\n    }\n    st.yyinput[st.yylimit] = 0 // append sentinel symbol\n\n    return .lex_ready\n}\n\nfn lex(mut yyrecord &State, mut recv &int) Status {\n    mut yych := u8(0)\n    /*!getstate:re2c*/\nloop:\n    yyrecord.token = yyrecord.yycursor\n    /*!re2c\n        re2c:api = record;\n        re2c:eof = 0;\n        re2c:YYFILL = \"return .lex_waiting\";\n\n        packet = [a-z]+[;];\n\n        *      { return .lex_bad_packet }\n        $      { return .lex_end }\n        packet { recv += 1; unsafe{ goto loop } }\n    */\n}\n\nfn test(expect Status, packets []string) {\n    // Create a pipe (open the same file for reading and writing).\n    fname := \"pipe\"\n    mut fw := os.create(fname) or { panic(\"cannot create file\") }\n    mut fr := os.open(fname) or { panic(\"cannot open file\") }\n\n    // Initialize lexer state: `state` value is -1, all offsets are at the end\n    // of buffer.\n    mut st := &State{\n        file:     fr,\n        // Sentinel at `yylimit` offset is set to zero, which triggers YYFILL.\n        yyinput:  []u8{len: bufsize + 1},\n        yycursor: bufsize,\n        yymarker: bufsize,\n        yylimit:  bufsize,\n        token:    bufsize,\n        yystate:  -1,\n    }\n\n    // Main loop. The buffer contains incomplete data which appears packet by\n    // packet. When the lexer needs more input it saves its internal state and\n    // returns to the caller which should provide more input and resume lexing.\n    mut status := Status.lex_ready\n    mut send := 0\n    mut recv := 0\n    for {\n        status = lex(mut st, mut &recv)\n        if status == .lex_end {\n            break\n        } else if status == .lex_waiting {\n            if send < packets.len {\n                log.debug(\"sending packet $send\")\n                fw.write_string(packets[send]) or { panic(\"cannot write to file\") }\n                fw.flush()\n                send += 1\n            }\n            status = fill(mut st)\n            log.debug(\"filled buffer $st.yyinput, status $status\")\n            if status != .lex_ready {\n                break\n            }\n        } else if status == .lex_bad_packet {\n            break\n        }\n    }\n\n    // Check results.\n    if status != expect || (status == .lex_end && recv != send) {\n        panic(\"expected $expect with $send packet(s), got $status with $recv packet(s)\")\n    }\n\n    // Cleanup: remove input file.\n    fr.close()\n    fw.close()\n    os.rm(fname) or { panic(\"cannot remove file\") }\n}\n\nfn main() {\n    //log.set_level(.debug)\n\n    test(.lex_end, [])\n    test(.lex_end, [\"zero;\", \"one;\", \"two;\", \"three;\", \"four;\"])\n    test(.lex_bad_packet, [\"??;\"])\n    test(.lex_big_packet, [\"looooooooooooong;\"])\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/02_mtags.re": {
      "content": "// re2v $INPUT -o $OUTPUT\n\nimport arrays\n\nconst mtag_root = -1\nconst tag_none = -1\n\n// An m-tag tree is a way to store histories with an O(1) copy operation.\n// Histories naturally form a tree, as they have common start and fork at some\n// point. The tree is stored as an array of pairs (tag value, link to parent).\n// An m-tag is represented with a single link in the tree (array index).\nstruct MtagElem {\n    elem int\n    pred int\n}\ntype MtagTrie = []MtagElem\n\n// Append a single value to an m-tag history.\nfn add_mtag(mut trie &MtagTrie, mtag int, value int) int {\n    trie = arrays.concat(trie, MtagElem{value, mtag})\n    return trie.len - 1\n}\n\n// Recursively unwind tag histories and collect version components.\nfn unwind(trie MtagTrie, x int, y int, str string) []int {\n    // Reached the root of the m-tag tree, stop recursion.\n    if x == mtag_root && y == mtag_root {\n        return []\n    }\n\n    // Unwind history further.\n    mut result := unwind(trie, trie[x].pred, trie[y].pred, str)\n\n    // Get tag values. Tag histories must have equal length.\n    if x == mtag_root || y == mtag_root {\n        panic(\"tag histories have different length\")\n    }\n    ex := trie[x].elem\n    ey := trie[y].elem\n\n    if ex != tag_none && ey != tag_none {\n        // Both tags are valid string indices, extract component.\n        result = arrays.concat(result, s2n(str[ex..ey]))\n    } else if !(ex == tag_none && ey == tag_none) {\n        panic(\"both tags should be tag_none\")\n    }\n    return result\n}\n\nfn s2n(s string) int { // convert pre-parsed string to number\n    mut n := 0\n    for c in s { n = n * 10 + int(c - 48) }\n    return n\n}\n\nfn parse(yyinput string) ?[]int {\n    mut yycursor, mut yymarker := 0, 0\n    mut trie := []MtagElem{}\n\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = 'mut @@ := tag_none\\n'; */\n    /*!mvars:re2c format = \"mut @@ := mtag_root\\n\"; */\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = 'mut @@ := tag_none\\n'; */\n    /*!mtags:re2c format = \"mut @@ := mtag_root\\n\"; */\n\n    /*!re2c\n        re2c:tags = 1;\n        re2c:yyfill:enable = 0;\n        re2c:YYMTAGP = \"@@ = add_mtag(mut &trie, @@, yycursor)\";\n        re2c:YYMTAGN = \"@@ = add_mtag(mut &trie, @@, tag_none)\";\n\n        num = [0-9]+;\n\n        @t1 num @t2 (\".\" #t3 num #t4)* [\\x00] {\n            mut ver := []int{}\n            ver = arrays.concat(ver, s2n(yyinput[t1..t2]))\n            ver = arrays.append(ver, unwind(trie, t3, t4, yyinput))\n            return ver\n        }\n        * { return none }\n    */\n}\n\nfn main() {\n    test := fn (result ?[]int, expect ?[]int) {\n        if r := result {\n            if e := expect { if r != e { panic(\"expected $e, got $r\") } }\n        } else {\n            if _ := result { panic(\"expected none\") }\n        }\n    }\n    test(parse(\"1\\0\"), [1])\n    test(parse(\"1.2.3.4.5.6.7\\0\"), [1, 2, 3, 4, 5, 6, 7])\n    test(parse(\"1.\\0\"), none)\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/04_posix_captures.re": {
      "content": "// re2v $INPUT -o $OUTPUT\n\n// Maximum number of capturing groups among all rules.\n/*!maxnmatch:re2c*/\n\nstruct SemVer {\n    major int\n    minor int\n    patch int\n}\n\nfn s2n(s string) int { // convert pre-parsed string to number\n    mut n := 0\n    for c in s { n = n * 10 + int(c - 48) }\n    return n\n}\n\nfn parse(yyinput string) ?SemVer {\n    mut yycursor, mut yymarker := 0, 0\n\n    // Allocate memory for capturing parentheses (twice the number of groups).\n    mut yypmatch := []int{len: yymaxnmatch * 2}\n    mut yynmatch := 0\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = 'mut @@ := 0\\n'; */\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:posix-captures = 1;\n\n        num = [0-9]+;\n\n        (num) \".\" (num) (\".\" num)? [\\x00] {\n            // `yynmatch` is the number of capturing groups\n            if yynmatch != 4 { panic(\"expected 4 submatch groups\") }\n\n            // Even `yypmatch` values are for opening parentheses, odd values\n            // are for closing parentheses, the first group is the whole match.\n            return SemVer {\n                major: s2n(yyinput[yypmatch[2]..yypmatch[3]]),\n                minor: s2n(yyinput[yypmatch[4]..yypmatch[5]]),\n                patch: if yypmatch[6] == -1 {0} else {s2n(yyinput[yypmatch[6] + 1..yypmatch[7]])}\n            }\n        }\n        * { return none }\n    */\n}\n\nfn main() {\n    test := fn (result ?SemVer, expect ?SemVer) {\n        if r := result {\n            if e := expect { if r != e { panic(\"expected $e, got $r\") } }\n        } else {\n            if _ := result { panic(\"expected none\") }\n        }\n    }\n    test(parse(\"23.34\\0\"), SemVer{23, 34, 0})\n    test(parse(\"1.2.9999\\0\"), SemVer{1, 2, 9999})\n    test(parse(\"1.a\\0\"), none)\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags.re": {
      "content": "// re2v $INPUT -o $OUTPUT\n\nstruct SemVer {\n    major int\n    minor int\n    patch int\n}\n\nfn s2n(s string) int { // convert pre-parsed string to number\n    mut n := 0\n    for c in s { n = n * 10 + int(c - 48) }\n    return n\n}\n\nfn parse(yyinput string) ?SemVer {\n    mut yycursor, mut yymarker := 0, 0\n\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = 'mut @@ := 0\\n'; */\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = 'mut @@ := -1\\n'; */\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:tags = 1;\n\n        num = [0-9]+;\n\n        @t1 num @t2 \".\" @t3 num @t4 (\".\" @t5 num)? [\\x00] {\n            return SemVer{\n                major: s2n(yyinput[t1..t2]),\n                minor: s2n(yyinput[t3..t4]),\n                patch: if t5 == -1 { 0 } else { s2n(yyinput[t5..yycursor - 1]) }\n            }\n        }\n        * { return none }\n    */\n}\n\nfn main() {\n    test := fn (result ?SemVer, expect ?SemVer) {\n        if r := result {\n            if e := expect { if r != e { panic(\"expected $e, got $r\") } }\n        } else {\n            if _ := result { panic(\"expected none\") }\n        }\n    }\n    test(parse(\"23.34\\0\"), SemVer{23, 34, 0})\n    test(parse(\"1.2.9999\\0\"), SemVer{1, 2, 9999})\n    test(parse(\"1.a\\0\"), none)\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/03_captures.re": {
      "content": "// re2v $INPUT -o $OUTPUT\n\nstruct SemVer {\n    major int\n    minor int\n    patch int\n}\n\nfn s2n(s string) int { // convert pre-parsed string to number\n    mut n := 0\n    for c in s { n = n * 10 + int(c - 48) }\n    return n\n}\n\nfn parse(yyinput string) ?SemVer {\n    mut yycursor, mut yymarker := 0, 0\n\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = 'mut @@ := 0\\n'; */\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = 'mut @@ := 0\\n'; */\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:captvars = 1;\n\n        num = [0-9]+;\n\n        (num) \".\" (num) (\".\" num)? [\\x00] {\n            _ := yytl0; _ := yytr0 // some variables are unused\n            return SemVer {\n                major: s2n(yyinput[yytl1..yytr1]),\n                minor: s2n(yyinput[yytl2..yytr2]),\n                patch: if yytl3 == -1 {0} else {s2n(yyinput[yytl3 + 1..yytr3])}\n            }\n        }\n        * { return none }\n    */\n}\n\nfn main() {\n    test := fn (result ?SemVer, expect ?SemVer) {\n        if r := result {\n            if e := expect { if r != e { panic(\"expected $e, got $r\") } }\n        } else {\n            if _ := result { panic(\"expected none\") }\n        }\n    }\n    test(parse(\"23.34\\0\"), SemVer{23, 34, 0})\n    test(parse(\"1.2.9999\\0\"), SemVer{1, 2, 9999})\n    test(parse(\"1.a\\0\"), none)\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags_fill.re": {
      "content": "// re2v $INPUT -o $OUTPUT\n\nimport arrays\nimport os\nimport strings\n\nconst bufsize = 4096\nconst tag_none = -1\n\nstruct State {\n    file     os.File\nmut:\n    yyinput  []u8\n    yycursor int\n    yymarker int\n    yylimit  int\n    token    int\n    // Intermediate tag variables must be part of the lexer state passed to YYFILL.\n    // They don't correspond to tags and should be autogenerated by re2c.\n    /*!stags:re2c format = \"\\t@@ int\\n\"; */\n    eof      bool\n}\n\nstruct SemVer {\n    major int\n    minor int\n    patch int\n}\n\nfn s2n(s []u8) int { // convert pre-parsed string to number\n    mut n := 0\n    for c in s { n = n * 10 + int(c - 48) }\n    return n\n}\n\nfn fill(mut st &State) int {\n    if st.eof { return -1 } // unexpected EOF\n\n    // Error: lexeme too long. In real life can reallocate a larger buffer.\n    if st.token < 1 { return -2 }\n\n    // Shift buffer contents (discard everything up to the current token).\n    copy(mut &st.yyinput, st.yyinput[st.token..st.yylimit])\n    st.yycursor -= st.token\n    st.yymarker -= st.token\n    st.yylimit -= st.token\n    // Tag variables need to be shifted like other input positions. The check\n    // for -1 is only needed if some tags are nested inside of alternative or\n    // repetition, so that they can have -1 value.\n    /*!stags:re2c format = \"\\tif st.@@ != -1 { st.@@ -= st.token }\\n\"; */\n    st.token = 0\n\n    // Fill free space at the end of buffer with new data from file.\n    pos := st.file.tell() or { 0 }\n    if n := st.file.read_bytes_into(u64(pos), mut st.yyinput[st.yylimit..bufsize]) {\n        st.yylimit += n\n    }\n    st.yyinput[st.yylimit] = 0 // append sentinel symbol\n\n    // If read less than expected, this is the end of input.\n    st.eof = st.yylimit < bufsize\n\n    return 0\n}\n\nfn parse(mut st &State) ?[]SemVer {\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = \"mut @@ := tag_none\\n\"; */\n\n    mut vers := []SemVer{}\nloop:\n    st.token = st.yycursor\n    /*!re2c\n        re2c:api = record;\n        re2c:yyrecord = st;\n        re2c:YYFILL = \"fill(mut st) == 0\";\n        re2c:tags = 1;\n        re2c:eof = 0;\n\n        num = [0-9]+;\n\n        num @t1 \".\" @t2 num @t3 (\".\" @t4 num)? [\\n] {\n            ver := SemVer {\n                major: s2n(st.yyinput[st.token..t1]),\n                minor: s2n(st.yyinput[t2..t3]),\n                patch: if t4 == -1 { 0 } else { s2n(st.yyinput[t4..st.yycursor - 1]) }\n            }\n            vers = arrays.concat(vers, ver)\n            unsafe { goto loop }\n        }\n        $ { return vers }\n        * { return none }\n    */\n}\n\nfn main() {\n    fname := \"input\"\n    content := \"1.22.333\\n\";\n\n    // Prepare input file: a few times the size of the buffer, containing\n    // strings with zeroes and escaped quotes.\n    mut fw := os.create(fname)!\n    fw.write_string(strings.repeat_string(content, bufsize))!\n    fw.close()\n\n    // Prepare lexer state: all offsets are at the end of buffer.\n    mut fr := os.open(fname)!\n    mut st := &State{\n        file:      fr,\n        // Sentinel at `yylimit` offset is set to zero, which triggers YYFILL.\n        yyinput:  []u8{len: bufsize + 1},\n        yycursor: bufsize,\n        yymarker: bufsize,\n        yylimit:  bufsize,\n        token:    bufsize,\n        eof:      false,\n    }\n\n    // Run the lexer.\n    expect := []SemVer{len: bufsize, init: SemVer{1, 22, 333}}\n    result := parse(mut st) or { panic(\"parse failed\") }\n    if result != expect { panic(\"error\") }\n\n    // Cleanup: remove input file.\n    fr.close()\n    os.rm(fname)!\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/03_eof_rule.re": {
      "content": "// re2v $INPUT -o $OUTPUT\n\n// Expects a null-terminated string.\nfn lex(yyinput string) int {\n    mut yycursor, mut yymarker := 0, 0\n    yylimit := yyinput.len - 1 // yylimit points at the terminating null\n    mut count := 0\n\nloop: /*!re2c\n    re2c:eof = 0;\n    re2c:yyfill:enable = 0;\n\n    str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n    *    { return -1 }\n    $    { return count }\n    str  { count += 1; unsafe { goto loop } }\n    [ ]+ { unsafe { goto loop } }\n\n    */\n}\n\nfn main() {\n    assert lex(\"\\0\") == 0\n    assert lex(\"'qu\\0tes' 'are' 'fine: \\\\'' \\0\") == 3\n    assert lex(\"'unterminated\\\\'\\0\") == -1\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/04_fake_sentinel.re": {
      "content": "// re2v $INPUT -o $OUTPUT\n\n// Returns \"fake\" terminating null if cursor has reached limit.\nfn peek(str string, cur int) u8 {\n    return if cur >= str.len { u8(0) } /* fake null */ else { return str[cur] }\n}\n\n// Expects a string without terminating null.\nfn lex(str string) int {\n    mut cur := 0\n    mut count := 0\n\nloop: /*!re2c\n    re2c:api = generic;\n    re2c:yyfill:enable = 0;\n    re2c:YYPEEK = \"peek(str, cur)\";\n    re2c:YYSKIP = \"cur += 1\";\n\n    *      { return -1 }\n    [\\x00] { return count }\n    [a-z]+ { count += 1; unsafe { goto loop } }\n    [ ]+   { unsafe { goto loop } }\n\n    */\n}\n\nfn main() {\n    assert lex(\"\") == 0\n    assert lex(\"one two three\") == 3\n    assert lex(\"f0ur\") == -1\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/02_bounds_checking.re": {
      "content": "// re2v $INPUT -o $OUTPUT\n\n/*!max:re2c*/\n\n// Expects yymaxfill-padded string.\nfn lex(str string) int {\n    // Pad string with yymaxfill zeroes at the end.\n    mut yyinput := []u8{len: str.len + yymaxfill}\n    copy(mut &yyinput, str.bytes())\n\n    mut yycursor := 0\n    yylimit := yyinput.len\n    mut count := 0\n\nloop: /*!re2c\n    re2c:YYFILL = \"return -1\";\n\n    str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n    [\\x00] {\n        // Check that it is the sentinel, not some unexpected null.\n        if yycursor - 1 == str.len { return count } else { return -1 }\n    }\n    str  { count += 1; unsafe { goto loop } }\n    [ ]+ { unsafe { goto loop } }\n    *    { return -1 }\n\n    */\n}\n\nfn main() {\n    assert lex(\"\") == 0\n    assert lex(\"'qu\\0tes' 'are' 'fine: \\\\'' \") == 3\n    assert lex(\"'unterminated\\\\'\") == -1\n    assert lex(\"'unexpected \\00 null\\\\'\") == -1\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/01_sentinel.re": {
      "content": "// re2v $INPUT -o $OUTPUT\n\n// Expect a null-terminated string.\nfn lex(yyinput string) int {\n    mut yycursor := 0\n    mut count := 0\n\nloop: /*!re2c\n    re2c:yyfill:enable = 0;\n\n    *      { return -1 }\n    [\\x00] { return count }\n    [a-z]+ { count += 1; unsafe { goto loop } }\n    [ ]+   {  unsafe { goto loop } }\n    */\n}\n\nfn main() {\n    assert lex(\"\\0\") == 0\n    assert lex(\"one two three\\0\") == 3\n    assert lex(\"f0ur\\0\") == -1\n}\n",
      "extraCommandLineArguments": ""
    },
    "includes/include.re": {
      "content": "// re2v $INPUT -o $OUTPUT -i\n\n/*!include:re2c \"definitions.v\" */\n\nfn lex(yyinput string) Result {\n    mut yycursor, mut yymarker := 0, 0\n    /*!re2c\n        re2c:yyfill:enable = 0;\n\n        *      { return .fail }\n        number { return .ok }\n        !include \"extra_rules.re.inc\";\n    */\n}\n\nfn main() {\n    assert lex(\"123\\0\") == .ok\n    assert lex(\"123.4567\\0\") == .ok\n}\n",
      "extraCommandLineArguments": "-i"
    },
    "encodings/unicode_identifier.re": {
      "content": "// re2v $INPUT -o $OUTPUT --utf8 -si\n\n/*!include:re2c \"unicode_categories.re\" */\n\nfn lex(yyinput string) int {\n    mut yycursor, mut yymarker := 0, 0\n    /*!re2c\n        re2c:yyfill:enable = 0;\n\n        // Simplified \"Unicode Identifier and Pattern Syntax\"\n        // (see https://unicode.org/reports/tr31)\n        id_start    = L | Nl | [$_];\n        id_continue = id_start | Mn | Mc | Nd | Pc | [\\u200D\\u05F3];\n        identifier  = id_start id_continue*;\n\n        identifier { return 0 }\n        *          { return 1 }\n    */\n}\n\nfn main() {\n    if lex(\"_\u042b\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\\0\") != 0 {\n        panic(\"error\")\n    }\n}\n",
      "extraCommandLineArguments": "--utf8 -si"
    },
    "reuse/reuse.re": {
      "content": "// re2v $INPUT -o $OUTPUT --input-encoding utf8\n\n// This example supports multiple input encodings: UTF-8 and UTF-32.\n// Both lexers are generated from the same rules block, and the use\n// blocks add only encoding-specific configurations.\n/*!rules:re2c\n    re2c:yyfill:enable = 0;\n\n    \"\u2200x \u2203y\" { return 0 }\n    *       { return 1 }\n*/\n\nfn lex_utf8(yyinput []u8) int {\n    mut yycursor, mut yymarker := 0, 0\n    /*!use:re2c\n        re2c:encoding:utf8 = 1;\n        re2c:YYCTYPE = u8; // the default\n    */\n}\n\nfn lex_utf32(yyinput []u32) int {\n    mut yycursor, mut yymarker := 0, 0\n    /*!use:re2c\n        re2c:encoding:utf32 = 1;\n        re2c:YYCTYPE = u32;\n    */\n}\n\nfn main() {\n    s8 := [u8(0xe2), u8(0x88), u8(0x80), u8(0x78), u8(0x20), u8(0xe2), u8(0x88), u8(0x83), u8(0x79)]\n    s32 := [u32(0x2200), u32(0x78), u32(0x20), u32(0x2203), u32(0x79)]\n    assert lex_utf8(s8) == 0\n    assert lex_utf32(s32) == 0\n}\n",
      "extraCommandLineArguments": "--input-encoding utf8"
    },
    "reuse/usedir.re": {
      "content": "// re2v $INPUT -o $OUTPUT\n\n// This example shows how to combine reusable re2c blocks: two blocks\n// ('colors' and 'fish') are merged into one. The 'salmon' rule occurs\n// in both blocks; the 'fish' block takes priority because it is used\n// earlier. Default rule * occurs in all three blocks; the local (not\n// inherited) definition takes priority.\n\nenum What {\n    color\n    fish\n    dunno\n}\n\n/*!rules:re2c:colors\n    *                            { panic(\"eh!\") }\n    \"red\" | \"salmon\" | \"magenta\" { return .color }\n*/\n\n/*!rules:re2c:fish\n    *                            { panic(\"oh!\") }\n    \"haddock\" | \"salmon\" | \"eel\" { return .fish }\n*/\n\nfn lex(yyinput string) What {\n    mut yycursor, mut yymarker := 0, 0\n    /*!re2c\n        re2c:yyfill:enable = 0;\n\n        !use:fish;\n        !use:colors;\n        * { return .dunno }  // overrides inherited '*' rules\n    */\n}\n\nfn main() {\n    assert lex(\"salmon\") == .fish\n    assert lex(\"what?\") == .dunno\n}\n",
      "extraCommandLineArguments": ""
    },
    "headers/header.re": {
      "content": "// re2v $INPUT -o $OUTPUT -i --header lexer/state.v\nmodule main\n\nimport lexer // the package is generated by re2c\n\n/*!header:re2c:on*/\nmodule lexer\n\npub struct State {\npub mut:\n    yyinput string\n    yycursor int\n    /*!stags:re2c format=\"@@ int\\n\"; */\n}\n/*!header:re2c:off*/\n\nfn lex(mut yyrecord &lexer.State) int {\n    mut t := 0\n    /*!re2c\n        re2c:header = \"lexer/state.v\";\n        re2c:api = record;\n        re2c:yyfill:enable = 0;\n        re2c:tags = 1;\n\n        [a]* @t [b]* { return t }\n    */\n}\n\nfn main() {\n    mut st := &lexer.State{yyinput:\"ab\\0\",}\n    if lex(mut st) != 1 {\n        panic(\"error\")\n    }\n}\n",
      "extraCommandLineArguments": "-i --header lexer/state.v"
    }
  },
  "c": {
    "01_basic.re": {
      "content": "// re2c $INPUT -o $OUTPUT -i --case-ranges\n#include <assert.h>\n\nbool lex(const char *s) {\n    const char *YYCURSOR = s;\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:YYCTYPE = char;\n\n        [1-9][0-9]* { return true; }\n        *           { return false; }\n    */\n}\n\nint main() {\n    assert(lex(\"1234\"));\n    return 0;\n}\n",
      "extraCommandLineArguments": "-i --case-ranges"
    },
    "fill/01_fill.re": {
      "content": "// re2c $INPUT -o $OUTPUT\n#include <assert.h>\n#include <stdio.h>\n#include <string.h>\n\n#define BUFSIZE 4095\n\nstruct Input {\n    FILE *file;\n    char buffer[BUFSIZE + 1]; // +1 for sentinel\n    char *yylimit;\n    char *yycursor;\n    char *yymarker;\n    char *token;\n    bool eof;\n};\n\nstatic int fill(Input &in) {\n    if (in.eof) return 1;\n\n    const size_t shift = in.token - in.buffer;\n    const size_t used = in.yylimit - in.token;\n\n    // Error: lexeme too long. In real life could reallocate a larger buffer.\n    if (shift < 1) return 2;\n\n    // Shift buffer contents (discard everything up to the current token).\n    memmove(in.buffer, in.token, used);\n    in.yylimit -= shift;\n    in.yycursor -= shift;\n    in.yymarker -= shift;\n    in.token -= shift;\n\n    // Fill free space at the end of buffer with new data from file.\n    in.yylimit += fread(in.yylimit, 1, BUFSIZE - used, in.file);\n    in.yylimit[0] = 0;\n    in.eof = in.yylimit < in.buffer + BUFSIZE;\n    return 0;\n}\n\nstatic int lex(Input *yyrecord) {\n    int count = 0;\nloop:\n    yyrecord->token = yyrecord->yycursor;\n    /*!re2c\n        re2c:api = record;\n        re2c:YYCTYPE = char;\n        re2c:YYFILL = \"fill(*yyrecord) == 0\";\n        re2c:eof = 0;\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        *    { return -1; }\n        $    { return count; }\n        str  { ++count; goto loop; }\n        [ ]+ { goto loop; }\n    */\n}\n\nint main() {\n    const char *fname = \"input\";\n    const char content[] = \"'qu\\0tes' 'are' 'fine: \\\\'' \";\n\n    // Prepare input file: a few times the size of the buffer, containing\n    // strings with zeroes and escaped quotes.\n    FILE *f = fopen(fname, \"w\");\n    for (int i = 0; i < BUFSIZE; ++i) {\n        fwrite(content, 1, sizeof(content) - 1, f);\n    }\n    fclose(f);\n    int count = 3 * BUFSIZE; // number of quoted strings written to file\n\n    // Initialize lexer state: all pointers are at the end of buffer.\n    Input in;\n    in.file = fopen(fname, \"r\");\n    in.yycursor = in.yymarker = in.token = in.yylimit = in.buffer + BUFSIZE;\n    in.eof = 0;\n    // Sentinel (at YYLIMIT pointer) is set to zero, which triggers YYFILL.\n    in.yylimit[0] = 0;\n\n    // Run the lexer.\n    assert(lex(&in) == count);\n\n    // Cleanup: remove input file.\n    fclose(in.file);\n    remove(fname);\n    return 0;\n}\n",
      "extraCommandLineArguments": ""
    },
    "fill/02_fill.re": {
      "content": "// re2c $INPUT -o $OUTPUT\n#include <assert.h>\n#include <stdio.h>\n#include <string.h>\n\n/*!max:re2c*/\n#define BUFSIZE (4096 - YYMAXFILL)\n\nstruct Input {\n    FILE *file;\n    char buffer[BUFSIZE + YYMAXFILL];\n    char *yylimit;\n    char *yycursor;\n    char *token;\n    bool eof;\n};\n\nstatic int fill(Input &in, size_t need) {\n    if (in.eof) return 1;\n\n    const size_t shift = in.token - in.buffer;\n    const size_t used = in.yylimit - in.token;\n\n    // Error: lexeme too long. In real life could reallocate a larger buffer.\n    if (shift < need) return 2;\n\n    // Shift buffer contents (discard everything up to the current token).\n    memmove(in.buffer, in.token, used);\n    in.yylimit -= shift;\n    in.yycursor -= shift;\n    in.token -= shift;\n\n    // Fill free space at the end of buffer with new data from file.\n    in.yylimit += fread(in.yylimit, 1, BUFSIZE - used, in.file);\n\n    // If read less than expected, this is end of input => add zero padding\n    // so that the lexer can access characters at the end of buffer.\n    if (in.yylimit < in.buffer + BUFSIZE) {\n        in.eof = true;\n        memset(in.yylimit, 0, YYMAXFILL);\n        in.yylimit += YYMAXFILL;\n    }\n\n    return 0;\n}\n\nstatic int lex(Input *yyrecord) {\n    int count = 0;\nloop:\n    yyrecord->token = yyrecord->yycursor;\n    /*!re2c\n        re2c:api = record;\n        re2c:YYCTYPE = char;\n        re2c:YYFILL = \"if (fill(*yyrecord, @@) != 0) return -1;\";\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        [\\x00] {\n            // Check that it is the sentinel, not some unexpected null.\n            return yyrecord->token == yyrecord->yylimit - YYMAXFILL ? count : -1;\n        }\n        str  { ++count; goto loop; }\n        [ ]+ { goto loop; }\n        *    { return -1; }\n    */\n}\n\nint main() {\n    const char *fname = \"input\";\n    const char content[] = \"'qu\\0tes' 'are' 'fine: \\\\'' \";\n\n    // Prepare input file: a few times the size of the buffer, containing\n    // strings with zeroes and escaped quotes.\n    FILE *f = fopen(fname, \"w\");\n    for (int i = 0; i < BUFSIZE; ++i) {\n        fwrite(content, 1, sizeof(content) - 1, f);\n    }\n    fclose(f);\n    int count = 3 * BUFSIZE; // number of quoted strings written to file\n\n    // Initialize lexer state: all pointers are at the end of buffer.\n    // This immediately triggers YYFILL, as the check `in.yycursor < in.yylimit` fails.\n    Input in;\n    in.file = fopen(fname, \"r\");\n    in.yycursor = in.token = in.yylimit = in.buffer + BUFSIZE;\n    in.eof = 0;\n\n    // Run the lexer.\n    assert(lex(&in) == count);\n\n    // Cleanup: remove input file.\n    fclose(in.file);\n    remove(fname);\n    return 0;\n}\n",
      "extraCommandLineArguments": ""
    },
    "conditions/parse_u32_conditions.re": {
      "content": "// re2c $INPUT -o $OUTPUT -ci\n#include <stdint.h>\n#include <limits.h>\n#include <assert.h>\n\nstatic const uint64_t ERROR = UINT64_MAX;\n/*!conditions:re2c*/\n\ntemplate<int BASE> static void add(uint64_t &u, char d) {\n    u = u * BASE + d;\n    if (u > UINT32_MAX) u = ERROR;\n}\n\nstatic uint64_t parse_u32(const char *s) {\n    const char *YYCURSOR = s, *YYMARKER;\n    int c = yycinit;\n    uint64_t u = 0;\n\n    /*!re2c\n        re2c:api:style = free-form;\n        re2c:YYCTYPE = char;\n        re2c:YYGETCOND = \"c\";\n        re2c:YYSETCOND = \"c = @@;\";\n        re2c:yyfill:enable = 0;\n\n        <*> * { return ERROR; }\n\n        <init> '0b' / [01]        :=> bin\n        <init> \"0\"                :=> oct\n        <init> \"\" / [1-9]         :=> dec\n        <init> '0x' / [0-9a-fA-F] :=> hex\n\n        <bin, oct, dec, hex> \"\\x00\" { return u; }\n\n        <bin> [01]  { add<2>(u,  YYCURSOR[-1] - '0');      goto yyc_bin; }\n        <oct> [0-7] { add<8>(u,  YYCURSOR[-1] - '0');      goto yyc_oct; }\n        <dec> [0-9] { add<10>(u, YYCURSOR[-1] - '0');      goto yyc_dec; }\n        <hex> [0-9] { add<16>(u, YYCURSOR[-1] - '0');      goto yyc_hex; }\n        <hex> [a-f] { add<16>(u, YYCURSOR[-1] - 'a' + 10); goto yyc_hex; }\n        <hex> [A-F] { add<16>(u, YYCURSOR[-1] - 'A' + 10); goto yyc_hex; }\n    */\n}\n\nint main() {\n    assert(parse_u32(\"\") == ERROR);\n    assert(parse_u32(\"1234567890\") == 1234567890);\n    assert(parse_u32(\"0b1101\") == 13);\n    assert(parse_u32(\"0x7Fe\") == 2046);\n    assert(parse_u32(\"0644\") == 420);\n    assert(parse_u32(\"9999999999\") == ERROR);\n    return 0;\n}\n",
      "extraCommandLineArguments": "-ci"
    },
    "conditions/parse_u32_blocks.re": {
      "content": "// re2c $INPUT -o $OUTPUT -i\n#include <stdint.h>\n#include <limits.h>\n#include <assert.h>\n\nstatic const uint64_t ERROR = UINT64_MAX;\n\ntemplate<int BASE> static void add(uint64_t &u, char d) {\n    u = u * BASE + d;\n    if (u > UINT32_MAX) u = ERROR;\n}\n\nstatic uint64_t parse_u32(const char *s) {\n    const char *YYCURSOR = s, *YYMARKER;\n    uint64_t u = 0;\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:YYCTYPE = char;\n\n        end = \"\\x00\";\n\n        '0b' / [01]        { goto bin; }\n        \"0\"                { goto oct; }\n        \"\" / [1-9]         { goto dec; }\n        '0x' / [0-9a-fA-F] { goto hex; }\n        *                  { return ERROR; }\n    */\nbin:\n    /*!re2c\n        end   { return u; }\n        [01]  { add<2>(u, YYCURSOR[-1] - '0'); goto bin; }\n        *     { return ERROR; }\n    */\noct:\n    /*!re2c\n        end   { return u; }\n        [0-7] { add<8>(u, YYCURSOR[-1] - '0'); goto oct; }\n        *     { return ERROR; }\n    */\ndec:\n    /*!re2c\n        end   { return u; }\n        [0-9] { add<10>(u, YYCURSOR[-1] - '0'); goto dec; }\n        *     { return ERROR; }\n    */\nhex:\n    /*!re2c\n        end   { return u; }\n        [0-9] { add<16>(u, YYCURSOR[-1] - '0');      goto hex; }\n        [a-f] { add<16>(u, YYCURSOR[-1] - 'a' + 10); goto hex; }\n        [A-F] { add<16>(u, YYCURSOR[-1] - 'A' + 10); goto hex; }\n        *     { return ERROR; }\n    */\n}\n\nint main() {\n    assert(parse_u32(\"\") == ERROR);\n    assert(parse_u32(\"1234567890\") == 1234567890);\n    assert(parse_u32(\"0b1101\") == 13);\n    assert(parse_u32(\"0x7Fe\") == 2046);\n    assert(parse_u32(\"0644\") == 420);\n    assert(parse_u32(\"9999999999\") == ERROR);\n    return 0;\n}\n",
      "extraCommandLineArguments": "-i"
    },
    "state/push.re": {
      "content": "// re2c $INPUT -o $OUTPUT -f\n#include <assert.h>\n#include <stdio.h>\n#include <string.h>\n\n#define DEBUG 0\n#define LOG(...) if (DEBUG) fprintf(stderr, __VA_ARGS__);\n\n// Use a small buffer to cover the case when a lexeme doesn't fit.\n// In real world use a larger buffer.\n#define BUFSIZE 10\n\nstruct State {\n    FILE *file;\n    char buf[BUFSIZE + 1], *lim, *cur, *mar, *tok;\n    int state;\n};\n\ntypedef enum {END, READY, WAITING, BAD_PACKET, BIG_PACKET} Status;\n\nstatic Status fill(State &st) {\n    const size_t shift = st.tok - st.buf;\n    const size_t used = st.lim - st.tok;\n    const size_t free = BUFSIZE - used;\n\n    // Error: no space. In real life can reallocate a larger buffer.\n    if (free < 1) return BIG_PACKET;\n\n    // Shift buffer contents (discard already processed data).\n    memmove(st.buf, st.tok, used);\n    st.lim -= shift;\n    st.cur -= shift;\n    st.mar -= shift;\n    st.tok -= shift;\n\n    // Fill free space at the end of buffer with new data.\n    const size_t read = fread(st.lim, 1, free, st.file);\n    st.lim += read;\n    st.lim[0] = 0; // append sentinel symbol\n\n    return READY;\n}\n\nstatic Status lex(State &st, unsigned int *recv) {\n    char yych;\n    /*!getstate:re2c*/\n\n    for (;;) {\n        st.tok = st.cur;\n    /*!re2c\n        re2c:api:style = free-form;\n        re2c:YYCTYPE = \"char\";\n        re2c:YYCURSOR = \"st.cur\";\n        re2c:YYMARKER = \"st.mar\";\n        re2c:YYLIMIT = \"st.lim\";\n        re2c:YYGETSTATE = \"st.state\";\n        re2c:YYSETSTATE = \"st.state = @@;\";\n        re2c:YYFILL = \"return WAITING;\";\n        re2c:eof = 0;\n\n        packet = [a-z]+[;];\n\n        *      { return BAD_PACKET; }\n        $      { return END; }\n        packet { *recv = *recv + 1; continue; }\n    */\n    }\n}\n\nvoid test(const char **packets, Status expect) {\n    // Create a pipe (open the same file for reading and writing).\n    const char *fname = \"pipe\";\n    FILE *fw = fopen(fname, \"w\");\n    FILE *fr = fopen(fname, \"r\");\n    setvbuf(fw, NULL, _IONBF, 0);\n    setvbuf(fr, NULL, _IONBF, 0);\n\n    // Initialize lexer state: `state` value is -1, all pointers are at the end\n    // of buffer.\n    State st;\n    st.file = fr;\n    st.cur = st.mar = st.tok = st.lim = st.buf + BUFSIZE;\n    // Sentinel (at YYLIMIT pointer) is set to zero, which triggers YYFILL.\n    st.lim[0] = 0;\n    st.state = -1;\n\n    // Main loop. The buffer contains incomplete data which appears packet by\n    // packet. When the lexer needs more input it saves its internal state and\n    // returns to the caller which should provide more input and resume lexing.\n    Status status;\n    unsigned int send = 0, recv = 0;\n    for (;;) {\n        status = lex(st, &recv);\n        if (status == END) {\n            LOG(\"done: got %u packets\\n\", recv);\n            break;\n        } else if (status == WAITING) {\n            LOG(\"waiting...\\n\");\n            if (*packets) {\n                LOG(\"sent packet %u\\n\", send);\n                fprintf(fw, \"%s\", *packets++);\n                ++send;\n            }\n            status = fill(st);\n            LOG(\"queue: '%s'\\n\", st.buf);\n            if (status == BIG_PACKET) {\n                LOG(\"error: packet too big\\n\");\n                break;\n            }\n            assert(status == READY);\n        } else {\n            assert(status == BAD_PACKET);\n            LOG(\"error: ill-formed packet\\n\");\n            break;\n        }\n    }\n\n    // Check results.\n    assert(status == expect);\n    if (status == END) assert(recv == send);\n\n    // Cleanup: remove input file.\n    fclose(fw);\n    fclose(fr);\n    remove(fname);\n}\n\nint main() {\n    const char *packets1[] = {0};\n    const char *packets2[] = {\"zero;\", \"one;\", \"two;\", \"three;\", \"four;\", 0};\n    const char *packets3[] = {\"zer0;\", 0};\n    const char *packets4[] = {\"looooooooooong;\", 0};\n\n    test(packets1, END);\n    test(packets2, END);\n    test(packets3, BAD_PACKET);\n    test(packets4, BIG_PACKET);\n\n    return 0;\n}\n",
      "extraCommandLineArguments": "-f"
    },
    "submatch/http_rfc7230.re": {
      "content": "// re2c $INPUT -o $OUTPUT -i\n#include <assert.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n\n/*!re2c re2c:flags:tags = 1; */\n\ntypedef struct mtag_t {\n    struct mtag_t *pred;\n    long dist;\n} mtag_t;\n\ntypedef struct mtagpool_t {\n    mtag_t *head;\n    mtag_t *next;\n    mtag_t *last;\n} mtagpool_t;\n\ntypedef struct {\n    FILE *file;\n    char *buf;\n    char *lim;\n    char *cur;\n    char *mar;\n    char *tok;\n    /*!stags:re2c format = \"char *@@;\\n\"; */\n    /*!mtags:re2c format = \"mtag_t *@@;\\n\"; */\n    mtagpool_t mtp;\n    int eof;\n} input_t;\n\nstatic void mtagpool_clear(mtagpool_t *mtp, input_t *in)\n{\n    mtp->next = mtp->head;\n    /*!mtags:re2c format = \"in->@@ = 0;\\n\"; */\n}\n\nstatic void mtagpool_init(mtagpool_t *mtp)\n{\n    static const unsigned size = 1024 * 1024;\n    mtp->head = (mtag_t*)malloc(size * sizeof(mtag_t));\n    mtp->next = mtp->head;\n    mtp->last = mtp->head + size;\n}\n\nstatic void mtagpool_free(mtagpool_t *mtp)\n{\n    free(mtp->head);\n    mtp->head = mtp->next = mtp->last = NULL;\n}\n\nstatic mtag_t *mtagpool_next(mtagpool_t *mtp)\n{\n    unsigned size;\n    mtag_t *head;\n\n    if (mtp->next < mtp->last) return mtp->next++;\n\n    size = mtp->last - mtp->head;\n    head = (mtag_t*)malloc(2 * size * sizeof(mtag_t));\n    memcpy(head, mtp->head, size * sizeof(mtag_t));\n    free(mtp->head);\n    mtp->head = head;\n    mtp->next = head + size;\n    mtp->last = head + size * 2;\n    return mtp->next++;\n}\n\nstatic void mtag(mtag_t **pmt, const char *b, const char *t, mtagpool_t *mtp)\n{\n    mtag_t *mt = mtagpool_next(mtp);\n    mt->pred = *pmt;\n    mt->dist = t - b;\n    *pmt = mt;\n}\n\n/*!max:re2c*/\nstatic const size_t SIZE = 4096;\n\nstatic void init_input(input_t *in, const char *fname)\n{\n    in->file = fopen(fname, \"r\");\n    in->buf = (char*) malloc(SIZE + YYMAXFILL);\n    in->lim = in->buf + SIZE;\n    in->cur = in->lim;\n    in->mar = in->lim;\n    in->tok = in->lim;\n    /*!stags:re2c format = \"in->@@ = 0;\\n\"; */\n    /*!mtags:re2c format = \"in->@@ = 0;\\n\"; */\n    mtagpool_init(&in->mtp);\n    in->eof = 0;\n}\n\nstatic void free_input(input_t *in)\n{\n    fclose(in->file);\n    free(in->buf);\n    mtagpool_free(&in->mtp);\n}\n\nstatic int fill(input_t *in, size_t need)\n{\n    size_t free;\n    if (in->eof) return 1;\n\n    free = in->tok - in->buf;\n    if (free < need) return 2;\n\n    memmove(in->buf, in->tok, in->lim - in->tok);\n    in->lim -= free;\n    in->cur -= free;\n    in->mar -= free;\n    in->tok -= free;\n    /*!stags:re2c format = \"if (in->@@) in->@@ -= free;\\n\"; */\n    in->lim += fread(in->lim, 1, free, in->file);\n    if (in->lim < in->buf + SIZE) {\n        in->eof = 1;\n        memset(in->lim, 0, YYMAXFILL);\n        in->lim += YYMAXFILL;\n    }\n    return 0;\n}\n\nstatic void print_headers(const char *tok,\n    const mtag_t *h1, const mtag_t *h2,\n    const mtag_t *h3, const mtag_t *h4,\n    const mtag_t *h5)\n{\n    if (!h1) return;\n    print_headers(tok, h1->pred, h2->pred, h3->pred, h4->pred, h5->pred);\n    fprintf(stderr, \"%.*s%.*s%.*s%.*s\\n\",\n        (int)(h2->dist - h1->dist), tok + h1->dist,\n        (int)(h3->dist - h2->dist), tok + h2->dist,\n        (int)(h4->dist - h3->dist), tok + h3->dist,\n        (int)(h5->dist - h4->dist), tok + h4->dist);\n}\n\n#define YYCTYPE        char\n#define YYCURSOR       in->cur\n#define YYMARKER       in->mar\n#define YYLIMIT        in->lim\n#define YYMTAGP(mt)    mtag(&mt, in->tok, in->cur, &in->mtp)\n#define YYMTAGN(mt)    mtag(&mt, in->tok, NULL, &in->mtp)\n#define YYFILL(n)      if (fill(in, n) != 0) return 2;\n\nstatic int lex(input_t *in, long *count)\n{\n    /*!svars:re2c format = 'const char *@@ = NULL;\\n'; */\n    /*!mvars:re2c format = 'mtag_t *@@;\\n'; */\n    long c = 0;\nloop:\n    in->tok = in->cur;\n/*!re2c\n    re2c:tags:expression = \"in->@@\";\n\n    end = \"\\x00\";\n    eol = \"\\n\";\n\n    crlf        = eol;\n    sp          = \" \";\n    htab        = \"\\t\";\n    ows         = (sp | htab)*;\n    digit       = [0-9];\n    alpha       = [a-zA-Z];\n    hexdigit    = [0-9a-fA-F];\n    unreserved  = alpha | digit | [-._~];\n    pct_encoded = \"%\" hexdigit{2};\n    sub_delims  = [!$&'()*+,;=];\n    pchar       = unreserved | pct_encoded | sub_delims | [:@];\n    vchar       = [\\x1f-\\x7e];\n    tchar       = [-!#$%&'*+.^_`|~] | digit | alpha;\n\n    obs_fold       = crlf (sp | htab)+;\n    obs_text       = [\\x80-\\xff];\n    field_name     = tchar+;\n    field_vchar    = vchar | obs_text;\n    field_content  = field_vchar ((sp | htab)+ field_vchar)?;\n    field_value    = (field_content | obs_fold)*;\n    header_field   = #h1 field_name #h2 \":\" ows #h3 field_value #h4 ows #h5;\n    scheme         = alpha (alpha | digit | [-+.])*;\n    userinfo       = (unreserved | pct_encoded | sub_delims | \":\")*;\n    dec_octet\n        = digit\n        | [\\x31-\\x39] digit\n        | \"1\" digit{2}\n        | \"2\" [\\x30-\\x34] digit\n        | \"25\" [\\x30-\\x35];\n    ipv4address    = dec_octet \".\" dec_octet \".\" dec_octet \".\" dec_octet;\n    h16            = hexdigit{1,4};\n    ls32           = h16 \":\" h16 | ipv4address;\n    ipv6address\n        =                            (h16 \":\"){6} ls32\n        |                       \"::\" (h16 \":\"){5} ls32\n        | (               h16)? \"::\" (h16 \":\"){4} ls32\n        | ((h16 \":\"){0,1} h16)? \"::\" (h16 \":\"){3} ls32\n        | ((h16 \":\"){0,2} h16)? \"::\" (h16 \":\"){2} ls32\n        | ((h16 \":\"){0,3} h16)? \"::\"  h16 \":\"     ls32\n        | ((h16 \":\"){0,4} h16)? \"::\"              ls32\n        | ((h16 \":\"){0,5} h16)? \"::\"              h16\n        | ((h16 \":\"){0,6} h16)? \"::\";\n    ipvfuture      = \"v\" hexdigit+ \".\" (unreserved | sub_delims | \":\" )+;\n    ip_literal     = \"[\" ( ipv6address | ipvfuture ) \"]\";\n    reg_name       = (unreserved | pct_encoded | sub_delims)*;\n    path_abempty   = (\"/\" pchar*)*;\n    path_absolute  = \"/\" (pchar+ (\"/\" pchar*)*)?;\n    path_rootless  = pchar+ (\"/\" pchar*)*;\n    path_empty     = \"\";\n    host           = ip_literal | ipv4address | reg_name;\n    port           = digit*;\n    query          = (pchar | [/?])*;\n    absolute_uri   = @s1 scheme @s2 \":\"\n        ( \"//\" (@u1 userinfo @u2 \"@\")? @hs1 host @hs2 (\":\" @r1 port @r2)? @p1 path_abempty @p2\n        | @p3 (path_absolute | path_rootless | path_empty) @p4\n        ) (\"?\" @q1 query @q2)?;\n    authority      = (@u3 userinfo @u4 \"@\")? @hs3 host @hs4 (\":\" @r3 port @r4)?;\n    origin_form    = @p5 path_abempty @p6 (\"?\" @q3 query @q4)?;\n    http_name      = \"HTTP\";\n    http_version   = http_name \"/\" digit \".\" digit;\n    request_target\n        = @at authority\n        | @au absolute_uri\n        | @of origin_form\n        | \"*\";\n    method         = tchar+;\n    request_line   = @m1 method @m2 sp request_target sp @v3 http_version @v4 crlf;\n    status_code    = digit{3};\n    reason_phrase  = (htab | sp | vchar | obs_text)*;\n    status_line    = @v1 http_version @v2 sp @st1 status_code @st2 sp @rp1 reason_phrase @rp2 crlf;\n    start_line     = (request_line | status_line);\n    message_head   = start_line (header_field crlf)* crlf;\n\n    *   { return 1; }\n    end { *count = c; return 0; }\n    eol { goto loop; }\n    message_head {\n        ++c;\n        if (st1) {\n            fprintf(stderr, \"%.*s %.*s %.*s\\n\",\n                (int)(v2 - v1), v1,\n                (int)(st2 - st1), st1,\n                (int)(rp2 - rp1), rp1);\n        } else if (m1) {\n            fprintf(stderr, \"%.*s \", (int)(m2 - m1), m1);\n            if (of) {\n                fprintf(stderr, \"%.*s\", (int)(p6 - p5), p5);\n                if (q3) fprintf(stderr, \"?%.*s\", (int)(q4 - q3), q3);\n            } else if (au) {\n                fprintf(stderr, \"%.*s:\", (int)(s2 - s1), s1);\n                if (p1) fprintf(stderr, \"//\");\n                if (u1) fprintf(stderr, \"%.*s@\", (int)(u2 - u1), u1);\n                fprintf(stderr, \"%.*s\", (int)(hs2 - hs1), hs1);\n                if (r1) fprintf(stderr, \":%.*s\", (int)(r2 - r1), r1);\n                if (p1) fprintf(stderr, \"%.*s\",  (int)(p2 - p1), p1);\n                if (p3) fprintf(stderr, \"%.*s\",  (int)(p4 - p3), p3);\n                if (q1) fprintf(stderr, \"?%.*s\", (int)(q2 - q1), q1);\n            } else if (at) {\n                if (u3) fprintf(stderr, \"%.*s@\", (int)(u4 - u3), u3);\n                fprintf(stderr, \"%.*s\", (int)(hs4 - hs3), hs3);\n                if (r3) fprintf(stderr, \":%.*s\", (int)(r4 - r3), r3);\n            } else {\n                fprintf(stderr, \"*\");\n            }\n            fprintf(stderr, \" %.*s\\n\", (int)(v4 - v3), v3);\n        }\n        print_headers(in->tok, h1, h2, h3, h4, h5);\n        fprintf(stderr, \"\\n\");\n        mtagpool_clear(&in->mtp, in);\n        goto loop;\n    }\n*/\n}\n\nint main(int argc, char **argv)\n{\n    const char *fname = \"input\";\n    FILE *f;\n\n    // prepare input file\n    f = fopen(fname, \"w\");\n    fprintf(f,\n        \"GET /index.html HTTP/1.1\\n\"\n        \"Host: www.example.com\\n\"\n        \"User-Agent: Mozilla/5.0\\n\"\n        \"Accept: text/xml,application/xml,application/xhtml+xml,text/html*/*\\n\"\n        \"Accept-Language: en-us\\n\"\n        \"Accept-Charset: ISO-8859-1,utf-8\\n\"\n        \"Connection: keep-alive\\n\"\n        \"\\n\"\n        \"HTTP/1.1 200 OK\\n\"\n        \"Date: Thu, 24 Jul 2008 17:36:27 GMT\\n\"\n        \"Server: Apache-Coyote/1.1\\n\"\n        \"Content-Type: text/html;charset=UTF-8\\n\"\n        \"Content-Length: 1846\\n\"\n        \"\\n\");\n    fclose(f);\n\n    // read input into buffer\n    input_t in;\n    init_input(&in, fname);\n    long count;\n\n    assert(lex(&in, &count) == 0 && count == 2);\n\n    // cleanup\n    remove(fname);\n    free_input(&in);\n    return 0;\n}\n",
      "extraCommandLineArguments": "-i"
    },
    "submatch/parse_records.re": {
      "content": "// re2c $INPUT -o $OUTPUT -i\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <vector>\n\nstruct mtag_t\n{\n    int pred;\n    const char *tag;\n};\n\ntypedef std::vector<mtag_t> mtagpool_t;\n\nstatic void mtag(int *pt, const char *t, mtagpool_t *tp) {\n    mtag_t l = {*pt, t};\n    *pt = (int) tp->size();\n    tp->push_back(l);\n}\n\nstatic void print_channels(const mtagpool_t &tp, int x, int y) {\n    if (x == -1) return;\n    print_channels(tp, tp[x].pred, tp[y].pred);\n    const char *px = tp[x].tag, *py = tp[y].tag;\n    fprintf(stderr, \"    %.*s\\n\", (int) (py - px), px);\n}\n\n#define YYMTAGP(t) mtag(&t, YYCURSOR, &tp)\n#define YYMTAGN(t) mtag(&t, NULL,     &tp)\n\nstatic int lex(const char *YYCURSOR) {\n    const char *YYMARKER, *n1, *n2, *a1, *a2, *c1, *c2;\n    mtagpool_t tp;\n    int h1, h2;\n    /*!stags:re2c format = \"const char *@@;\"; */\n    /*!mtags:re2c format = \"int @@;\"; */\n\n    for (;;) {\n        tp.clear();\n    /*!mtags:re2c format = \"@@ = -1;\"; */\n    /*!re2c\n        re2c:YYCTYPE = char;\n        re2c:yyfill:enable = 0;\n        re2c:tags = 1;\n\n        end     = \"\\x00\";\n        eol     = \"\\n\";\n        wsp     = [ \\t]*;\n        eq      = wsp \"=\" wsp;\n        nick    = [a-zA-Z0-9_]+;\n        name    = [A-Z] (\".\" | [a-z]+);\n        names   = name (wsp name)*;\n        country = [A-Za-z ]+;\n        channel = ([a-z0-9-]+ \"/\")? \"#\" [a-z0-9-]+;\n\n        *         { fprintf(stderr, \"error: %s\\n\", YYCURSOR); return 1; }\n        end       { return 0; }\n        wsp | eol { continue; }\n\n        @n1 nick @n2 wsp \"{\" wsp eol\n            wsp \"name\"     eq @a1 names   @a2 wsp eol\n            wsp \"country\"  eq @c1 country @c2 wsp eol\n            wsp \"channels\" eq (wsp #h1 channel #h2 wsp \";\")* wsp eol\n        wsp \"}\" {\n            fprintf(stderr, \"\\n%.*s\\n\", (int) (n2 - n1), n1);\n            fprintf(stderr, \"  name:     %.*s\\n\", (int) (a2 - a1), a1);\n            fprintf(stderr, \"  country:  %.*s\\n\", (int) (c2 - c1), c1);\n            fprintf(stderr, \"  channels:\\n\");\n            print_channels(tp, h1, h2);\n            continue;\n        }\n    */\n    }\n}\n\nint main() {\n    const char *fname = \"etc_passwd\";\n    FILE *f;\n\n    // prepare input file\n    f = fopen(fname, \"w\");\n    fprintf(f,\n        \"h4cker1970 {\\n\"\n        \"    name     = Jon Smith\\n\"\n        \"    country  = UK\\n\"\n        \"    channels = freenode/#gentoo-dev; freenode/#gentoo-arch; freenode/#alpha;\\n\"\n        \"}\\n\"\n        \"\\n\"\n        \"mitek {\\n\"\n        \"    name     = Mitrofan Rygoravich\\n\"\n        \"    country  = Belarus\\n\"\n        \"    channels = bynets/#haskell; freenode/#unix;\\n\"\n        \"}\\n\"\n        \"\\n\");\n    fclose(f);\n\n    // read input file into buffer\n    f = fopen(fname, \"r\");\n    fseek(f, 0, SEEK_END);\n    const size_t fsize = (size_t) ftell(f);\n    fseek(f, 0, SEEK_SET);\n    char *buffer = (char*) malloc(fsize + 1);\n    fread(buffer, 1, fsize, f);\n    buffer[fsize] = 0;\n    fclose(f);\n\n    assert(lex(buffer) == 0);\n\n    // cleanup\n    remove(fname);\n    free(buffer);\n    return 0;\n}\n",
      "extraCommandLineArguments": "-i"
    },
    "submatch/parse_etc_passwd.re": {
      "content": "// re2c $INPUT -o $OUTPUT -i\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n/*!max:re2c*/\n\nstatic int lex(const char *YYCURSOR) {\n    const char *YYMARKER;\n    /*!svars:re2c format = 'const char *@@;'; */\n    /*!stags:re2c format = 'const char *@@;'; */\n\n    for (;;) {\n    /*!re2c\n        re2c:YYCTYPE = char;\n        re2c:yyfill:enable = 0;\n        re2c:tags = 1;\n\n        end  = \"\\x00\";\n        eol  = \"\\n\";\n        sep  = [:];\n        char = [^] \\ (end | eol | sep);\n        user = char+;\n        pass = char*;\n        uid  = [0-9]+;\n        gid  = [0-9]+;\n        info = char*;\n        home = \"/\" char*;\n        cmd  = \"/\" char*;\n\n        *   { fprintf(stderr, \"error\\n\"); return 1; }\n        end { return 0; }\n\n        @n user sep\n        @p pass sep\n        @u uid  sep\n        @g gid  sep\n        @f info sep\n        @h home sep\n        @c cmd  eol {\n            fprintf(stderr, \"user:     %.*s\\n\", (int)(p - n) - 1, n);\n            fprintf(stderr, \"password: %.*s\\n\", (int)(u - p) - 1, p);\n            fprintf(stderr, \"UID:      %.*s\\n\", (int)(g - u) - 1, u);\n            fprintf(stderr, \"GID:      %.*s\\n\", (int)(f - g) - 1, g);\n            fprintf(stderr, \"info:     %.*s\\n\", (int)(h - f) - 1, f);\n            fprintf(stderr, \"home:     %.*s\\n\", (int)(c - h) - 1, h);\n            fprintf(stderr, \"command:  %.*s\\n\", (int)(YYCURSOR - c - 1), c);\n            fprintf(stderr, \"\\n\");\n            continue;\n        }\n    */\n    }\n}\n\nint main() {\n    const char *fname = \"etc_passwd\";\n    FILE *f;\n\n    // prepare input file\n    f = fopen(fname, \"w\");\n    fprintf(f,\n        \"root:x:0:0:root:/root:/bin/bash\\n\"\n        \"bin:x:1:1:bin:/bin:/bin/false\\n\"\n        \"portage:x:250:250:portage:/var/tmp/portage:/bin/false\\n\");\n    fclose(f);\n\n    // read input file into buffer\n    f = fopen(fname, \"r\");\n    fseek(f, 0, SEEK_END);\n    const size_t fsize = (size_t) ftell(f);\n    fseek(f, 0, SEEK_SET);\n    char *buffer = (char*) malloc(fsize + 1);\n    fread(buffer, 1, fsize, f);\n    buffer[fsize] = 0;\n    fclose(f);\n\n    assert(lex(buffer) == 0);\n\n    // cleanup\n    remove(fname);\n    free(buffer);\n    return 0;\n}\n",
      "extraCommandLineArguments": "-i"
    },
    "submatch/02_mtags.re": {
      "content": "// re2c $INPUT -o $OUTPUT\n#include <assert.h>\n#include <stddef.h>\n#include <vector>\n\nstatic const int MTAG_ROOT = -1;\n\n// An m-tag tree is a way to store histories with an O(1) copy operation.\n// Histories naturally form a tree, as they have common start and fork at some\n// point. The tree is stored as an array of pairs (tag value, link to parent).\n// An m-tag is represented with a single link in the tree (array index).\nstruct Mtag {\n    const char *elem; // tag value\n    int pred; // index of the predecessor node or root\n};\ntypedef std::vector<Mtag> MtagTrie;\n\ntypedef std::vector<int> Ver; // unbounded number of version components\n\nstatic int s2n(const char *s, const char *e) { // pre-parsed string to number\n    int n = 0;\n    for (; s < e; ++s) n = n * 10 + (*s - '0');\n    return n;\n}\n\n// Append a single value to an m-tag history.\nstatic void add_mtag(MtagTrie &trie, int &mtag, const char *value) {\n    Mtag m = {value, mtag};\n    mtag = (int)trie.size();\n    trie.push_back(m);\n}\n\n// Recursively unwind tag histories and collect version components.\nstatic void unfold(const MtagTrie &trie, int x, int y, Ver &ver) {\n    // Reached the root of the m-tag tree, stop recursion.\n    if (x == MTAG_ROOT && y == MTAG_ROOT) return;\n\n    // Unwind history further.\n    unfold(trie, trie[x].pred, trie[y].pred, ver);\n\n    // Get tag values. Tag histories must have equal length.\n    assert(x != MTAG_ROOT && y != MTAG_ROOT);\n    const char *ex = trie[x].elem, *ey = trie[y].elem;\n\n    if (ex != NULL && ey != NULL) {\n        // Both tags are valid pointers, extract component.\n        ver.push_back(s2n(ex, ey));\n    } else {\n        // Both tags are NULL (this corresponds to zero repetitions).\n        assert(ex == NULL && ey == NULL);\n    }\n}\n\nstatic bool parse(const char *str, Ver &ver) {\n    const char *YYCURSOR = str, *YYMARKER;\n    MtagTrie mt;\n\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = 'const char *@@;'; */\n    /*!mvars:re2c format = 'int @@;'; */\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = 'const char *@@ = NULL;'; */\n    /*!mtags:re2c format = 'int @@ = MTAG_ROOT;'; */\n\n    /*!re2c\n        re2c:api:style = free-form;\n        re2c:YYCTYPE = char;\n        re2c:YYSTAGP = \"@@ = YYCURSOR;\";\n        re2c:YYSTAGN = \"@@ = NULL;\";\n        re2c:YYMTAGP = \"add_mtag(mt, @@, YYCURSOR);\";\n        re2c:YYMTAGN = \"add_mtag(mt, @@, NULL);\";\n        re2c:yyfill:enable = 0;\n        re2c:tags = 1;\n\n        num = [0-9]+;\n\n        @t1 num @t2 (\".\" #t3 num #t4)* [\\x00] {\n            ver.clear();\n            ver.push_back(s2n(t1, t2));\n            unfold(mt, t3, t4, ver);\n            return true;\n        }\n        * { return false; }\n    */\n}\n\nint main() {\n    Ver v;\n    assert(parse(\"1\", v) && v == Ver({1}));\n    assert(parse(\"1.2.3.4.5.6.7\", v) && v == Ver({1, 2, 3, 4, 5, 6, 7}));\n    assert(!parse(\"1.2.\", v));\n    return 0;\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/uri_rfc3986.re": {
      "content": "// re2c $INPUT -o $OUTPUT -i\n#include <assert.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n\n/*!re2c re2c:flags:tags = 1; */\n/*!max:re2c*/\nstatic const size_t SIZE = 4096;\n\ntypedef struct {\n    FILE *file;\n    char *buf;\n    char *lim;\n    char *cur;\n    char *mar;\n    char *tok;\n    /*!stags:re2c format = \"char *@@;\\n\"; */\n    int eof;\n} input_t;\n\nstatic void init_input(input_t *in, const char *fname)\n{\n    in->file = fopen(fname, \"r\");\n    in->buf = (char*) malloc(SIZE + YYMAXFILL);\n    in->lim = in->buf + SIZE;\n    in->cur = in->lim;\n    in->mar = in->lim;\n    in->tok = in->lim;\n    /*!stags:re2c format = \"in->@@ = 0;\\n\"; */\n    in->eof = 0;\n}\n\nstatic void free_input(input_t *in)\n{\n    free(in->buf);\n    fclose(in->file);\n}\n\nstatic int fill(input_t *in, size_t need)\n{\n    size_t free;\n    if (in->eof) return 1;\n\n    free = in->tok - in->buf;\n    if (free < need) return 2;\n\n    memmove(in->buf, in->tok, in->lim - in->tok);\n    in->lim -= free;\n    in->cur -= free;\n    in->mar -= free;\n    in->tok -= free;\n    /*!stags:re2c format = \"if (in->@@) in->@@ -= free;\\n\"; */\n    in->lim += fread(in->lim, 1, free, in->file);\n    if (in->lim < in->buf + SIZE) {\n        in->eof = 1;\n        memset(in->lim, 0, YYMAXFILL);\n        in->lim += YYMAXFILL;\n    }\n    return 0;\n}\n\nstatic int lex(input_t *in, long *count)\n{\n    /*!svars:re2c format = \"const char *@@;\\n\"; */\n    long c = 0;\nloop:\n    in->tok = in->cur;\n/*!re2c\n\n    re2c:YYCTYPE = char;\n    re2c:YYCURSOR = in->cur;\n    re2c:YYMARKER = in->mar;\n    re2c:YYLIMIT = in->lim;\n    re2c:YYFILL = \"if (fill(in, @@) != 0) return 2;\";\n    re2c:YYFILL:naked = 1;\n    re2c:tags:expression = \"in->@@\";\n\n    end = \"\\x00\";\n    eol = \"\\n\";\n\n    alpha       = [a-zA-Z];\n    digit       = [0-9];\n    hexdigit    = [0-9a-fA-F];\n    unreserved  = alpha | digit | [-._~];\n    pct_encoded = \"%\" hexdigit{2};\n    sub_delims  = [!$&'()*+,;=];\n    pchar       = unreserved | pct_encoded | sub_delims | [:@];\n\n    scheme = @s1 alpha (alpha | digit | [-+.])* @s2;\n    userinfo = @u1 (unreserved | pct_encoded | sub_delims | \":\")* @u2;\n    dec_octet\n        = digit\n        | [\\x31-\\x39] digit\n        | \"1\" digit{2}\n        | \"2\" [\\x30-\\x34] digit\n        | \"25\" [\\x30-\\x35];\n    ipv4address = dec_octet \".\" dec_octet \".\" dec_octet \".\" dec_octet;\n    h16         = hexdigit{1,4};\n    ls32        = h16 \":\" h16 | ipv4address;\n    ipv6address\n        =                            (h16 \":\"){6} ls32\n        |                       \"::\" (h16 \":\"){5} ls32\n        | (               h16)? \"::\" (h16 \":\"){4} ls32\n        | ((h16 \":\"){0,1} h16)? \"::\" (h16 \":\"){3} ls32\n        | ((h16 \":\"){0,2} h16)? \"::\" (h16 \":\"){2} ls32\n        | ((h16 \":\"){0,3} h16)? \"::\"  h16 \":\"     ls32\n        | ((h16 \":\"){0,4} h16)? \"::\"              ls32\n        | ((h16 \":\"){0,5} h16)? \"::\"              h16\n        | ((h16 \":\"){0,6} h16)? \"::\";\n    ipvfuture   = \"v\" hexdigit+ \".\" (unreserved | sub_delims | \":\" )+;\n    ip_literal  = \"[\" ( ipv6address | ipvfuture ) \"]\";\n    reg_name    = (unreserved | pct_encoded | sub_delims)*;\n    host\n        = @h1 ip_literal  @h2\n        | @h3 ipv4address @h4\n        | @h5 reg_name    @h6;\n    port      = @r1 digit* @r2;\n    authority = (userinfo \"@\")? host (\":\" port)?;\n    path_abempty  = (\"/\" pchar*)*;\n    path_absolute = \"/\" (pchar+ (\"/\" pchar*)*)?;\n    path_rootless = pchar+ (\"/\" pchar*)*;\n    path_empty    = \"\";\n    hier_part\n        = \"//\" authority @p1 path_abempty @p2\n        | @p3 (path_absolute | path_rootless | path_empty) @p4;\n    query    = @q1 (pchar | [/?])* @q2;\n    fragment = @f1 (pchar | [/?])* @f2;\n    uri = scheme \":\" hier_part (\"?\" query)? (\"#\" fragment)?;\n\n    *   { return 1; }\n    end { *count = c; return 0; }\n    eol { goto loop; }\n    uri {\n        ++c;\n        fprintf(stderr, \"URI %ld:\\n\", c);\n        fprintf(stderr, \"  scheme:   %.*s\\n\", (int)(s2 - s1), s1);\n        if (u1) fprintf(stderr, \"  userinfo: %.*s\\n\", (int)(u2 - u1), u1);\n        if (h1) fprintf(stderr, \"  host:     %.*s (IP literal)\\n\", (int)(h2 - h1), h1);\n        if (h3) fprintf(stderr, \"  host:     %.*s (IPv4)\\n\", (int)(h4 - h3), h3);\n        if (h5) fprintf(stderr, \"  host:     %.*s (name)\\n\", (int)(h6 - h5), h5);\n        if (r1) fprintf(stderr, \"  port:     %.*s\\n\", (int)(r2 - r1), r1);\n        if (p1) fprintf(stderr, \"  path:     %.*s\\n\", (int)(p2 - p1), p1);\n        if (p3) fprintf(stderr, \"  path:     %.*s\\n\", (int)(p4 - p3), p3);\n        if (q1) fprintf(stderr, \"  query:    %.*s\\n\", (int)(q2 - q1), q1);\n        if (f1) fprintf(stderr, \"  fragment: %.*s\\n\", (int)(f2 - f1), f1);\n        fprintf(stderr, \"\\n\");\n        goto loop;\n    }\n*/\n}\n\nint main(int argc, char **argv)\n{\n    const char *fname = \"input\";\n    FILE *f;\n\n    // prepare input file\n    f = fopen(fname, \"w\");\n    fprintf(f,\n        \"http://user:pass@127.0.0.1:8000/path/data?key=val&key2=val2#frag1\\n\"\n        \"rsync://rsync.kernel.org/pub/\\n\"\n        \"http://re2c.org/manual/syntax/syntax.html#rules\\n\"\n        \"ssh://[2001:db8:85a3::8a2e:370:7334]/\\n\");\n    fclose(f);\n\n    // read input into buffer\n    input_t in;\n    init_input(&in, fname);\n    long count;\n\n    assert(lex(&in, &count) == 0 && count == 4);\n\n    // cleanup\n    remove(fname);\n    free_input(&in);\n    return 0;\n}\n",
      "extraCommandLineArguments": "-i"
    },
    "submatch/04_posix_captures.re": {
      "content": "// re2c $INPUT -o $OUTPUT\n#include <assert.h>\n#include <stddef.h>\n\n// Maximum number of capturing groups among all rules.\n/*!maxnmatch:re2c*/\n\nstruct SemVer { int major, minor, patch; };\n\nstatic int s2n(const char *s, const char *e) { // pre-parsed string to number\n    int n = 0;\n    for (; s < e; ++s) n = n * 10 + (*s - '0');\n    return n;\n}\n\nstatic bool lex(const char *str, SemVer &ver) {\n    const char *YYCURSOR = str, *YYMARKER;\n\n    // Allocate memory for capturing parentheses (twice the number of groups).\n    const char *yypmatch[YYMAXNMATCH * 2];\n    size_t yynmatch;\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = 'const char *@@;\\n'; */\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:YYCTYPE = char;\n        re2c:posix-captures = 1;\n\n        num = [0-9]+;\n\n        (num) \".\" (num) (\".\" num)? [\\x00] {\n            // `yynmatch` is the number of capturing groups\n            assert(yynmatch == 4);\n            // Even `yypmatch` values are for opening parentheses, odd values\n            // are for closing parentheses, the first group is the whole match.\n            ver.major = s2n(yypmatch[2], yypmatch[3]);\n            ver.minor = s2n(yypmatch[4], yypmatch[5]);\n            ver.patch = yypmatch[6] ? s2n(yypmatch[6] + 1, yypmatch[7]) : 0;\n            return true;\n        }\n        * { return false; }\n    */\n}\n\nint main() {\n    SemVer v;\n    assert(lex(\"23.34\", v) && v.major == 23 && v.minor == 34 && v.patch == 0);\n    assert(lex(\"1.2.999\", v) && v.major == 1 && v.minor == 2 && v.patch == 999);\n    assert(!lex(\"1.a\", v));\n    return 0;\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags.re": {
      "content": "// re2c $INPUT -o $OUTPUT\n#include <assert.h>\n#include <stddef.h>\n\nstruct SemVer { int major, minor, patch; };\n\nstatic int s2n(const char *s, const char *e) { // pre-parsed string to number\n    int n = 0;\n    for (; s < e; ++s) n = n * 10 + (*s - '0');\n    return n;\n}\n\nstatic bool lex(const char *str, SemVer &ver) {\n    const char *YYCURSOR = str, *YYMARKER;\n\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = \"const char *@@;\\n\"; */\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = 'const char *@@;\\n'; */\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:YYCTYPE = char;\n        re2c:tags = 1;\n\n        num = [0-9]+;\n\n        @t1 num @t2 \".\" @t3 num @t4 (\".\" @t5 num)? [\\x00] {\n            ver.major = s2n(t1, t2);\n            ver.minor = s2n(t3, t4);\n            ver.patch = t5 != NULL ? s2n(t5, YYCURSOR - 1) : 0;\n            return true;\n        }\n        * { return false; }\n    */\n}\n\nint main() {\n    SemVer v;\n    assert(lex(\"23.34\", v) && v.major == 23 && v.minor == 34 && v.patch == 0);\n    assert(lex(\"1.2.999\", v) && v.major == 1 && v.minor == 2 && v.patch == 999);\n    assert(!lex(\"1.a\", v));\n    return 0;\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/03_captures.re": {
      "content": "// re2c $INPUT -o $OUTPUT\n#include <assert.h>\n#include <stddef.h>\n\nstruct SemVer { int major, minor, patch; };\n\nstatic int s2n(const char *s, const char *e) { // pre-parsed string to number\n    int n = 0;\n    for (; s < e; ++s) n = n * 10 + (*s - '0');\n    return n;\n}\n\nstatic bool lex(const char *str, SemVer &ver) {\n    const char *YYCURSOR = str, *YYMARKER;\n\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = 'const char *@@;\\n'; */\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = 'const char *@@;\\n'; */\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:YYCTYPE = char;\n        re2c:captvars = 1;\n\n        num = [0-9]+;\n\n        (num) \".\" (num) (\".\" num)? [\\x00] {\n            (void) yytl0; (void) yytr0; // some variables are unused\n            ver.major = s2n(yytl1, yytr1);\n            ver.minor = s2n(yytl2, yytr2);\n            ver.patch = yytl3 ? s2n(yytl3 + 1, yytr3) : 0;\n            return true;\n        }\n        * { return false; }\n    */\n}\n\nint main() {\n    SemVer v;\n    assert(lex(\"23.34\", v) && v.major == 23 && v.minor == 34 && v.patch == 0);\n    assert(lex(\"1.2.999\", v) && v.major == 1 && v.minor == 2 && v.patch == 999);\n    assert(!lex(\"1.a\", v));\n    return 0;\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags_fill.re": {
      "content": "// re2c $INPUT -o $OUTPUT --tags\n#include <assert.h>\n#include <stddef.h>\n#include <stdio.h>\n#include <string.h>\n#include <vector>\n\n#define BUFSIZE 4095\n\nstruct Input {\n    FILE *file;\n    char buf[BUFSIZE + 1], *lim, *cur, *mar, *tok;\n    // Intermediate tag variables must be part of the lexer state passed to YYFILL.\n    // They don't correspond to tags and should be autogenerated by re2c.\n    /*!stags:re2c format = 'const char *@@;'; */\n    bool eof;\n};\n\nstruct SemVer { int major, minor, patch; };\n\nstatic bool operator==(const SemVer &x, const SemVer &y) {\n    return x.major == y.major && x.minor == y.minor && x.patch == y.patch;\n}\n\nstatic int s2n(const char *s, const char *e) { // pre-parsed string to number\n    int n = 0;\n    for (; s < e; ++s) n = n * 10 + (*s - '0');\n    return n;\n}\n\nstatic int fill(Input &in) {\n    if (in.eof) return 1;\n\n    const size_t shift = in.tok - in.buf;\n    const size_t used = in.lim - in.tok;\n\n    // Error: lexeme too long. In real life could reallocate a larger buffer.\n    if (shift < 1) return 2;\n\n    // Shift buffer contents (discard everything up to the current token).\n    memmove(in.buf, in.tok, used);\n    in.lim -= shift;\n    in.cur -= shift;\n    in.mar -= shift;\n    in.tok -= shift;\n    // Tag variables need to be shifted like other input positions. The check\n    // for non-NULL is only needed if some tags are nested inside of alternative\n    // or repetition, so that they can have NULL value.\n    /*!stags:re2c format = \"if (in.@@) in.@@ -= shift;\\n\"; */\n\n    // Fill free space at the end of buffer with new data from file.\n    in.lim += fread(in.lim, 1, BUFSIZE - used, in.file);\n    in.lim[0] = 0;\n    in.eof = in.lim < in.buf + BUFSIZE;\n    return 0;\n}\n\nstatic bool lex(Input &in, std::vector<SemVer> &vers) {\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = 'const char *@@;\\n'; */\n\n    for (;;) {\n        in.tok = in.cur;\n    /*!re2c\n        re2c:eof = 0;\n        re2c:api:style = free-form;\n        re2c:YYCTYPE = char;\n        re2c:YYCURSOR = in.cur;\n        re2c:YYMARKER = in.mar;\n        re2c:YYLIMIT = in.lim;\n        re2c:YYFILL = \"fill(in) == 0\";\n        re2c:tags:expression = \"in.@@\";\n\n        num = [0-9]+;\n\n        num @t1 \".\" @t2 num @t3 (\".\" @t4 num)? [\\n] {\n            int major = s2n(in.tok, t1);\n            int minor = s2n(t2, t3);\n            int patch = t4 != NULL ? s2n(t4, in.cur - 1) : 0;\n            SemVer ver = {major, minor, patch};\n            vers.push_back(ver);\n            continue;\n        }\n        $ { return true; }\n        * { return false; }\n    */}\n}\n\nint main() {\n    const char *fname = \"input\";\n    const SemVer semver = {1, 22, 333};\n    std::vector<SemVer> expect(BUFSIZE, semver), actual;\n\n    // Prepare input file (make sure it exceeds buffer size).\n    FILE *f = fopen(fname, \"w\");\n    for (int i = 0; i < BUFSIZE; ++i) fprintf(f, \"1.22.333\\n\");\n    fclose(f);\n\n    // Reopen input file for reading.\n    f = fopen(fname, \"r\");\n\n    // Initialize lexer state: all pointers are at the end of buffer.\n    Input in;\n    in.file = f;\n    in.cur = in.mar = in.tok = in.lim = in.buf + BUFSIZE;\n    /*!stags:re2c format = \"in.@@ = in.lim;\\n\"; */\n    in.eof = false;\n    // Sentinel (at YYLIMIT pointer) is set to zero, which triggers YYFILL.\n    *in.lim = 0;\n  \n    // Run the lexer and check results.\n    assert(lex(in, actual) && expect == actual);\n\n    // Cleanup: remove input file.\n    fclose(f);\n    remove(fname);\n    return 0;\n}\n",
      "extraCommandLineArguments": "--tags"
    },
    "submatch/parse_options.re": {
      "content": "// re2c $INPUT -o $OUTPUT -i\n#include <assert.h>\n#include <stdio.h>\n#include <string>\n#include <vector>\n\ntypedef std::vector<std::pair<std::string, std::string> > unknown_t;\n\nstruct options_t {\n    std::string date;\n    std::string path;\n    std::string format;\n    std::string limit;\n    bool verbose;\n};\n\nstatic void show(const options_t &o, const unknown_t &u) {\n    fprintf(stderr, \"\\noptions:\\n\");\n    fprintf(stderr, \"  date:    %s\\n\", o.date.c_str());\n    fprintf(stderr, \"  path:    %s\\n\", o.path.c_str());\n    fprintf(stderr, \"  format:  %s\\n\", o.format.c_str());\n    fprintf(stderr, \"  limit:   %s\\n\", o.limit.c_str());\n    fprintf(stderr, \"  verbose: %s\\n\", o.verbose ? \"yes\" : \"no\");\n\n    fprintf(stderr, \"\\nunknown:\\n\");\n    unknown_t::const_iterator i = u.begin(), e = u.end();\n    for (; i != e; ++i) {\n        fprintf(stderr, \"  %s: '%s'\\n\", i->first.c_str(), i->second.c_str());\n    }\n}\n\nstatic void bad_arg(const char *k, const char *v, const char *e) {\n    fprintf(stderr, \"bad argument '%.*s' to option %.*s\\n\",\n        (int) (e - v), v, (int) (v - k), k);\n}\n\nstatic int lex(const char *s) {\n    options_t o;\n    unknown_t u;\n    const char *m, *k, *v;\n    /*!stags:re2c format = 'const char *@@;'; */\n\n    for (;;) {\n    /*!re2c\n        re2c:YYCTYPE = char;\n        re2c:YYCURSOR = s;\n        re2c:YYMARKER = m;\n        re2c:yyfill:enable = 0;\n        re2c:tags = 1;\n\n        end    = \"\\x00\";\n        sp     = [ \\t\\n\\r];\n        eq     = \"=\";\n        wsp    = sp*;\n        char   = [^=] \\ end;\n        ochar  = char \\ sp;\n        pchar  = ochar \\ [/];\n        str    = [\"] (char \\ [\"] | [\\][\"])* [\"];\n        opt    = ochar+;\n        arg    = ochar* | str;\n        date   = [0-9]{2} \"/\" [0-9]{2} \"/\" [0-9]{4};\n        path   = pchar* (\"/\" pchar*)*;\n        format = str;\n        limit  = [0-9]+ [BKMG]?;\n\n        *   { fprintf(stderr, \"error: %s\\n\", s); return 1; }\n        end { show(o, u); return 0; }\n        wsp { continue; }\n\n        \"-v\" | \"--verbose\"              { o.verbose = true; continue; }\n        (\"-l\" | \"--limit\"  eq) @v limit { o.limit  = std::string(v, s); continue; }\n        (\"-f\" | \"--format\" eq) @v str   { o.format = std::string(v, s); continue; }\n        (\"-d\" | \"--date\"   eq) @v date  { o.date   = std::string(v, s); continue; }\n        (\"-p\" | \"--path\"   eq) @v path  { o.path   = std::string(v, s); continue; }\n\n        @k (\"--\" (\"limit\" | \"format\" | \"date\" | \"path\") | \"-\" [lfdp]) @v eq? arg {\n            bad_arg(k, v, s);\n            continue;\n        }\n        [-]{1,2} @k opt @v eq? arg {\n            u.push_back(std::make_pair(std::string(k, v), std::string(v, s)));\n            continue;\n        }\n    */\n    }\n}\n\nint main() {\n    assert(lex(\"-v --limit=8K -d08/08/1985 -p/usr/src/linux \"\n        \"--format=\\\"%s\\\" --limit -f=3 --verbos --d\\\"19th May\\\"\") == 0);\n    return 0;\n}\n",
      "extraCommandLineArguments": "-i"
    },
    "real_world/cxx98.re": {
      "content": "// re2c $INPUT -o $OUTPUT -i\n#include <assert.h>\n#include <float.h>\n#include <limits.h>\n#include <stdio.h>\n#include <string.h>\n\n/*!max:re2c*/\nstatic const size_t SIZE = 64 * 1024;\n\nstruct input_t {\n    unsigned char buf[SIZE + YYMAXFILL];\n    unsigned char *lim;\n    unsigned char *cur;\n    unsigned char *mar;\n    unsigned char *tok;\n    bool eof;\n\n    FILE *const file;\n\n    input_t(FILE *f)\n        : buf()\n        , lim(buf + SIZE)\n        , cur(lim)\n        , mar(lim)\n        , tok(lim)\n        , eof(false)\n        , file(f)\n    {}\n    bool fill(size_t need)\n    {\n        if (eof) {\n            return false;\n        }\n        const size_t free = tok - buf;\n        if (free < need) {\n            return false;\n        }\n        memmove(buf, tok, lim - tok);\n        lim -= free;\n        cur -= free;\n        mar -= free;\n        tok -= free;\n        lim += fread(lim, 1, free, file);\n        if (lim < buf + SIZE) {\n            eof = true;\n            memset(lim, 0, YYMAXFILL);\n            lim += YYMAXFILL;\n        }\n        return true;\n    }\n};\n\n/*!re2c re2c:YYCTYPE = \"unsigned char\"; */\n\ntemplate<int base>\nstatic bool adddgt(unsigned long &u, unsigned long d)\n{\n    if (u > (ULONG_MAX - d) / base) {\n        return false;\n    }\n    u = u * base + d;\n    return true;\n}\n\nstatic bool lex_oct(const unsigned char *s, const unsigned char *e, unsigned long &u)\n{\n    for (u = 0, ++s; s < e; ++s) {\n        if (!adddgt<8>(u, *s - 0x30u)) {\n            return false;\n        }\n    }\n    return true;\n}\n\nstatic bool lex_dec(const unsigned char *s, const unsigned char *e, unsigned long &u)\n{\n    for (u = 0; s < e; ++s) {\n        if (!adddgt<10>(u, *s - 0x30u)) {\n            return false;\n        }\n    }\n    return true;\n}\n\nstatic bool lex_hex(const unsigned char *s, const unsigned char *e, unsigned long &u)\n{\n    for (u = 0, s += 2; s < e;) {\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:YYCURSOR = s;\n        *     { if (!adddgt<16>(u, s[-1] - 0x30u))      return false; continue; }\n        [a-f] { if (!adddgt<16>(u, s[-1] - 0x61u + 10)) return false; continue; }\n        [A-F] { if (!adddgt<16>(u, s[-1] - 0x41u + 10)) return false; continue; }\n    */\n    }\n    return true;\n}\n\nstatic bool lex_str(input_t &in, unsigned char q)\n{\n    fprintf(stderr, \"%c\", q);\n    for (unsigned long u = q;; fprintf(stderr, \"\\\\x%lx\", u)) {\n        in.tok = in.cur;\n        /*!re2c\n            re2c:yyfill:enable = 1;\n            re2c:YYCURSOR = in.cur;\n            re2c:YYMARKER = in.mar;\n            re2c:YYLIMIT = in.lim;\n            re2c:YYFILL = \"if (!in.fill(@@)) return false;\";\n            re2c:YYFILL:naked = 1;\n            *                    { return false; }\n            [^\\n\\\\]              { u = in.tok[0]; if (u == q) break; continue; }\n            \"\\\\a\"                { u = '\\a'; continue; }\n            \"\\\\b\"                { u = '\\b'; continue; }\n            \"\\\\f\"                { u = '\\f'; continue; }\n            \"\\\\n\"                { u = '\\n'; continue; }\n            \"\\\\r\"                { u = '\\r'; continue; }\n            \"\\\\t\"                { u = '\\t'; continue; }\n            \"\\\\v\"                { u = '\\v'; continue; }\n            \"\\\\\\\\\"               { u = '\\\\'; continue; }\n            \"\\\\'\"                { u = '\\''; continue; }\n            \"\\\\\\\"\"               { u = '\"';  continue; }\n            \"\\\\?\"                { u = '?';  continue; }\n            \"\\\\\" [0-7]{1,3}      { lex_oct(in.tok, in.cur, u); continue; }\n            \"\\\\u\" [0-9a-fA-F]{4} { lex_hex(in.tok, in.cur, u); continue; }\n            \"\\\\U\" [0-9a-fA-F]{8} { lex_hex(in.tok, in.cur, u); continue; }\n            \"\\\\x\" [0-9a-fA-F]+   { if (!lex_hex(in.tok, in.cur, u)) return false; continue; }\n        */\n    }\n    fprintf(stderr, \"%c\", q);\n    return true;\n}\n\nstatic bool lex_flt(const unsigned char *s)\n{\n    double d = 0;\n    double x = 1;\n    int e = 0;\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:YYCURSOR = s;\n    */\nmant_int:\n    /*!re2c\n        \".\"   { goto mant_frac; }\n        [eE]  { goto exp_sign; }\n        *     { d = (d * 10) + (s[-1] - '0'); goto mant_int; }\n    */\nmant_frac:\n    /*!re2c\n        \"\"    { goto sfx; }\n        [eE]  { goto exp_sign; }\n        [0-9] { d += (x /= 10) * (s[-1] - '0'); goto mant_frac; }\n    */\nexp_sign:\n    /*!re2c\n        \"+\"?  { x = 1e+1; goto exp; }\n        \"-\"   { x = 1e-1; goto exp; }\n    */\nexp:\n    /*!re2c\n        \"\"    { for (; e > 0; --e) d *= x;    goto sfx; }\n        [0-9] { e = (e * 10) + (s[-1] - '0'); goto exp; }\n    */\nsfx:\n    /*!re2c\n        *     { goto end; }\n        [fF]  { if (d > FLT_MAX) return false; goto end; }\n    */\nend:\n    fprintf(stderr, \"%g\", d);\n    return true;\n}\n\nstatic bool lex(input_t &in)\n{\n    unsigned long u;\n    for (;;) {\n        in.tok = in.cur;\n        /*!re2c\n            re2c:yyfill:enable = 1;\n            re2c:YYCURSOR = in.cur;\n            re2c:YYMARKER = in.mar;\n            re2c:YYLIMIT = in.lim;\n            re2c:YYFILL = \"if (!in.fill(@@)) return false;\";\n            re2c:YYFILL:naked = 1;\n\n            end = \"\\x00\";\n\n            *   { return false; }\n            end {\n                fprintf(stderr, \"\\n\");\n                return in.lim - in.tok == YYMAXFILL;\n            }\n\n            // macros\n            macro = (\"#\" | \"%:\") ([^\\n] | \"\\\\\\n\")* \"\\n\";\n            macro { continue; }\n\n            // whitespaces\n            mcm = \"/*\" ([^*] | (\"*\" [^/]))* \"*\"\"/\";\n            scm = \"//\" [^\\n]* \"\\n\";\n            wsp = ([ \\t\\v\\n\\r] | scm | mcm)+;\n            wsp { fprintf(stderr, \" \"); continue; }\n\n            // character and string literals\n            \"L\"? ['\"] { if (!lex_str(in, in.cur[-1])) return false; continue; }\n            \"L\"? \"''\" { return false; }\n\n            // integer literals\n            oct = \"0\" [0-7]*;\n            dec = [1-9][0-9]*;\n            hex = '0x' [0-9a-fA-F]+;\n            oct { if (!lex_oct(in.tok, in.cur, u)) return false; goto sfx; }\n            dec { if (!lex_dec(in.tok, in.cur, u)) return false; goto sfx; }\n            hex { if (!lex_hex(in.tok, in.cur, u)) return false; goto sfx; }\n\n            // floating literals\n            frc = [0-9]* \".\" [0-9]+ | [0-9]+ \".\";\n            exp = 'e' [+-]? [0-9]+;\n            flt = (frc exp? | [0-9]+ exp) [fFlL]?;\n            flt { if (lex_flt(in.tok)) continue; return false; }\n\n            // boolean literals\n            \"false\" { fprintf(stderr, \"false\"); continue; }\n            \"true\"  { fprintf(stderr, \"true\");  continue; }\n\n            // keywords\n            \"asm\"              { fprintf(stderr, \"ASM\");              continue; }\n            \"auto\"             { fprintf(stderr, \"AUTO\");             continue; }\n            \"bool\"             { fprintf(stderr, \"BOOL\");             continue; }\n            \"break\"            { fprintf(stderr, \"BREAK\");            continue; }\n            \"case\"             { fprintf(stderr, \"CASE\");             continue; }\n            \"catch\"            { fprintf(stderr, \"CATCH\");            continue; }\n            \"char\"             { fprintf(stderr, \"CHAR\");             continue; }\n            \"class\"            { fprintf(stderr, \"CLASS\");            continue; }\n            \"const\"            { fprintf(stderr, \"CONST\");            continue; }\n            \"const_cast\"       { fprintf(stderr, \"CONST_CAST\");       continue; }\n            \"continue\"         { fprintf(stderr, \"CONTINUE\");         continue; }\n            \"default\"          { fprintf(stderr, \"DEFAULT\");          continue; }\n            \"do\"               { fprintf(stderr, \"DO\");               continue; }\n            \"double\"           { fprintf(stderr, \"DOUBLE\");           continue; }\n            \"dynamic_cast\"     { fprintf(stderr, \"DYNAMIC_CAST\");     continue; }\n            \"else\"             { fprintf(stderr, \"ELSE\");             continue; }\n            \"enum\"             { fprintf(stderr, \"ENUM\");             continue; }\n            \"explicit\"         { fprintf(stderr, \"EXPLICIT\");         continue; }\n            \"export\"           { fprintf(stderr, \"EXPORT\");           continue; }\n            \"extern\"           { fprintf(stderr, \"EXTERN\");           continue; }\n            \"float\"            { fprintf(stderr, \"FLOAT\");            continue; }\n            \"for\"              { fprintf(stderr, \"FOR\");              continue; }\n            \"friend\"           { fprintf(stderr, \"FRIEND\");           continue; }\n            \"goto\"             { fprintf(stderr, \"GOTO\");             continue; }\n            \"if\"               { fprintf(stderr, \"IF\");               continue; }\n            \"inline\"           { fprintf(stderr, \"INLINE\");           continue; }\n            \"int\"              { fprintf(stderr, \"INT\");              continue; }\n            \"long\"             { fprintf(stderr, \"LONG\");             continue; }\n            \"mutable\"          { fprintf(stderr, \"MUTABLE\");          continue; }\n            \"namespace\"        { fprintf(stderr, \"NAMESPACE\");        continue; }\n            \"operator\"         { fprintf(stderr, \"OPERATOR\");         continue; }\n            \"private\"          { fprintf(stderr, \"PRIVATE\");          continue; }\n            \"protected\"        { fprintf(stderr, \"PROTECTED\");        continue; }\n            \"public\"           { fprintf(stderr, \"PUBLIC\");           continue; }\n            \"register\"         { fprintf(stderr, \"REGISTER\");         continue; }\n            \"reinterpret_cast\" { fprintf(stderr, \"REINTERPRET_CAST\"); continue; }\n            \"return\"           { fprintf(stderr, \"RETURN\");           continue; }\n            \"short\"            { fprintf(stderr, \"SHORT\");            continue; }\n            \"signed\"           { fprintf(stderr, \"SIGNED\");           continue; }\n            \"sizeof\"           { fprintf(stderr, \"SIZEOF\");           continue; }\n            \"static\"           { fprintf(stderr, \"STATIC\");           continue; }\n            \"static_cast\"      { fprintf(stderr, \"STATIC_CAST\");      continue; }\n            \"struct\"           { fprintf(stderr, \"STRUCT\");           continue; }\n            \"switch\"           { fprintf(stderr, \"SWITCH\");           continue; }\n            \"template\"         { fprintf(stderr, \"TEMPLATE\");         continue; }\n            \"this\"             { fprintf(stderr, \"THIS\");             continue; }\n            \"throw\"            { fprintf(stderr, \"THROW\");            continue; }\n            \"try\"              { fprintf(stderr, \"TRY\");              continue; }\n            \"typedef\"          { fprintf(stderr, \"TYPEDEF\");          continue; }\n            \"typeid\"           { fprintf(stderr, \"TYPEID\");           continue; }\n            \"typename\"         { fprintf(stderr, \"TYPENAME\");         continue; }\n            \"union\"            { fprintf(stderr, \"UNION\");            continue; }\n            \"unsigned\"         { fprintf(stderr, \"UNSIGNED\");         continue; }\n            \"using\"            { fprintf(stderr, \"USING\");            continue; }\n            \"virtual\"          { fprintf(stderr, \"VIRTUAL\");          continue; }\n            \"void\"             { fprintf(stderr, \"VOID\");             continue; }\n            \"volatile\"         { fprintf(stderr, \"VOLATILE\");         continue; }\n            \"wchar_t\"          { fprintf(stderr, \"WCHAR_T\");          continue; }\n            \"while\"            { fprintf(stderr, \"WHILE\");            continue; }\n\n            // operators and punctuation (including preprocessor)\n            (\"{\" | \"<%\")      { fprintf(stderr, \"{\");      continue; }\n            (\"}\" | \"%>\")      { fprintf(stderr, \"}\");      continue; }\n            (\"[\" | \"<:\")      { fprintf(stderr, \"[\");      continue; }\n            (\"]\" | \":>\")      { fprintf(stderr, \"]\");      continue; }\n            \"(\"               { fprintf(stderr, \"(\");      continue; }\n            \")\"               { fprintf(stderr, \")\");      continue; }\n            \";\"               { fprintf(stderr, \";\");      continue; }\n            \":\"               { fprintf(stderr, \":\");      continue; }\n            \"...\"             { fprintf(stderr, \"...\");    continue; }\n            \"new\"             { fprintf(stderr, \"new\");    continue; }\n            \"delete\"          { fprintf(stderr, \"delete\"); continue; }\n            \"?\"               { fprintf(stderr, \"?\");      continue; }\n            \"::\"              { fprintf(stderr, \"::\");     continue; }\n            \".\"               { fprintf(stderr, \".\");      continue; }\n            \".*\"              { fprintf(stderr, \".\");      continue; }\n            \"+\"               { fprintf(stderr, \"+\");      continue; }\n            \"-\"               { fprintf(stderr, \"-\");      continue; }\n            \"*\"               { fprintf(stderr, \"*\");      continue; }\n            \"/\"               { fprintf(stderr, \"/\");      continue; }\n            \"%\"               { fprintf(stderr, \"%%\");     continue; }\n            (\"^\" | \"xor\")     { fprintf(stderr, \"^\");      continue; }\n            (\"&\" | \"bitand\")  { fprintf(stderr, \"&\");      continue; }\n            (\"|\" | \"bitor\")   { fprintf(stderr, \"|\");      continue; }\n            (\"~\" | \"compl\")   { fprintf(stderr, \"~\");      continue; }\n            (\"!\" | \"not\")     { fprintf(stderr, \"!\");      continue; }\n            \"=\"               { fprintf(stderr, \"=\");      continue; }\n            \"<\"               { fprintf(stderr, \"<\");      continue; }\n            \">\"               { fprintf(stderr, \">\");      continue; }\n            \"+=\"              { fprintf(stderr, \"+=\");     continue; }\n            \"-=\"              { fprintf(stderr, \"-=\");     continue; }\n            \"*=\"              { fprintf(stderr, \"*=\");     continue; }\n            \"/=\"              { fprintf(stderr, \"/=\");     continue; }\n            \"%=\"              { fprintf(stderr, \"%%=\");    continue; }\n            (\"^=\" | \"xor_eq\") { fprintf(stderr, \"^=\");     continue; }\n            (\"&=\" | \"and_eq\") { fprintf(stderr, \"&=\");     continue; }\n            (\"|=\" | \"or_eq\")  { fprintf(stderr, \"|=\");     continue; }\n            \"<<\"              { fprintf(stderr, \"<<\");     continue; }\n            \">>\"              { fprintf(stderr, \">>\");     continue; }\n            \">>=\"             { fprintf(stderr, \">>=\");    continue; }\n            \"<<=\"             { fprintf(stderr, \"<<=\");    continue; }\n            \"==\"              { fprintf(stderr, \"==\");     continue; }\n            (\"!=\" | \"not_eq\") { fprintf(stderr, \"!=\");     continue; }\n            \"<=\"              { fprintf(stderr, \"<=\");     continue; }\n            \">=\"              { fprintf(stderr, \">=\");     continue; }\n            (\"&&\" | \"and\")    { fprintf(stderr, \"&&\");     continue; }\n            (\"||\" | \"or\")     { fprintf(stderr, \"||\");     continue; }\n            \"++\"              { fprintf(stderr, \"++\");     continue; }\n            \"--\"              { fprintf(stderr, \"--\");     continue; }\n            \",\"               { fprintf(stderr, \",\");      continue; }\n            \"->*\"             { fprintf(stderr, \"->*\");    continue; }\n            \"->\"              { fprintf(stderr, \"->\");     continue; }\n\n            // identifiers\n            id = [a-zA-Z_][a-zA-Z_0-9]*;\n            id { fprintf(stderr, \"%.*s\", (int)(in.cur - in.tok), in.tok); continue; }\n        */\nsfx:\n        /*!re2c\n            \"\"          { if (u > INT_MAX)  return false; fprintf(stderr, \"%d\",  static_cast<int>(u));      continue; }\n            'u'         { if (u > UINT_MAX) return false; fprintf(stderr, \"%u\",  static_cast<unsigned>(u)); continue; }\n            'l'         { if (u > LONG_MAX) return false; fprintf(stderr, \"%ld\", static_cast<long>(u));     continue; }\n            'ul' | 'lu' { fprintf(stderr, \"%lu\", u); continue; }\n        */\n    }\n}\n\nint main()\n{\n    const char *fname = \"example.cpp\";\n    FILE *f;\n\n    // prepare input file\n    f = fopen(fname, \"w\");\n    fprintf(f,\n        \"#include<stdio.h>\\n\"\n        \"\\n\"\n        \"int main()\\n\"\n        \"{\\n\"\n        \"    int n;\\n\"\n        \"    printf(\\\"Enter the number:\\\\n\\\");\\n\"\n        \"    scanf(\\\"%%d\\\", &n);\\n\"\n        \"\\n\"\n        \"    int f = 1;\\n\"\n        \"    for(int i = 1; i <= n; ++i) {\\n\"\n        \"        f *= i;\\n\"\n        \"    }\\n\"\n        \"\\n\"\n        \"    printf(\\\"Factorial of %%d is %%d\\\\n\\\", n, f);\\n\"\n        \"    return 0;\\n\"\n        \"}\\n\"\n        \"\\n\");\n    fclose(f);\n\n    f = fopen(fname, \"rb\");\n    input_t in(f);\n    assert(lex(in));\n    fclose(f);\n\n    // cleanup\n    remove(fname);\n    return 0;\n}\n",
      "extraCommandLineArguments": "-i"
    },
    "eof/05_fake_sentinel_eof_rule.re": {
      "content": "// re2c $INPUT -o $OUTPUT\n#include <assert.h>\n#include <stdlib.h>\n#include <string.h>\n\nstatic int lex(const char *str, unsigned int len) {\n    // For the sake of example create a string without terminating null.\n    char *buf = (char*) malloc(len);\n    memcpy(buf, str, len);\n\n    const char *cur = buf, *lim = buf + len, *mar;\n    int count = 0;\n\n    for (;;) {\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:eof = 0;\n        re2c:api = generic;\n        re2c:api:style = free-form;\n        re2c:YYCTYPE = char;\n        re2c:YYLESSTHAN = \"cur >= lim\";\n        re2c:YYPEEK = \"cur < lim ? *cur : 0\";  // fake null\n        re2c:YYSKIP = \"++cur;\";\n        re2c:YYBACKUP = \"mar = cur;\";\n        re2c:YYRESTORE = \"cur = mar;\";\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        *    { count = -1; break; }\n        $    { break;; }\n        str  { ++count; continue; }\n        [ ]+ { continue; }\n    */\n    }\n\n    free(buf);\n    return count;\n}\n\n#define TEST(s, r) assert(lex(s, sizeof(s) - 1) == r)\nint main() {\n    TEST(\"\", 0);\n    TEST(\"'qu\\0tes' 'are' 'fine: \\\\'' \", 3);\n    TEST(\"'unterminated\\\\'\", -1);\n    return 0;\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/03_eof_rule.re": {
      "content": "// re2c $INPUT -o $OUTPUT\n#include <assert.h>\n\n// Expect a null-terminated string.\nstatic int lex(const char *str, unsigned int len) {\n    const char *YYCURSOR = str, *YYLIMIT = str + len, *YYMARKER;\n    int count = 0;\n\n    for (;;) {\n    /*!re2c\n        re2c:YYCTYPE = char;\n        re2c:yyfill:enable = 0;\n        re2c:eof = 0;\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        *    { return -1; }\n        $    { return count; }\n        str  { ++count; continue; }\n        [ ]+ { continue; }\n    */\n    }\n}\n\n#define TEST(s, r) assert(lex(s, sizeof(s) - 1) == r)\nint main() {\n    TEST(\"\", 0);\n    TEST(\"'qu\\0tes' 'are' 'fine: \\\\'' \", 3);\n    TEST(\"'unterminated\\\\'\", -1);\n    return 0;\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/04_fake_sentinel.re": {
      "content": "// re2c $INPUT -o $OUTPUT\n#include <assert.h>\n#include <stdlib.h>\n#include <string.h>\n\nstatic int lex(const char *str, unsigned int len) {\n    // For the sake of example create a string without terminating null.\n    char *buf = (char*) malloc(len);\n    memcpy(buf, str, len);\n\n    const char *cur = buf, *lim = buf + len;\n    int count = 0;\n\n    for (;;) {\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:api = generic;\n        re2c:api:style = free-form;\n        re2c:YYCTYPE = char;\n        re2c:YYPEEK = \"cur < lim ? *cur : 0\";  // fake null\n        re2c:YYSKIP = \"++cur;\";\n\n        *      { count = -1; break; }\n        [\\x00] { break;; }\n        [a-z]+ { ++count; continue;; }\n        [ ]+   { continue; }\n    */\n    }\n\n    free(buf);\n    return count;\n}\n\n#define TEST(s, r) assert(lex(s, sizeof(s) - 1) == r)\nint main() {\n    TEST(\"\", 0);\n    TEST(\"one two three \", 3);\n    TEST(\"f0ur\", -1);\n    return 0;\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/02_bounds_checking.re": {
      "content": "// re2c $INPUT -o $OUTPUT\n#include <assert.h>\n#include <stdlib.h>\n#include <string.h>\n\n/*!max:re2c*/\n\nstatic int lex(const char *str, unsigned int len) {\n    // Make a copy of the string with YYMAXFILL zeroes at the end.\n    char *buf = (char*) malloc(len + YYMAXFILL);\n    memcpy(buf, str, len);\n    memset(buf + len, 0, YYMAXFILL);\n\n    const char *YYCURSOR = buf, *YYLIMIT = buf + len + YYMAXFILL;\n    int count = 0;\n\nloop:\n    /*!re2c\n        re2c:api:style = free-form;\n        re2c:YYCTYPE = char;\n        re2c:YYFILL = \"goto fail;\";\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        [\\x00] {\n            // Check that it is the sentinel, not some unexpected null.\n            if (YYCURSOR - 1 == buf + len) goto exit; else goto fail;\n        }\n        str  { ++count; goto loop; }\n        [ ]+ { goto loop; }\n        *    { goto fail; }\n    */\n\nfail:\n    count = -1;\n\nexit:\n    free(buf);\n    return count;\n}\n\n#define TEST(s, r) assert(lex(s, sizeof(s) - 1) == r)\nint main() {\n    TEST(\"\", 0);\n    TEST(\"'qu\\0tes' 'are' 'fine: \\\\'' \", 3);\n    TEST(\"'unterminated\\\\'\", -1);\n    TEST(\"'unexpected \\0 null\\\\'\", -1);\n    return 0;\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/01_sentinel.re": {
      "content": "// re2c $INPUT -o $OUTPUT\n#include <assert.h>\n\n// Expect a null-terminated string.\nstatic int lex(const char *YYCURSOR) {\n    int count = 0;\n\n    for (;;) {\n    /*!re2c\n        re2c:YYCTYPE = char;\n        re2c:yyfill:enable = 0;\n\n        *      { return -1; }\n        [\\x00] { return count; }\n        [a-z]+ { ++count; continue; }\n        [ ]+   { continue; }\n    */\n    }\n}\n\nint main() {\n    assert(lex(\"\") == 0);\n    assert(lex(\"one two three\") == 3);\n    assert(lex(\"f0ur\") == -1);\n    return 0;\n}\n",
      "extraCommandLineArguments": ""
    },
    "includes/include.re": {
      "content": "// re2c $INPUT -o $OUTPUT -i\n#include <assert.h>\n/*!include:re2c \"definitions.h\" */\n\nResult lex(const char *s) {\n    const char *YYCURSOR = s, *YYMARKER;\n    /*!re2c\n        re2c:YYCTYPE = char;\n        re2c:yyfill:enable = 0;\n\n        *      { return FAIL; }\n        number { return OK; }\n        !include \"extra_rules.re.inc\";\n    */\n}\n\nint main() {\n    assert(lex(\"123\") == OK);\n    assert(lex(\"123.4567\") == OK);\n    return 0;\n}\n",
      "extraCommandLineArguments": "-i"
    },
    "generic_api/ifstream.re": {
      "content": "// re2c $INPUT -o $OUTPUT\n#include <cassert>\n#include <cstdio>\n#include <fstream>\n#include <sstream>\n\nstatic void convert_newlines(std::ifstream &in, std::ostringstream &out) {\n    std::streampos mar;\n    for (;;) {\n    /*!re2c\n        re2c:api = generic;\n        re2c:api:style = free-form;\n        re2c:YYCTYPE = char;\n        re2c:YYPEEK = \"in.peek()\";\n        re2c:YYSKIP = \"{ in.ignore(); if (in.eof()) return; }\";\n        re2c:YYBACKUP = \"mar = in.tellg();\";\n        re2c:YYRESTORE = \"in.seekg(mar);\";\n        re2c:yyfill:enable = 0;\n\n        *      { out.put(yych); continue; }\n        \"\\r\\n\" { out.put('\\n'); continue; }\n    */\n    }\n}\n\nint main() {\n    const char *fname = \"input\";\n    const char s1[] = \"Text\\r\\nwith\\r\\nnewlines.\\r\\n\\r\\n\";\n    const char s2[] = \"Text\\nwith\\nnewlines.\\n\\n\";\n\n    std::ofstream f(fname, std::ios::binary);\n    f.write(s1, sizeof(s1) - 1);\n    f.close();\n\n    std::ifstream in(fname, std::ios::binary);\n    std::ostringstream out;\n    convert_newlines(in, out);\n    assert(out.str() == s2);\n\n    remove(fname);\n    return 0;\n}\n",
      "extraCommandLineArguments": ""
    },
    "encodings/unicode_identifier.re": {
      "content": "// re2c $INPUT -o $OUTPUT -8 --case-ranges -i\n#include <assert.h>\n#include <stdint.h>\n\n/*!include:re2c \"unicode_categories.re\" */\n\nstatic int lex(const char *s) {\n    const char *YYCURSOR = s, *YYMARKER;\n    /*!re2c\n        re2c:YYCTYPE = 'unsigned char';\n        re2c:yyfill:enable = 0;\n\n        // Simplified \"Unicode Identifier and Pattern Syntax\"\n        // (see https://unicode.org/reports/tr31)\n        id_start    = L | Nl | [$_];\n        id_continue = id_start | Mn | Mc | Nd | Pc | [\\u200D\\u05F3];\n        identifier  = id_start id_continue*;\n\n        identifier { return 0; }\n        *          { return 1; }\n    */\n}\n\nint main() {\n    assert(lex(\"_\u042b\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\") == 0);\n    return 0;\n}\n",
      "extraCommandLineArguments": "-8 --case-ranges -i"
    },
    "reuse/braille.re": {
      "content": "// re2c $INPUT -o $OUTPUT -cri\n#include <assert.h>\n#include <ctype.h>\n#include <stdio.h>\n\ntemplate<typename char_t>\nstruct input_t {\n    size_t len;\n    char_t *str;\n\n    input_t(FILE *f) : len(0), str(NULL)\n    {\n        fseek(f, 0, SEEK_END);\n        len = ftell(f) / sizeof(char_t);\n        fseek(f, 0, SEEK_SET);\n        str = new char_t[len + 1];\n        fread(str, sizeof(char_t), len, f);\n        str[len] = 0;\n    }\n    ~input_t() { delete[] str; }\n};\n\ntypedef input_t<unsigned char>  iutf8_t;\ntypedef input_t<unsigned short> iutf16_t;\ntypedef input_t<unsigned int>   iutf32_t;\ntypedef input_t<unsigned short> iucs2_t;\n\nstruct out_t {\n    bool caps;\n\n    out_t() : caps(false) {}\n    void prt(char c)\n    {\n        fprintf(stderr, \"%c\", caps ? toupper(c) : c);\n        caps = false;\n    }\n    void err()\n    {\n        fprintf(stderr, \" ... error\\n\");\n    }\n};\n\n/*!rules:re2c\n    re2c:yyfill:enable = 0;\n    re2c:api:style = free-form;\n    re2c:encoding:utf8 = 1;\n    re2c:YYGETCOND = \"c\";\n    re2c:YYSETCOND = \"c = @@;\";\n\n    // letters\n    l = \"\\u2830\";\n    la = \"\\u2801\"; lb = \"\\u2803\"; lc = \"\\u2809\"; ld = \"\\u2819\"; le = \"\\u2811\";\n    lf = \"\\u280b\"; lg = \"\\u281b\"; lh = \"\\u2813\"; li = \"\\u280a\"; lj = \"\\u281a\";\n    lk = \"\\u2805\"; ll = \"\\u2807\"; lm = \"\\u280d\"; ln = \"\\u281d\"; lo = \"\\u2815\";\n    lp = \"\\u280f\"; lq = \"\\u281f\"; lr = \"\\u2817\"; ls = \"\\u280e\"; lt = \"\\u281e\";\n    lu = \"\\u2825\"; lv = \"\\u2827\"; lw = \"\\u283a\"; lx = \"\\u282d\"; ly = \"\\u283d\";\n    lz = \"\\u2835\";\n\n    // numbers\n    n = \"\\u283c\";\n    n1 = \"\\u2801\"; n2 = \"\\u2803\"; n3 = \"\\u2809\"; n4 = \"\\u2819\"; n5 = \"\\u2811\";\n    n6 = \"\\u280b\"; n7 = \"\\u281b\"; n8 = \"\\u2813\"; n9 = \"\\u280a\"; n0 = \"\\u281a\";\n\n    // punctuation\n    pcom = \"\\u2802\"; psem = \"\\u2806\"; pcln = \"\\u2812\";\n    pdot = \"\\u2832\"; pxcl = \"\\u2816\"; pqst = \"\\u2826\";\n    past = \"\\u2814\"; pdsh = \"\\u2804\"; phyp = \"\\u2824\";\n\n    // formatting\n    fcp = \"\\u2820\"; fsp = \"\\u2800\" | \"\\x20\"; fnl = \"\\n\" | \"\\n\\r\";\n\n    <*> *      { out.err(); return; }\n    <*> \"\\x00\" { if (YYCURSOR != in.str + in.len + 1) out.err(); return; }\n\n    <*> l :=> l\n    <l> la { out.prt('a'); goto yyc_l; }\n    <l> lb { out.prt('b'); goto yyc_l; }\n    <l> lc { out.prt('c'); goto yyc_l; }\n    <l> ld { out.prt('d'); goto yyc_l; }\n    <l> le { out.prt('e'); goto yyc_l; }\n    <l> lf { out.prt('f'); goto yyc_l; }\n    <l> lg { out.prt('g'); goto yyc_l; }\n    <l> lh { out.prt('h'); goto yyc_l; }\n    <l> li { out.prt('i'); goto yyc_l; }\n    <l> lj { out.prt('j'); goto yyc_l; }\n    <l> lk { out.prt('k'); goto yyc_l; }\n    <l> ll { out.prt('l'); goto yyc_l; }\n    <l> lm { out.prt('m'); goto yyc_l; }\n    <l> ln { out.prt('n'); goto yyc_l; }\n    <l> lo { out.prt('o'); goto yyc_l; }\n    <l> lp { out.prt('p'); goto yyc_l; }\n    <l> lq { out.prt('q'); goto yyc_l; }\n    <l> lr { out.prt('r'); goto yyc_l; }\n    <l> ls { out.prt('s'); goto yyc_l; }\n    <l> lt { out.prt('t'); goto yyc_l; }\n    <l> lu { out.prt('u'); goto yyc_l; }\n    <l> lv { out.prt('v'); goto yyc_l; }\n    <l> lw { out.prt('w'); goto yyc_l; }\n    <l> lx { out.prt('x'); goto yyc_l; }\n    <l> ly { out.prt('y'); goto yyc_l; }\n    <l> lz { out.prt('z'); goto yyc_l; }\n\n    <*> n :=> n\n    <n> n1 { out.prt('1'); goto yyc_n; }\n    <n> n2 { out.prt('2'); goto yyc_n; }\n    <n> n3 { out.prt('3'); goto yyc_n; }\n    <n> n4 { out.prt('4'); goto yyc_n; }\n    <n> n5 { out.prt('5'); goto yyc_n; }\n    <n> n6 { out.prt('6'); goto yyc_n; }\n    <n> n7 { out.prt('7'); goto yyc_n; }\n    <n> n8 { out.prt('8'); goto yyc_n; }\n    <n> n9 { out.prt('9'); goto yyc_n; }\n    <n> n0 { out.prt('0'); goto yyc_n; }\n\n    <*> pcom { out.prt(','); goto yyc_l; }\n    <*> psem { out.prt(';'); goto yyc_l; }\n    <*> pcln { out.prt(':'); goto yyc_l; }\n    <*> pdot { out.prt('.'); goto yyc_l; }\n    <*> pxcl { out.prt('!'); goto yyc_l; }\n    <*> pqst { out.prt('?'); goto yyc_l; }\n    <*> past { out.prt('*'); goto yyc_l; }\n    <*> pdsh { out.prt('\\''); goto yyc_l; }\n    <*> phyp { out.prt('-'); goto yyc_l; }\n\n    <*> fcp { out.caps = true; goto yyc_l; }\n    <*> fsp { out.prt(' '); goto yyc_l; }\n    <*> fnl { out.prt('\\n'); goto yyc_l; }\n*/\n\n/*!types:re2c*/\n\nstatic void lex_utf8(const iutf8_t & in)\n{\n    const unsigned char *YYCURSOR = in.str, *YYMARKER;\n    int c = yycl;\n    out_t out;\n    /*!use:re2c\n        re2c:YYCTYPE = \"unsigned char\";\n        re2c:encoding:utf8 = 1;\n    */\n}\n\nstatic void lex_utf16(const iutf16_t & in)\n{\n    const unsigned short *YYCURSOR = in.str;\n    int c = yycl;\n    out_t out;\n    /*!use:re2c\n        re2c:YYCTYPE = \"unsigned int\";\n        re2c:encoding:utf16 = 1;\n    */\n}\n\nstatic void lex_utf32(const iutf32_t & in)\n{\n    const unsigned int *YYCURSOR = in.str;\n    int c = yycl;\n    out_t out;\n    /*!use:re2c\n        re2c:YYCTYPE = \"unsigned int\";\n        re2c:encoding:utf32 = 1;\n    */\n}\n\nstatic void lex_ucs2(const iucs2_t & in)\n{\n    const unsigned short *YYCURSOR = in.str;\n    int c = yycl;\n    out_t out;\n    /*!use:re2c\n        re2c:YYCTYPE = \"unsigned int\";\n        re2c:encoding:ucs2 = 1;\n    */\n}\n\nint main()\n{\n    FILE *f;\n\n    assert(f = fopen(\"braille.utf8.txt\", \"rb\"));\n    fprintf(stderr, \"utf8:\\n\");\n    iutf8_t in8(f);\n    lex_utf8(in8);\n    fclose(f);\n\n    assert(f = fopen(\"braille.utf16.txt\", \"rb\"));\n    fprintf(stderr, \"utf16:\\n\");\n    iutf16_t in16(f);\n    lex_utf16(in16);\n    fclose(f);\n\n    assert(f = fopen(\"braille.utf32.txt\", \"rb\"));\n    fprintf(stderr, \"utf32:\\n\");\n    iutf32_t in32(f);\n    lex_utf32(in32);\n    fclose(f);\n\n    assert(f = fopen(\"braille.ucs2.txt\", \"rb\"));\n    fprintf(stderr, \"ucs2:\\n\");\n    iucs2_t in2(f);\n    lex_ucs2(in2);\n    fclose(f);\n\n    return 0;\n}\n",
      "extraCommandLineArguments": "-cri"
    },
    "reuse/reuse.re": {
      "content": "// re2c $INPUT -o $OUTPUT --input-encoding utf8\n#include <assert.h>\n#include <stdint.h>\n\n// This example supports multiple input encodings: UTF-8 and UTF-32.\n// Both lexers are generated from the same rules block, and the use\n// blocks add only encoding-specific configurations.\n/*!rules:re2c\n    re2c:yyfill:enable = 0;\n\n    \"\u2200x \u2203y\" { return 0; }\n    *       { return 1; }\n*/\n\nstatic int lex_utf8(const uint8_t *s) {\n    const uint8_t *YYCURSOR = s, *YYMARKER;\n    /*!use:re2c\n        re2c:YYCTYPE = uint8_t;\n        re2c:encoding:utf8 = 1;\n    */\n}\n\nstatic int lex_utf32(const uint32_t *s) {\n    const uint32_t *YYCURSOR = s, *YYMARKER;\n    /*!use:re2c\n        re2c:YYCTYPE = uint32_t;\n        re2c:encoding:utf32 = 1;\n    */\n}\n\nint main() {\n    static const uint8_t s8[] = // UTF-8\n        { 0xe2, 0x88, 0x80, 0x78, 0x20, 0xe2, 0x88, 0x83, 0x79 };\n\n    static const uint32_t s32[] = // UTF32\n        { 0x00002200, 0x00000078, 0x00000020, 0x00002203, 0x00000079 };\n\n    assert(lex_utf8(s8) == 0);\n    assert(lex_utf32(s32) == 0);\n    return 0;\n}\n\n",
      "extraCommandLineArguments": "--input-encoding utf8"
    },
    "reuse/usedir.re": {
      "content": "// re2c $INPUT -o $OUTPUT\n#include <assert.h>\n\n// This example shows how to combine reusable re2c blocks: two blocks\n// ('colors' and 'fish') are merged into one. The 'salmon' rule occurs\n// in both blocks; the 'fish' block takes priority because it is used\n// earlier. Default rule * occurs in all three blocks; the local (not\n// inherited) definition takes priority.\n\nenum What { COLOR, FISH, DUNNO };\n\n/*!rules:re2c:colors\n    *                            { assert(false); }\n    \"red\" | \"salmon\" | \"magenta\" { return COLOR; }\n*/\n\n/*!rules:re2c:fish\n    *                            { assert(false); }\n    \"haddock\" | \"salmon\" | \"eel\" { return FISH; }\n*/\n\nstatic What lex(const char *s) {\n    const char *YYCURSOR = s, *YYMARKER;\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:YYCTYPE = char;\n\n        !use:fish;\n        !use:colors;\n        * { return DUNNO; }  // overrides inherited '*' rules\n    */\n}\n\nint main() {\n    assert(lex(\"salmon\") == FISH);\n    assert(lex(\"what?\") == DUNNO);\n    return 0;\n}\n",
      "extraCommandLineArguments": ""
    },
    "headers/header.re": {
      "content": "// re2c $INPUT -o $OUTPUT -i --header lexer/state.h\n#include <assert.h>\n#include <stddef.h>\n#include \"lexer/state.h\" // the header is generated by re2c\n\n/*!header:re2c:on*/\nstruct LexerState {\n    const char *str, *yycursor;\n    /*!stags:re2c format = \"const char *@@;\"; */\n};\n/*!header:re2c:off*/\n\nlong lex(LexerState* yyrecord) {\n    const char *t;\n    /*!re2c\n        re2c:header = \"lexer/state.h\";\n        re2c:api = record;\n        re2c:yyfill:enable = 0;\n        re2c:YYCTYPE = char;\n        re2c:tags = 1;\n\n        [a]* @t [b]* { return t - yyrecord->str; }\n    */\n}\n\nint main() {\n    const char *s = \"ab\";\n    LexerState st = { s, s /*!stags:re2c format = \", NULL\"; */ };\n    assert(lex(&st) == 1);\n    return 0;\n}\n",
      "extraCommandLineArguments": "-i --header lexer/state.h"
    }
  },
  "rust": {
    "01_basic.re": {
      "content": "// re2rust $INPUT -o $OUTPUT --no-unsafe --api simple\n\nfn lex(yyinput: &[u8]) -> bool {\n    let mut yycursor = 0;\n    /*!re2c\n        re2c:YYCTYPE = u8;\n        re2c:yyfill:enable = 0;\n\n        [1-9][0-9]* { return true; }\n        *           { return false; }\n    */\n}\n\nfn main() {\n    assert!(lex(b\"1234\\0\"));\n}\n",
      "extraCommandLineArguments": "--no-unsafe --api simple"
    },
    "fill/01_fill.re": {
      "content": "// re2rust $INPUT -o $OUTPUT\n\nuse std::fs::File;\nuse std::io::{Read, Write};\n\nconst BUFSIZE: usize = 4096;\n\nstruct State {\n    file: File,\n    yyinput: [u8; BUFSIZE],\n    yylimit: usize,\n    yycursor: usize,\n    yymarker: usize,\n    token: usize,\n    eof: bool,\n}\n\n#[derive(PartialEq)]\nenum Fill { Ok, Eof, LongLexeme }\n\nfn fill(st: &mut State) -> Fill {\n    if st.eof { return Fill::Eof; }\n\n    // Error: lexeme too long. In real life could reallocate a larger buffer.\n    if st.token < 1 { return Fill::LongLexeme; }\n\n    // Shift buffer contents (discard everything up to the current token).\n    st.yyinput.copy_within(st.token..st.yylimit, 0);\n    st.yylimit -= st.token;\n    st.yycursor -= st.token;\n    st.yymarker = st.yymarker.overflowing_sub(st.token).0; // may underflow if marker is unused\n    st.token = 0;\n\n    // Fill free space at the end of buffer with new data from file.\n    match st.file.read(&mut st.yyinput[st.yylimit..BUFSIZE - 1]) { // -1 for sentinel\n        Ok(n) => {\n            st.yylimit += n;\n            st.eof = n == 0; // end of file\n            st.yyinput[st.yylimit] = 0; // append sentinel\n        }\n        Err(why) => panic!(\"cannot read from file: {}\", why)\n    }\n\n    return Fill::Ok;\n}\n\nfn lex(yyrecord: &mut State) -> isize {\n    let mut count: isize = 0;\n\n    'lex: loop {\n        yyrecord.token = yyrecord.yycursor;\n    /*!re2c\n        re2c:api = record;\n        re2c:YYCTYPE = u8;\n        re2c:YYFILL = \"fill(yyrecord) == Fill::Ok\";\n        re2c:eof = 0;\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        *    { return -1; }\n        $    { return count; }\n        str  { count += 1; continue 'lex; }\n        [ ]+ { continue 'lex; }\n    */}\n}\n\nfn main() {\n    let fname = \"input\";\n    let content = b\"'qu\\0tes' 'are' 'fine: \\\\'' \";\n\n    // Prepare input file: a few times the size of the buffer, containing\n    // strings with zeroes and escaped quotes.\n    match File::create(fname) {\n        Err(why) => panic!(\"cannot open {}: {}\", fname, why),\n        Ok(mut file) => match file.write_all(&content.repeat(BUFSIZE)) {\n            Err(why) => panic!(\"cannot write to {}: {}\", fname, why),\n            Ok(_) => {}\n        }\n    };\n    let count = 3 * BUFSIZE; // number of quoted strings written to file\n\n    // Reopen input file for reading.\n    let file = match File::open(fname) {\n        Err(why) => panic!(\"cannot read file {}: {}\", fname, why),\n        Ok(file) => file,\n    };\n\n    // Initialize lexer state: all offsets are at the end of buffer.\n    let yylimit = BUFSIZE - 1;\n    let mut st = State {\n        file: file,\n        // Sentinel (at `yylimit` offset) is set to null, which triggers YYFILL.\n        yyinput: [0; BUFSIZE],\n        yylimit: yylimit,\n        yycursor: yylimit,\n        yymarker: yylimit,\n        token: yylimit,\n        eof: false,\n    };\n\n    // Run the lexer.\n    assert_eq!(lex(&mut st), count as isize);\n\n    // Cleanup: remove input file.\n    match std::fs::remove_file(fname) {\n        Err(why) => panic!(\"cannot remove {}: {}\", fname, why),\n        Ok(_) => {}\n    }\n}\n",
      "extraCommandLineArguments": ""
    },
    "fill/02_fill.re": {
      "content": "// re2rust $INPUT -o $OUTPUT\n\nuse std::fs::File;\nuse std::io::{Read, Write};\n\n/*!max:re2c*/\nconst BUFSIZE: usize = 4096;\n\nstruct State {\n    file: File,\n    yyinput: [u8; BUFSIZE],\n    yylimit: usize,\n    yycursor: usize,\n    yymarker: usize,\n    token: usize,\n    eof: bool,\n}\n\n#[derive(PartialEq)]\nenum Fill { Ok, Eof, LongLexeme }\n\nfn fill(st: &mut State, need: usize) -> Fill {\n    if st.eof { return Fill::Eof; }\n\n    // Error: lexeme too long. In real life can reallocate a larger buffer.\n    if st.token < need { return Fill::LongLexeme; }\n\n    // Shift buffer contents (discard everything up to the current token).\n    st.yyinput.copy_within(st.token..st.yylimit, 0);\n    st.yylimit -= st.token;\n    st.yycursor -= st.token;\n    st.yymarker = st.yymarker.overflowing_sub(st.token).0; // underflows if marker is unused\n    st.token = 0;\n\n    // Fill free space at the end of buffer with new data from file.\n    let n = match st.file.read(&mut st.yyinput[st.yylimit..BUFSIZE - YYMAXFILL]) {\n        Ok(n) => n,\n        Err(why) => panic!(\"cannot read from file: {}\", why)\n    };\n    st.yylimit += n;\n\n    // If read zero characters, this is end of input => add zero padding\n    // so that the lexer can access characters at the end of buffer.\n    if n == 0 {\n        st.eof = true;\n        for i in 0..YYMAXFILL { st.yyinput[st.yylimit + i] = 0; }\n        st.yylimit += YYMAXFILL;\n    }\n\n    return Fill::Ok;\n}\n\nfn lex(yyrecord: &mut State) -> isize {\n    let mut count: isize = 0;\n\n    'lex: loop {\n        yyrecord.token = yyrecord.yycursor;\n    /*!re2c\n        re2c:api = record;\n        re2c:YYCTYPE = u8;\n        re2c:YYFILL = \"if fill(yyrecord, @@) != Fill::Ok { return -1; }\";\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        [\\x00] {\n            // Check that it is the sentinel, not some unexpected null.\n            return if yyrecord.token == yyrecord.yylimit - YYMAXFILL { count } else { -1 }\n        }\n        str  { count += 1; continue 'lex; }\n        [ ]+ { continue 'lex; }\n        *    { return -1; }\n    */}\n}\n\nfn main() {\n    let fname = \"input\";\n    let content = b\"'qu\\0tes' 'are' 'fine: \\\\'' \";\n\n    // Prepare input file: a few times the size of the buffer, containing\n    // strings with zeroes and escaped quotes.\n    match File::create(fname) {\n        Err(why) => panic!(\"cannot open {}: {}\", fname, why),\n        Ok(mut file) => match file.write_all(&content.repeat(BUFSIZE)) {\n            Err(why) => panic!(\"cannot write to {}: {}\", fname, why),\n            Ok(_) => {}\n        }\n    };\n    let count = 3 * BUFSIZE; // number of quoted strings written to file\n\n    // Reopen input file for reading.\n    let file = match File::open(fname) {\n        Err(why) => panic!(\"cannot read file {}: {}\", fname, why),\n        Ok(file) => file,\n    };\n\n    // Initialize lexer state: all offsets are at the end of buffer.\n    // This immediately triggers YYFILL, as the YYLESSTHAN condition is true.\n    let yylimit = BUFSIZE - YYMAXFILL;\n    let mut st = State {\n        file: file,\n        yyinput: [0; BUFSIZE],\n        yylimit: yylimit,\n        yycursor: yylimit,\n        yymarker: yylimit,\n        token: yylimit,\n        eof: false,\n    };\n\n    // Run the lexer.\n    assert_eq!(lex(&mut st), count as isize);\n\n    // Cleanup: remove input file.\n    match std::fs::remove_file(fname) {\n        Err(why) => panic!(\"cannot remove {}: {}\", fname, why),\n        Ok(_) => {}\n    }\n}\n",
      "extraCommandLineArguments": ""
    },
    "conditions/parse_u32_conditions.re": {
      "content": "// re2rust $INPUT -o $OUTPUT -c --api simple\n\n/*!conditions:re2c*/\n\nconst ERROR: u64 = std::u32::MAX as u64 + 1; // overflow\n\n// Add digit with the given base, checking for overflow.\nfn add(num: &mut u64, str: &[u8], cur: usize, offs: u8, base: u64) {\n    let digit = unsafe { str.get_unchecked(cur - 1) } - offs;\n    *num = std::cmp::min(*num * base + digit as u64, ERROR);\n}\n\nfn parse_u32(yyinput: &[u8]) -> Option<u32> {\n    assert_eq!(yyinput.last(), Some(&0)); // expect null-terminated input\n\n    let (mut yycursor, mut yymarker) = (0, 0);\n    let mut yycond = YYC_INIT;\n    let mut num = 0u64; // Store number in u64 to simplify overflow checks.\n\n    'lex: loop { /*!re2c\n        re2c:YYCTYPE = u8;\n        re2c:yyfill:enable = 0;\n\n        <INIT> '0b' / [01]        :=> BIN\n        <INIT> \"0\"                :=> OCT\n        <INIT> \"\" / [1-9]         :=> DEC\n        <INIT> '0x' / [0-9a-fA-F] :=> HEX\n        <INIT> * { return None; }\n\n        <BIN> [01]  { add(&mut num, yyinput, yycursor, 48, 2);  continue 'lex; }\n        <OCT> [0-7] { add(&mut num, yyinput, yycursor, 48, 8);  continue 'lex; }\n        <DEC> [0-9] { add(&mut num, yyinput, yycursor, 48, 10); continue 'lex; }\n        <HEX> [0-9] { add(&mut num, yyinput, yycursor, 48, 16); continue 'lex; }\n        <HEX> [a-f] { add(&mut num, yyinput, yycursor, 87, 16); continue 'lex; }\n        <HEX> [A-F] { add(&mut num, yyinput, yycursor, 55, 16); continue 'lex; }\n\n        <BIN, OCT, DEC, HEX> * {\n            return if num < ERROR { Some(num as u32) } else { None };\n        }\n    */}\n}\n\nfn main() {\n    assert_eq!(parse_u32(b\"\\0\"), None);\n    assert_eq!(parse_u32(b\"1234567890\\0\"), Some(1234567890));\n    assert_eq!(parse_u32(b\"0b1101\\0\"), Some(13));\n    assert_eq!(parse_u32(b\"0x7Fe\\0\"), Some(2046));\n    assert_eq!(parse_u32(b\"0644\\0\"), Some(420));\n    assert_eq!(parse_u32(b\"9999999999\\0\"), None);\n}\n",
      "extraCommandLineArguments": "-c --api simple"
    },
    "conditions/parse_u32_blocks.re": {
      "content": "// re2rust $INPUT -o $OUTPUT\n\n// Store u32 number in u64 during parsing to simplify overflow hadling.\nstruct State<'a> {\n    yyinput: &'a [u8],\n    yycursor: usize,\n    yymarker: usize,\n    num: u64,\n}\n\n/*!re2c // Common re2c definitions shared between all functions.\n    re2c:api = record;\n    re2c:yyrecord = st;\n    re2c:yyfill:enable = 0;\n    re2c:YYCTYPE = u8;\n*/\n\nconst ERROR: u64 = std::u32::MAX as u64 + 1; // overflow\n\nmacro_rules! maybe { // Convert the number from u64 to optional u32.\n    ($n:expr) => { if $n < ERROR { Some($n as u32) } else { None } }\n}\n\n// Add digit with the given base, checking for overflow.\nfn add(st: &mut State, offs: u8, base: u64) {\n    let digit = unsafe { st.yyinput.get_unchecked(st.yycursor - 1) } - offs;\n    st.num = std::cmp::min(st.num * base + digit as u64, ERROR);\n}\n\nfn parse_u32(s: & [u8]) -> Option<u32> {\n    assert_eq!(s.last(), Some(&0)); // expect null-terminated input\n\n    let mut st = State {yyinput: s, yycursor: 0, yymarker: 0, num: 0};\n/*!re2c\n    '0b' / [01]        { return parse_bin(&mut st); }\n    \"0\"                { return parse_oct(&mut st); }\n    \"\" / [1-9]         { return parse_dec(&mut st); }\n    '0x' / [0-9a-fA-F] { return parse_hex(&mut st); }\n    *                  { return None; }\n*/\n}\n\nfn parse_bin(st: &mut State) -> Option<u32> {\n    'bin: loop {/*!re2c\n        [01] { add(st, 48, 2); continue 'bin; }\n        *    { return maybe!(st.num); }\n    */}\n}\n\nfn parse_oct(st: &mut State) -> Option<u32> {\n    'oct: loop {/*!re2c\n        [0-7] { add(st, 48, 8); continue 'oct; }\n        *     { return maybe!(st.num); }\n    */}\n}\n\nfn parse_dec(st: &mut State) -> Option<u32> {\n    'dec: loop {/*!re2c\n        [0-9] { add(st, 48, 10); continue 'dec; }\n        *     { return maybe!(st.num); }\n    */}\n}\n\nfn parse_hex(st: &mut State) -> Option<u32> {\n    'hex: loop {/*!re2c\n        [0-9] { add(st, 48, 16); continue 'hex; }\n        [a-f] { add(st, 87, 16); continue 'hex; }\n        [A-F] { add(st, 55, 16); continue 'hex; }\n        *     { return maybe!(st.num); }\n    */}\n}\n\nfn main() {\n    assert_eq!(parse_u32(b\"\\0\"), None);\n    assert_eq!(parse_u32(b\"1234567890\\0\"), Some(1234567890));\n    assert_eq!(parse_u32(b\"0b1101\\0\"), Some(13));\n    assert_eq!(parse_u32(b\"0x7Fe\\0\"), Some(2046));\n    assert_eq!(parse_u32(b\"0644\\0\"), Some(420));\n    assert_eq!(parse_u32(b\"9999999999\\0\"), None);\n}\n",
      "extraCommandLineArguments": ""
    },
    "state/push.re": {
      "content": "// re2rust $INPUT -o $OUTPUT -f\n\nuse std::fs::File;\nuse std::io::{Read, Write};\n\nconst DEBUG: bool = false;\nmacro_rules! log {\n    ($($fmt:expr)? $(, $args:expr)*) => {\n        if DEBUG { println!($($fmt)? $(, $args)*) }\n    }\n}\n\n// Use a small buffer to cover the case when a lexeme doesn't fit.\n// In real world use a larger buffer.\nconst BUFSIZE: usize = 10;\n\nstruct State {\n    file: File,\n    yyinput: [u8; BUFSIZE],\n    yylimit: usize,\n    yycursor: usize,\n    yymarker: usize,\n    token: usize,\n    yystate: isize,\n}\n\n#[derive(Debug, PartialEq)]\nenum Status {End, Ready, Waiting, BadPacket, BigPacket}\n\nfn fill(st: &mut State) -> Status {\n    // Error: lexeme too long. In real life can reallocate a larger buffer.\n    if st.token < 1 { return Status::BigPacket; }\n\n    // Shift buffer contents (discard everything up to the current lexeme).\n    st.yyinput.copy_within(st.token..st.yylimit, 0);\n    st.yylimit -= st.token;\n    st.yycursor -= st.token;\n    st.yymarker = st.yymarker.overflowing_sub(st.token).0; // underflows if marker is unused\n    st.token = 0;\n\n    // Fill free space at the end of buffer with new data.\n    match st.file.read(&mut st.yyinput[st.yylimit..BUFSIZE - 1]) { // -1 for sentinel\n        Ok(n) => {\n            st.yylimit += n;\n            st.yyinput[st.yylimit] = 0; // append sentinel symbol\n        },\n        Err(why) => panic!(\"cannot read from file: {}\", why)\n    }\n\n    return Status::Ready;\n}\n\nfn lex(yyrecord: &mut State, recv: &mut usize) -> Status {\n    let mut yych;\n    'lex: loop {\n        yyrecord.token = yyrecord.yycursor;\n    /*!re2c\n        re2c:api = record;\n        re2c:eof = 0;\n        re2c:YYCTYPE = \"u8\";\n        re2c:YYFILL = \"return Status::Waiting;\";\n\n        packet = [a-z]+[;];\n\n        *      { return Status::BadPacket; }\n        $      { return Status::End; }\n        packet { *recv += 1; continue 'lex; }\n    */}\n}\n\nfn test(packets: Vec<&[u8]>, expect: Status) {\n    // Create a pipe (open the same file for reading and writing).\n    let fname = \"pipe\";\n    let mut fw: File = match File::create(fname) {\n        Err(why) => panic!(\"cannot open {}: {}\", fname, why),\n        Ok(file) => file,\n    };\n    let fr: File = match File::open(fname) {\n        Err(why) => panic!(\"cannot read file {}: {}\", fname, why),\n        Ok(file) => file,\n    };\n\n    // Initialize lexer state: `state` value is -1, all offsets are at the end\n    // of buffer, the character at `yylimit` offset is the sentinel (null).\n    let yylimit = BUFSIZE - 1;\n    let mut state = State {\n        file: fr,\n        // Sentinel (at `yylimit` offset) is set to null, which triggers YYFILL.\n        yyinput: [0; BUFSIZE],\n        yylimit: yylimit,\n        yycursor: yylimit,\n        yymarker: yylimit,\n        token: yylimit,\n        yystate: -1,\n    };\n\n    // Main loop. The buffer contains incomplete data which appears packet by\n    // packet. When the lexer needs more input it saves its internal state and\n    // returns to the caller which should provide more input and resume lexing.\n    let mut status;\n    let mut send = 0;\n    let mut recv = 0;\n    loop {\n        status = lex(&mut state, &mut recv);\n        if status == Status::End {\n            log!(\"done: got {} packets\", recv);\n            break;\n        } else if status == Status::Waiting {\n            log!(\"waiting...\");\n            if send < packets.len() {\n                log!(\"sent packet {}\", send);\n                match fw.write_all(packets[send]) {\n                    Err(why) => panic!(\"cannot write to {}: {}\", fname, why),\n                    Ok(_) => send += 1,\n                }\n            }\n            status = fill(&mut state);\n            log!(\"queue: '{}'\", String::from_utf8_lossy(&state.yyinput));\n            if status == Status::BigPacket {\n                log!(\"error: packet too big\");\n                break;\n            }\n            assert_eq!(status, Status::Ready);\n        } else {\n            assert_eq!(status, Status::BadPacket);\n            log!(\"error: ill-formed packet\");\n            break;\n        }\n    }\n\n    // Check results.\n    assert_eq!(status, expect);\n    if status == Status::End { assert_eq!(recv, send); }\n\n    // Cleanup: remove input file.\n    match std::fs::remove_file(fname) {\n        Err(why) => panic!(\"cannot remove {}: {}\", fname, why),\n        Ok(_) => {}\n    }\n}\n\nfn main() {\n    test(vec![], Status::End);\n    test(vec![b\"zero;\", b\"one;\", b\"two;\", b\"three;\", b\"four;\"], Status::End);\n    test(vec![b\"zer0;\"], Status::BadPacket);\n    test(vec![b\"goooooooooogle;\"], Status::BigPacket);\n}\n",
      "extraCommandLineArguments": "-f"
    },
    "submatch/02_mtags.re": {
      "content": "// re2rust $INPUT -o $OUTPUT --api simple\n\nconst NONE: usize = std::usize::MAX;\nconst MTAG_ROOT: usize = NONE - 1;\n\n// An m-tag tree is a way to store histories with an O(1) copy operation.\n// Histories naturally form a tree, as they have common start and fork at some\n// point. The tree is stored as an array of pairs (tag value, link to parent).\n// An m-tag is represented with a single link in the tree (array index).\ntype MtagTrie = Vec::<MtagElem>;\nstruct MtagElem {\n    elem: usize, // tag value\n    pred: usize, // index of the predecessor node or root\n}\n\n// Append a single value to an m-tag history.\nfn add_mtag(trie: &mut MtagTrie, mtag: usize, value: usize) -> usize {\n    trie.push(MtagElem{elem: value, pred: mtag});\n    return trie.len() - 1;\n}\n\n// Recursively unwind tag histories and collect version components.\nfn unwind(trie: &MtagTrie, x: usize, y: usize, str: &[u8], ver: &mut Ver) {\n    // Reached the root of the m-tag tree, stop recursion.\n    if x == MTAG_ROOT && y == MTAG_ROOT { return; }\n\n    // Unwind history further.\n    unwind(trie, trie[x].pred, trie[y].pred, str, ver);\n\n    // Get tag values. Tag histories must have equal length.\n    assert!(x != MTAG_ROOT && y != MTAG_ROOT);\n    let (ex, ey) = (trie[x].elem, trie[y].elem);\n\n    if ex != NONE && ey != NONE {\n        // Both tags are valid string indices, extract component.\n        ver.push(s2n(&str[ex..ey]));\n    } else {\n        // Both tags are NONE (this corresponds to zero repetitions).\n        assert!(ex == NONE && ey == NONE);\n    }\n}\n\ntype Ver = Vec::<u32>; // unbounded number of version components\n\nfn s2n(str: &[u8]) -> u32 { // convert a pre-parsed string to a number\n    let mut n = 0;\n    for i in str { n = n * 10 + *i as u32 - 48; }\n    return n;\n}\n\nfn parse(yyinput: &[u8]) -> Option<Ver> {\n    assert_eq!(yyinput.last(), Some(&0)); // expect null-terminated input\n\n    let (mut yycursor, mut yymarker) = (0, 0);\n    let mut mt: MtagTrie = Vec::new();\n\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = 'let @@;\\n'; */\n    /*!mvars:re2c format = 'let @@;\\n'; */\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = 'let mut @@ = NONE;'; */\n    /*!mtags:re2c format = 'let mut @@ = MTAG_ROOT;'; */\n\n    /*!re2c\n        re2c:YYCTYPE = u8;\n        re2c:YYMTAGP = \"@@ = add_mtag(&mut mt, @@, yycursor);\";\n        re2c:YYMTAGN = \"@@ = add_mtag(&mut mt, @@, NONE);\";\n        re2c:yyfill:enable = 0;\n        re2c:tags = 1;\n\n        num = [0-9]+;\n\n        @t1 num @t2 (\".\" #t3 num #t4)* [\\x00] {\n            let mut ver: Ver = Vec::new();\n            ver.push(s2n(&yyinput[t1..t2]));\n            unwind(&mt, t3, t4, yyinput, &mut ver);\n            return Some(ver);\n        }\n        * { return None; }\n    */\n}\n\nfn main() {\n    assert_eq!(parse(b\"1\\0\"), Some(vec![1]));\n    assert_eq!(parse(b\"1.2.3.4.5.6.7\\0\"), Some(vec![1, 2, 3, 4, 5, 6, 7]));\n    assert_eq!(parse(b\"1.2.\\0\"), None);\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "submatch/04_posix_captures.re": {
      "content": "// re2rust $INPUT -o $OUTPUT --api simple\n\n// Maximum number of capturing groups among all rules.\n/*!maxnmatch:re2c*/\n\n#[derive(Debug, PartialEq)]\nstruct SemVer(u32, u32, u32); // version: (major, minor, patch)\n\nconst NONE: usize = std::usize::MAX;\n\nfn s2n(str: &[u8]) -> u32 { // convert a pre-parsed string to a number\n    let mut n = 0;\n    for i in str { n = n * 10 + *i as u32 - 48; }\n    return n;\n}\n\nfn parse(yyinput: &[u8]) -> Option<SemVer> {\n    assert_eq!(yyinput.last(), Some(&0)); // expect null-terminated input\n\n    let (mut yycursor, mut yymarker) = (0, 0);\n\n    // Allocate memory for capturing parentheses (twice the number of groups).\n    let yynmatch: usize;\n    let mut yypmatch = [0; YYMAXNMATCH*2];\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = 'let mut @@ = NONE;'; */\n\n    /*!re2c\n        re2c:YYCTYPE = u8;\n        re2c:yyfill:enable = 0;\n        re2c:posix-captures = 1;\n\n        num = [0-9]+;\n\n        (num) \".\" (num) (\".\" num)? [\\x00] {\n            // `yynmatch` is the number of capturing groups\n            assert_eq!(yynmatch, 4);\n\n            // Even `yypmatch` values are for opening parentheses, odd values\n            // are for closing parentheses, the first group is the whole match.\n            let major = s2n(&yyinput[yypmatch[2]..yypmatch[3]]);\n            let minor = s2n(&yyinput[yypmatch[4]..yypmatch[5]]);\n            let patch = if yypmatch[6] == NONE {0}\n                else {s2n(&yyinput[yypmatch[6] + 1..yypmatch[7]])};\n\n            return Some(SemVer(major, minor, patch));\n        }\n        * { return None; }\n    */\n}\n\nfn main() {\n    assert_eq!(parse(b\"23.34\\0\"), Some(SemVer(23, 34, 0)));\n    assert_eq!(parse(b\"1.2.99999\\0\"), Some(SemVer(1, 2, 99999)));\n    assert_eq!(parse(b\"1.a\\0\"), None);\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "submatch/01_stags.re": {
      "content": "// re2rust $INPUT -o $OUTPUT --api simple\n\n#[derive(Debug, PartialEq)]\nstruct SemVer(u32, u32, u32); // version: (major, minor, patch)\n\nconst NONE: usize = std::usize::MAX;\n\nfn s2n(str: &[u8]) -> u32 { // convert a pre-parsed string to a number\n    let mut n = 0;\n    for i in str { n = n * 10 + *i as u32 - 48; }\n    return n;\n}\n\nfn parse(yyinput: &[u8]) -> Option<SemVer> {\n    assert_eq!(yyinput.last(), Some(&0)); // expect null-terminated input\n\n    let (mut yycursor, mut yymarker) = (0, 0);\n\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = '#[allow(unused_mut)]\\nlet mut @@;\\n'; */\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = 'let mut @@ = NONE;'; */\n\n    /*!re2c\n        re2c:YYCTYPE = u8;\n        re2c:yyfill:enable = 0;\n        re2c:tags = 1;\n\n        num = [0-9]+;\n\n        @t1 num @t2 \".\" @t3 num @t4 (\".\" @t5 num)? [\\x00] {\n            let major = s2n(&yyinput[t1..t2]);\n            let minor = s2n(&yyinput[t3..t4]);\n            let patch = if t5 != NONE {s2n(&yyinput[t5..yycursor - 1])} else {0};\n            return Some(SemVer(major, minor, patch));\n        }\n        * { return None; }\n    */\n}\n\nfn main() {\n    assert_eq!(parse(b\"23.34\\0\"), Some(SemVer(23, 34, 0)));\n    assert_eq!(parse(b\"1.2.99999\\0\"), Some(SemVer(1, 2, 99999)));\n    assert_eq!(parse(b\"1.a\\0\"), None);\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "submatch/03_captures.re": {
      "content": "// re2rust $INPUT -o $OUTPUT --api simple\n\n#[derive(Debug, PartialEq)]\nstruct SemVer(u32, u32, u32); // version: (major, minor, patch)\n\nconst NONE: usize = std::usize::MAX;\n\nfn s2n(str: &[u8]) -> u32 { // convert a pre-parsed string to a number\n    let mut n = 0;\n    for i in str { n = n * 10 + *i as u32 - 48; }\n    return n;\n}\n\nfn parse(yyinput: &[u8]) -> Option<SemVer> {\n    assert_eq!(yyinput.last(), Some(&0)); // expect null-terminated input\n\n    let (mut yycursor, mut yymarker) = (0, 0);\n\n    // Final tag variables available in semantic action.\n    /*!stags:re2c format = 'let mut @@ = NONE;'; */\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!svars:re2c format = '#[allow(unused_mut)]\\nlet mut @@;\\n'; */\n\n    /*!re2c\n        re2c:YYCTYPE = u8;\n        re2c:yyfill:enable = 0;\n        re2c:captvars = 1;\n\n        num = [0-9]+;\n\n        (num) \".\" (num) (\".\" num)? [\\x00] {\n            assert!(yytl0 == 0 && yytr0 == yyinput.len());\n            let major = s2n(&yyinput[yytl1..yytr1]);\n            let minor = s2n(&yyinput[yytl2..yytr2]);\n            let patch = if yytl3 == NONE {0} else {s2n(&yyinput[yytl3 + 1..yytr3])};\n            return Some(SemVer(major, minor, patch));\n        }\n        * { return None; }\n    */\n}\n\nfn main() {\n    assert_eq!(parse(b\"23.34\\0\"), Some(SemVer(23, 34, 0)));\n    assert_eq!(parse(b\"1.2.99999\\0\"), Some(SemVer(1, 2, 99999)));\n    assert_eq!(parse(b\"1.a\\0\"), None);\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "submatch/01_stags_fill.re": {
      "content": "// re2rust $INPUT -o $OUTPUT\n\nuse std::fs::File;\nuse std::io::{Read, Write};\n\nconst BUFSIZE: usize = 4096;\nconst NONE: usize = usize::MAX;\n\nstruct State {\n    file: File,\n    yyinput: [u8; BUFSIZE],\n    yylimit: usize,\n    yycursor: usize,\n    yymarker: usize,\n    token: usize,\n    // Intermediate tag variables must be part of the lexer state passed to YYFILL.\n    // They don't correspond to tags and should be autogenerated by re2c.\n    /*!stags:re2c format = \"@@: usize,\\n\"; */\n    eof: bool,\n}\n\n#[derive(PartialEq)]\nenum Fill { Ok, Eof, LongLexeme }\n\n#[derive(Debug, PartialEq)]\nstruct SemVer(u32, u32, u32); // version: (major, minor, patch)\n\nfn s2n(str: &[u8]) -> u32 { // convert a pre-parsed string to a number\n    let mut n = 0;\n    for i in str { n = n * 10 + *i as u32 - 48; }\n    return n;\n}\n\nmacro_rules! shift { // ignore overflow, marker and tags may not be set yet\n    ($x:expr, $y:expr) => { $x = $x.overflowing_sub($y).0 }\n}\n\nfn fill(st: &mut State) -> Fill {\n    if st.eof { return Fill::Eof; }\n\n    // Error: lexeme too long. In real life could reallocate a larger buffer.\n    if st.token < 1 { return Fill::LongLexeme; }\n\n    // Shift buffer contents (discard everything up to the current token).\n    st.yyinput.copy_within(st.token..st.yylimit, 0);\n    st.yylimit -= st.token;\n    st.yycursor -= st.token;\n    shift!(st.yymarker, st.token);\n    // Tag variables need to be shifted like other input positions. The check\n    // for NONE is only needed if some tags are nested inside of alternative or\n    // repetition, so that they can have NONE value.\n    /*!stags:re2c format = \"if st.@@ != NONE { shift!(st.@@, st.token); }\\n\"; */\n    st.token = 0;\n\n    // Fill free space at the end of buffer with new data from file.\n    match st.file.read(&mut st.yyinput[st.yylimit..BUFSIZE - 1]) {\n        Ok(n) => {\n            st.yylimit += n;\n            st.eof = n == 0;\n            st.yyinput[st.yylimit] = 0;\n        }\n        Err(why) => panic!(\"cannot read from file: {}\", why)\n    }\n\n    return Fill::Ok;\n}\n\nfn parse(st: &mut State) -> Option<Vec::<SemVer>> {\n    let mut vers = Vec::new();\n\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = 'let mut @@;\\n'; */\n\n    'parse: loop {\n        st.token = st.yycursor;\n    /*!re2c\n        re2c:api = record;\n        re2c:eof = 0;\n        re2c:tags = 1;\n        re2c:yyrecord = st;\n        re2c:YYCTYPE = u8;\n        re2c:YYFILL = \"fill(st) == Fill::Ok\";\n\n        num = [0-9]+;\n\n        num @t1 \".\" @t2 num @t3 (\".\" @t4 num)? [\\n] {\n            let major = s2n(&st.yyinput[st.token..t1]);\n            let minor = s2n(&st.yyinput[t2..t3]);\n            let patch = if t4 != NONE {s2n(&st.yyinput[t4..st.yycursor - 1])} else {0};\n            vers.push(SemVer(major, minor, patch));\n            continue 'parse;\n        }\n        $ { return Some(vers); }\n        * { return None; }\n    */\n    }\n}\n\nfn main() {\n    let fname = \"input\";\n    let verstr = b\"1.22.333\\n\";\n    let expect = (0..BUFSIZE).map(|_| SemVer(1, 22, 333)).collect();\n\n    // Prepare input file (make sure it exceeds buffer size).\n    match File::create(fname) {\n        Err(why) => panic!(\"cannot open {}: {}\", fname, why),\n        Ok(mut file) => match file.write_all(&verstr.repeat(BUFSIZE)) {\n            Err(why) => panic!(\"cannot write to {}: {}\", fname, why),\n            Ok(_) => {}\n        }\n    };\n\n    // Reopen input file for reading.\n    let file = match File::open(fname) {\n        Err(why) => panic!(\"cannot read file {}: {}\", fname, why),\n        Ok(file) => file,\n    };\n\n    // Initialize lexer state.\n    let yylimit = BUFSIZE - 1;\n    let mut st = State {\n        file: file,\n        yyinput: [0; BUFSIZE], // sentinel is set to zero, which triggers YYFILL\n        yylimit: yylimit,\n        yycursor: yylimit,\n        yymarker: yylimit,\n        token: yylimit,\n        /*!stags:re2c format = \"@@: NONE,\\n\"; */\n        eof: false,\n    };\n\n    // Run the lexer and check results.\n    assert_eq!(parse(&mut st), Some(expect));\n\n    // Cleanup: remove input file.\n    match std::fs::remove_file(fname) {\n        Err(why) => panic!(\"cannot remove {}: {}\", fname, why),\n        Ok(_) => {}\n    }\n}\n",
      "extraCommandLineArguments": ""
    },
    "real_world/c.re": {
      "content": "// re2rust -W $INPUT -o $OUTPUT --no-unsafe\n\n// This example is based on a public domain C lex grammar originally\n// hosted at http://www.quut.com/c/ANSI-C-grammar-l.html\n// It has, however, been significantly modified.\n\n// A real C lexer in a modern compiler typically postprocesses a tokenization\n// step performed by the preprocessor. This example isn't actually practically\n// usable as-is, and would require significant work to turn into part of a real\n// C compiler.\n\n// As with the original from quut.com, this grammar presupposes translation for\n// phases 1 to 5 have already been performed, though it also still handles\n// comments. It does handle string concatenation though in a sort of\n// half-hearted manner.\n\n// We specify unicode here to make the code in this example more interesting.\n// We use the \"ignore\" Unicode encoding policy (which is the default anyway)\n// because the Rust input routine we use is already checking for surrogates.\n/*!re2c\n    re2c:encoding:utf8 = 1;\n    re2c:encoding-policy = ignore;\n */\n\nuse std::fmt;\n\n// Errors type\n#[derive(Debug, Clone)]\nstruct LexError {\n    message: String,\n    token_text: String,\n    line: usize,\n    column: usize,\n}\n\nimpl fmt::Display for LexError {\n    fn fmt(&self, f: &mut fmt::Formatter) -> Result<(), fmt::Error> {\n        write!(f, \"{}: {} ({}:{})\",\n            self.message, self.token_text, self.line, self.column)\n    }\n}\n\n// The default definitions for the Error methods are fine.\nimpl std::error::Error for LexError { }\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)] // silence 'field in not used' warnings\nstruct Position {\n    // What line are we on? (starts on line 0.)\n    line_num: usize,\n    // What is the index of the first character on the line?\n    bol: usize,\n    // What is the index of the current token?\n    start: usize,\n    // What is the index of the end of the current token?\n    end: usize,\n}\n\n// All the different kinds of tokens.\n#[derive(Debug, Clone, Eq, PartialEq)]\nenum TName {\n    // General\n    //Error(String),\n    Comment,\n    Whitespace,\n    Newline,\n    // Ids.\n    Id,\n    TypeId,\n    EnumId,\n    // Constants\n    IntConst,\n    FloatConst,\n    StringLiteral,\n    // Keywords\n    Alignas,\n    Alignof,\n    Atomic,\n    Bool,\n    Complex,\n    Generic,\n    Imaginary,\n    Noreturn,\n    StaticAssert,\n    ThreadLocal,\n    Auto,\n    Break,\n    Case,\n    Char,\n    Const,\n    Continue,\n    Default,\n    Do,\n    Double,\n    Else,\n    Enum,\n    Extern,\n    Float,\n    For,\n    Goto,\n    If,\n    Inline,\n    Int,\n    Long,\n    Register,\n    Restrict,\n    Return,\n    Short,\n    Signed,\n    Sizeof,\n    Static,\n    Struct,\n    Switch,\n    Typedef,\n    Union,\n    Unsigned,\n    Void,\n    Volatile,\n    While,\n    // Punctuators\n    Ellipsis,\n    RSAsgn,\n    LSAsgn,\n    AddAsgn,\n    SubAsgn,\n    MulAsgn,\n    DivAsgn,\n    ModAsgn,\n    BAndAsgn,\n    BXorAsgn,\n    BOrAsgn,\n    RShift,\n    LShift,\n    Incr,\n    Decr,\n    Arrow,\n    LAnd,\n    LOr,\n    LE,\n    GE,\n    Eq,\n    NEq,\n    Semi,\n    OBrace,\n    CBrace,\n    Comma,\n    Colon,\n    Asgn,\n    OParen,\n    CParen,\n    OBrack,\n    CBrack,\n    Dot,\n    Amper,\n    LNot,\n    BNot,\n    Sub,\n    Add,\n    Aster,\n    Div,\n    Mod,\n    LT,\n    GT,\n    BXor,\n    BOr,\n    Ques,\n}\n\n#[derive(Debug, Clone)]\n#[allow(dead_code)] // silence 'field in not used' warnings\nstruct Token {\n    tname: TName,\n    text: String,\n    position: Position,\n}\n\n#[derive(Debug, Clone)]\nenum SymType {\n    #[allow(dead_code)] // silence 'variant is never constructed' warning\n    TypeName,\n    #[allow(dead_code)] // silence 'variant is never constructed' warning\n    EnumConst,\n    Identifier,\n}\n\n// C lexers (unfortunately) need information from the symbol table to return\n// the correct token type, because an identifier could be a type name. (This\n// ambiguity is a big source of trouble in C.) This is a fake \"sym_type\" that\n// always returns Identifer. It needs to be fixed to actually hook into the\n// parser's symbol table if this lexer is used in the real world.\nfn sym_type(_ident: &str) -> SymType {\n    SymType::Identifier\n}\n\n#[derive(Debug, Clone)]\nstruct Input {\n    data: Vec<u8>,\n    cursor: usize,\n    token: usize,\n    marker: usize,\n    line: usize,\n    bol: usize,\n    eof: bool,\n}\n\nimpl Input {\n    fn new(s: String) -> Input {\n        let data = s.into_bytes();\n        Input {\n            data: data,\n            cursor: 0,\n            token: 0,\n            marker: 0,\n            line: 0,\n            bol: 0,\n            eof: false,\n        }\n    }\n    // text of the current token\n    fn current_ttext(&self) -> String {\n        // for maximum performance, this should actually be from_utf8_unchecked\n        String::from_utf8(self.data[self.token..self.cursor].to_vec()).unwrap()\n    }\n\n    fn token(&mut self, tname: TName) -> Result<Option<Token>, LexError> {\n        let text = self.current_ttext();\n\n        let position = Position {\n            line_num: self.line,\n            bol: self.bol,\n            start: self.token,\n            end: self.cursor,\n        };\n\n        let lines = match tname {\n            TName::Comment => text.lines().count() - 1,\n            // We may have multiple string literals separated by\n            // newlines or the like to fuse.\n            TName::StringLiteral => text.lines().count() - 1,\n            TName::Newline => 1,\n            _ => 0,\n        };\n\n        if tname == TName::Newline {\n            self.bol = self.cursor;\n        } else if lines > 0 {\n            // the unwrap should only fail if we have a bad bug.\n            self.bol = self.data[0..self.cursor]\n                .iter().rposition(|bytes| *bytes == b'\\n')\n                .unwrap();\n        };\n\n        self.line += lines;\n\n        Ok(Some(Token {\n            tname,\n            text,\n            position,\n        }))\n    }\n\n    fn error(&self, s: &str) -> Result<Option<Token>, LexError> {\n        Err(LexError {\n            message: s.to_string(),\n            token_text: self.current_ttext(),\n            line: self.line,\n            column: self.cursor - self.bol,\n        })\n    }\n\n    // Tells us whether an identifier is a type name, an enum constant, or an\n    // ordinary identifier.\n    fn check_type(&mut self) -> Result<Option<Token>, LexError> {\n        let text = self.current_ttext();\n        match sym_type(&text) {\n            SymType::TypeName   => self.token(TName::TypeId),\n            SymType::EnumConst  => self.token(TName::EnumId),\n            SymType::Identifier => self.token(TName::Id),\n        }\n    }\n}\n\n// Some of this lexer was taken from the C lex grammar at\n// http://www.quut.com/c/ANSI-C-grammar-l.html\nfn next_token(input: &mut Input) -> Result<Option<Token>, LexError> {\n    // The input must be null-terminated, otherwise the function has UB.\n    assert_eq!(input.data.last(), Some(&0));\n\n    if input.eof { return Ok(None) }\n\n    input.token = input.cursor;\n    /*!re2c\n    re2c:yyfill:enable = 0;\n    re2c:YYCTYPE      = \"u8\";\n    re2c:YYPEEK       = \"input.data[input.cursor]\";\n    re2c:YYSKIP       = \"input.cursor += 1;\";\n    re2c:YYBACKUP     = \"input.marker = input.cursor;\";\n    re2c:YYRESTORE    = \"input.cursor = input.marker;\";\n    re2c:YYRESTORETAG = \"input.cursor = ${tag};\";\n    re2c:YYSTAGP      = \"@@{tag} = input.cursor;\";\n    re2c:YYSTAGN      = \"@@{tag} = -1;\";\n    re2c:YYSHIFT      = \"input.cursor += @@{shift};\";\n    re2c:YYSHIFTSTAG  = \"@@{tag} += @@{shift};\";\n\n    O  = [0-7];\n    D  = [0-9];\n    NZ = [1-9];\n    L  = [a-zA-Z_];\n    A  = [a-zA-Z_0-9];\n    H  = [a-fA-F0-9];\n    HP = (\"0\"[xX]);\n    E  = ([Ee][+-]?D+);\n    P  = ([Pp][+-]?D+);\n    FS = [fFlL];\n    IS = (([uU](\"l\"|\"L\"|\"ll\"|\"LL\")?)|((\"l\"|\"L\"|\"ll\"|\"LL\")[uU]?));\n    CP = (\"u\"|\"U\"|\"L\");\n    SP = (\"u8\"|\"u\"|\"U\"|\"L\");\n    ES = (\"\\\\\"(['\"?\\\\abfnrtv]|[0-7]{1,3}|\"x\"[a-fA-F0-9]+));\n    LWS = [ \\t\\v\\f];\n    WS = [ \\t\\v\\n\\f];\n\n    // For efficiency, block comments should probably be handled by a special\n    // function that tracks newlines etc. We're punting on that.\n    \"/\" \"*\" ([^\\x00*]|\"*\"+[^\\x00/])* \"*\"+ \"/\" {\n        return input.token(TName::Comment)\n    }\n    // A small rule to catch and error on unterminated comments.\n    \"/\" \"*\" ([^\\x00*]|\"*\"+[^\\x00/])* {\n        return input.error(\"unterminated comment\")\n    }\n    // Line comments\n    \"//\"[^\\x00\\n]* { return input.token(TName::Comment) }\n\n    \"_Alignas\"       { return input.token(TName::Alignas) }\n    \"_Alignof\"       { return input.token(TName::Alignof) }\n    \"_Atomic\"        { return input.token(TName::Atomic) }\n    \"_Bool\"          { return input.token(TName::Bool) }\n    \"_Complex\"       { return input.token(TName::Complex) }\n    \"_Generic\"       { return input.token(TName::Generic) }\n    // _Imaginary is reserved but not used in C\n    \"_Imaginary\"     { return input.token(TName::Imaginary) }\n    \"_Noreturn\"      { return input.token(TName::Noreturn) }\n    \"_Static_assert\" { return input.token(TName::StaticAssert) }\n    \"_Thread_local\"  { return input.token(TName::ThreadLocal) }\n\n    \"auto\"     { return input.token(TName::Auto) }\n    \"break\"    { return input.token(TName::Break) }\n    \"case\"     { return input.token(TName::Case) }\n    \"char\"     { return input.token(TName::Char) }\n    \"const\"    { return input.token(TName::Const) }\n    \"continue\" { return input.token(TName::Continue) }\n    \"default\"  { return input.token(TName::Default) }\n    \"do\"       { return input.token(TName::Do) }\n    \"double\"   { return input.token(TName::Double) }\n    \"else\"     { return input.token(TName::Else) }\n    \"enum\"     { return input.token(TName::Enum) }\n    \"extern\"   { return input.token(TName::Extern) }\n    \"float\"    { return input.token(TName::Float) }\n    \"for\"      { return input.token(TName::For) }\n    \"goto\"     { return input.token(TName::Goto) }\n    \"if\"       { return input.token(TName::If) }\n    \"inline\"   { return input.token(TName::Inline) }\n    \"int\"      { return input.token(TName::Int) }\n    \"long\"     { return input.token(TName::Long) }\n    \"register\" { return input.token(TName::Register) }\n    \"restrict\" { return input.token(TName::Restrict) }\n    \"return\"   { return input.token(TName::Return) }\n    \"short\"    { return input.token(TName::Short) }\n    \"signed\"   { return input.token(TName::Signed) }\n    \"sizeof\"   { return input.token(TName::Sizeof) }\n    \"static\"   { return input.token(TName::Static) }\n    \"struct\"   { return input.token(TName::Struct) }\n    \"switch\"   { return input.token(TName::Switch) }\n    \"typedef\"  { return input.token(TName::Typedef) }\n    \"union\"    { return input.token(TName::Union) }\n    \"unsigned\" { return input.token(TName::Unsigned) }\n    \"void\"     { return input.token(TName::Void) }\n    \"volatile\" { return input.token(TName::Volatile) }\n    \"while\"    { return input.token(TName::While) }\n\n    // In C, identifiers cannot actually be assigned a token type without\n    // cooperation with the parser. We call a function that tells us what kind\n    // of token this really is.\n    L A*       { return input.check_type() }\n\n    HP H+ IS?  { return input.token(TName::IntConst) }\n    NZ D* IS?  { return input.token(TName::IntConst) }\n    \"0\" O* IS? { return input.token(TName::IntConst) }\n\n    // Character constants\n    CP? \"'\" ([^\\x00'\\\\\\n]|ES)+ \"'\" { return input.token(TName::IntConst) }\n\n    // A rule to catch unterminated character constants\n    CP? \"'\" ([^\\x00'\\\\\\n]|ES)+ {\n        return input.error(\"unterminated character constant\")\n    }\n\n    D+ E FS?            { return input.token(TName::FloatConst) }\n    D* \".\" D+ E? FS?    { return input.token(TName::FloatConst) }\n    D+ \".\" E? FS?       { return input.token(TName::FloatConst) }\n    HP H+ P FS?         { return input.token(TName::FloatConst) }\n    HP H* \".\" H+ P FS?  { return input.token(TName::FloatConst) }\n    HP H+ \".\" P FS?     { return input.token(TName::FloatConst) }\n\n    // adjacent string literals get fused\n    (SP? \"\\\"\" ([^\\x00\"\\\\\\n]|ES)* \"\\\"\" WS*)+ {\n        return input.token(TName::StringLiteral)\n    }\n\n    // A rule to catch unterminated strings.\n    (SP? \"\\\"\" ([^\\x00\"\\\\\\n]|ES)*) {\n        return input.error(\"unterminated string\")\n    }\n\n    \"...\"    { return input.token(TName::Ellipsis) }\n    \">>=\"    { return input.token(TName::RSAsgn) }\n    \"<<=\"    { return input.token(TName::LSAsgn) }\n    \"+=\"     { return input.token(TName::AddAsgn) }\n    \"-=\"     { return input.token(TName::SubAsgn) }\n    \"*=\"     { return input.token(TName::MulAsgn) }\n    \"/=\"     { return input.token(TName::DivAsgn) }\n    \"%=\"     { return input.token(TName::ModAsgn) }\n    \"&=\"     { return input.token(TName::BAndAsgn) }\n    \"^=\"     { return input.token(TName::BXorAsgn) }\n    \"|=\"     { return input.token(TName::BOrAsgn) }\n    \">>\"     { return input.token(TName::RShift) }\n    \"<<\"     { return input.token(TName::LShift) }\n    \"++\"     { return input.token(TName::Incr) }\n    \"--\"     { return input.token(TName::Decr) }\n    \"->\"     { return input.token(TName::Arrow) }\n    \"&&\"     { return input.token(TName::LAnd) }\n    \"||\"     { return input.token(TName::LOr) }\n    \"<=\"     { return input.token(TName::LE) }\n    \">=\"     { return input.token(TName::GE) }\n    \"==\"     { return input.token(TName::Eq) }\n    \"!=\"     { return input.token(TName::NEq) }\n    \";\"      { return input.token(TName::Semi) }\n    \"{\"      { return input.token(TName::OBrace) }\n    \"}\"      { return input.token(TName::CBrace) }\n    \",\"      { return input.token(TName::Comma) }\n    \":\"      { return input.token(TName::Colon) }\n    \"=\"      { return input.token(TName::Asgn) }\n    \"(\"      { return input.token(TName::OParen) }\n    \")\"      { return input.token(TName::CParen) }\n    \"[\"      { return input.token(TName::OBrack) }\n    \"]\"      { return input.token(TName::CBrack) }\n    \".\"      { return input.token(TName::Dot) }\n    \"&\"      { return input.token(TName::Amper) }\n    \"!\"      { return input.token(TName::LNot) }\n    \"~\"      { return input.token(TName::BNot) }\n    \"-\"      { return input.token(TName::Sub) }\n    \"+\"      { return input.token(TName::Add) }\n    \"*\"      { return input.token(TName::Aster) }\n    \"/\"      { return input.token(TName::Div) }\n    \"%\"      { return input.token(TName::Mod) }\n    \"<\"      { return input.token(TName::LT) }\n    \">\"      { return input.token(TName::GT) }\n    \"^\"      { return input.token(TName::BXor) }\n    \"|\"      { return input.token(TName::BOr) }\n    \"?\"      { return input.token(TName::Ques) }\n\n    // Whitespace separates tokens. In general, most parsers are not going to\n    // want to deal with these. In this example we're returning them as actual\n    // tokens though. For no particularly deep or good reason, we've made\n    // Newline its own token, though it does simplify some processing.\n    LWS+   { return input.token(TName::Whitespace) }\n    \"\\n\"   { return input.token(TName::Newline) }\n\n    // Bad characters generate an error.\n    *      { return input.error(\"bad character\") }\n\n    // XXX shouldn't need return!\n    [\\x00] { input.eof = true; return Ok(None); }\n    */\n\n}\n\nconst DEBUG: bool = false;\nmacro_rules! log {\n    ($($fmt:expr)? $(, $args:expr)*) => {\n        if DEBUG { println!($($fmt)? $(, $args)*) }\n    }\n}\n\nfn main() -> std::io::Result<()> {\n    use std::env;\n    use std::fs;\n\n    // Treats the first command line argument as a filename and returns file\n    // contents as a string. If there is no filename, returns a pre-defined\n    // example string (this is used for testing).\n    let args: Vec<String> = env::args().collect();\n\n    // We append a '\\0' at the end of the string to act as a sentinel.\n    let mut str: String;\n    if args.len() < 2 {\n        str = \"int main() { return 0; }\\0\".to_string(); // example C program\n    } else {\n        str = fs::read_to_string(&args[1])?;\n        str.push('\\0');\n    }\n\n    let mut input = Input::new(str);\n\n    loop {\n        match next_token(&mut input) {\n            Ok(Some(token)) => log!(\"{:#?}\", token),\n            Ok(None) => {\n                log!(\"EOF\");\n                break;\n            },\n            Err(error) => {\n                log!(\"error: {:#?}\", error);\n                break;\n            },\n        };\n    };\n\n    Ok(())\n}\n",
      "extraCommandLineArguments": "--no-unsafe"
    },
    "eof/03_eof_rule.re": {
      "content": "// re2rust $INPUT -o $OUTPUT --api simple\n\nfn lex(yyinput: &[u8]) -> isize {\n    // The input must be null-terminated, otherwise the function has UB.\n    assert_eq!(yyinput.last(), Some(&0));\n\n    let (mut yycursor, mut yymarker) = (0, 0);\n    let yylimit = yyinput.len() - 1; // null-terminator not included\n    let mut count = 0;\n\n    'lex: loop { /*!re2c\n        re2c:YYCTYPE = u8;\n        re2c:yyfill:enable = 0;\n        re2c:eof = 0;\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        *    { return -1; }\n        $    { return count; }\n        str  { count += 1; continue 'lex; }\n        [ ]+ { continue 'lex; }\n    */}\n}\n\nfn main() {\n    assert_eq!(lex(b\"\\0\"), 0);\n    assert_eq!(lex(b\"'qu\\0tes' 'are' 'fine: \\\\'' \\0\"), 3);\n    assert_eq!(lex(b\"'unterminated\\\\'\\0\"), -1);\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "eof/04_fake_sentinel.re": {
      "content": "// re2rust $INPUT -o $OUTPUT\n\n// Expect a string without terminating null.\nfn lex(s: &[u8]) -> isize {\n    let mut count = 0;\n    let mut cur = 0;\n    let lim = s.len();\n\n    'lex: loop {/*!re2c\n        re2c:YYCTYPE = u8;\n        re2c:YYPEEK = \"if cur < lim {*s.get_unchecked(cur)} else {0}\";\n        re2c:YYSKIP = \"cur += 1;\";\n        re2c:yyfill:enable  = 0;\n\n        *      { return -1; }\n        [\\x00] { return count; }\n        [a-z]+ { count += 1; continue 'lex; }\n        [ ]+   { continue 'lex; }\n    */}\n}\n\nfn main() {\n    assert_eq!(lex(b\"\"), 0);\n    assert_eq!(lex(b\"one two three \"), 3);\n    assert_eq!(lex(b\"f0ur\"), -1);\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/02_bounds_checking.re": {
      "content": "// re2rust $INPUT -o $OUTPUT --api simple\n\n/*!max:re2c*/\n\nfn lex(s: &[u8]) -> isize {\n    let mut count = 0;\n    let mut yycursor = 0;\n    let yylimit = s.len() + YYMAXFILL;\n\n    // Copy string to a buffer and add YYMAXFILL zero padding.\n    let mut yyinput = Vec::with_capacity(yylimit);\n    yyinput.extend_from_slice(s);\n    yyinput.extend([0 as u8; YYMAXFILL]);\n\n    'lex: loop { /*!re2c\n        re2c:YYCTYPE = u8;\n        re2c:YYFILL = \"return -1;\";\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        [\\x00] {\n            // Check that it is the sentinel, not some unexpected null.\n            return if yycursor == s.len() + 1 { count } else { -1 }\n        }\n        str  { count += 1; continue 'lex; }\n        [ ]+ { continue 'lex; }\n        *    { return -1; }\n    */}\n}\n\nfn main() {\n    assert_eq!(lex(b\"\"), 0);\n    assert_eq!(lex(b\"'qu\\0tes' 'are' 'fine: \\\\'' \"), 3);\n    assert_eq!(lex(b\"'unterminated\\\\'\"), -1);\n    assert_eq!(lex(b\"'unexpected \\0 null\"), -1);\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "eof/01_sentinel.re": {
      "content": "// re2rust $INPUT -o $OUTPUT --api simple\n\nfn lex(yyinput: &[u8]) -> isize {\n    // The input must be null-terminated, otherwise the function has UB.\n    assert_eq!(yyinput.last(), Some(&0));\n\n    let mut yycursor = 0;\n    let mut count = 0;\n\n    'lex: loop { /*!re2c\n        re2c:YYCTYPE = u8;\n        re2c:yyfill:enable = 0;\n\n        *      { return -1; }\n        [\\x00] { return count; }\n        [a-z]+ { count += 1; continue 'lex; }\n        [ ]+   { continue 'lex; }\n    */}\n}\n\nfn main() {\n    assert_eq!(lex(b\"\\x00\"), 0);\n    assert_eq!(lex(b\"one two three\\x00\"), 3);\n    assert_eq!(lex(b\"f0ur\\x00\"), -1);\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "includes/include.re": {
      "content": "// re2rust $INPUT -o $OUTPUT --api simple\n\n/*!include:re2c \"definitions.rs\" */\n\nfn lex(yyinput: &[u8]) -> Num {\n    assert_eq!(yyinput.last(), Some(&0)); // expect null-terminated input\n\n    let mut yycursor = 0;\n    let mut yymarker = 0;\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:YYCTYPE = u8;\n\n        *      { return Num::NaN; }\n        number { return Num::Int; }\n        !include \"extra_rules.re.inc\";\n    */\n}\n\nfn main() {\n    assert_eq!(lex(b\"123\\0\"), Num::Int);\n    assert_eq!(lex(b\"123.4567\\0\"), Num::Float);\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "encodings/unicode_identifier.re": {
      "content": "// re2rust $INPUT -o $OUTPUT --utf8 --api simple\n\n/*!include:re2c \"unicode_categories.re\" */\n\nfn lex(yyinput: &[u8]) -> bool {\n    assert_eq!(yyinput.last(), Some(&0)); // expect null-terminated input\n\n    let (mut yycursor, mut yymarker) = (0, 0);\n    /*!re2c\n        re2c:YYCTYPE = u8;\n        re2c:yyfill:enable = 0;\n\n        // Simplified \"Unicode Identifier and Pattern Syntax\"\n        // (see https://unicode.org/reports/tr31)\n        id_start    = L | Nl | [$_];\n        id_continue = id_start | Mn | Mc | Nd | Pc | [\\u200D\\u05F3];\n        identifier  = id_start id_continue*;\n\n        identifier { return true; }\n        *          { return false; }\n    */\n}\n\nfn main() {\n    assert!(lex(\"_\u042b\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\\0\".as_bytes()));\n}\n",
      "extraCommandLineArguments": "--utf8 --api simple"
    },
    "reuse/reuse.re": {
      "content": "// re2rust $INPUT -o $OUTPUT --input-encoding utf8 --api simple\n\n// This example supports multiple input encodings: UTF-8 and UTF-32.\n// Both lexers are generated from the same rules block, and the use\n// blocks add only encoding-specific configurations.\n/*!rules:re2c\n    re2c:yyfill:enable = 0;\n\n    \"\u2200x \u2203y\" { return Some(yycursor); }\n    *       { return None; }\n*/\n\nfn lex_utf8(yyinput: &[u8]) -> Option<usize> {\n    assert!(yyinput.len() > 0); // expect nonempty input\n    let (mut yycursor, mut yymarker) = (0, 0);\n    /*!use:re2c\n        re2c:encoding:utf8 = 1;\n        re2c:YYCTYPE = u8;\n    */\n}\n\nfn lex_utf32(yyinput: &[u32]) -> Option<usize> {\n    assert!(yyinput.len() > 0); // expect nonempty input\n    let (mut yycursor, mut yymarker) = (0, 0);\n    /*!use:re2c\n        re2c:encoding:utf32 = 1;\n        re2c:YYCTYPE = u32;\n    */\n}\n\nfn main() {\n    let s8 = vec![0xe2, 0x88, 0x80, 0x78, 0x20, 0xe2, 0x88, 0x83, 0x79];\n    assert_eq!(lex_utf8(&s8), Some(s8.len()));\n\n    let s32 = vec![0x2200, 0x78, 0x20, 0x2203, 0x79];\n    assert_eq!(lex_utf32(&s32), Some(s32.len()));\n}\n",
      "extraCommandLineArguments": "--input-encoding utf8 --api simple"
    },
    "reuse/usedir.re": {
      "content": "// re2rust $INPUT -o $OUTPUT --api simple\n\n// This example shows how to combine reusable re2c blocks: two blocks\n// ('colors' and 'fish') are merged into one. The 'salmon' rule occurs\n// in both blocks; the 'fish' block takes priority because it is used\n// earlier. Default rule * occurs in all three blocks; the local (not\n// inherited) definition takes priority.\n\n#[derive(Debug, PartialEq)]\nenum Ans { Color, Fish, Dunno }\n\n/*!rules:re2c:colors\n    *                            { panic!(\"ah\"); }\n    \"red\" | \"salmon\" | \"magenta\" { return Ans::Color; }\n*/\n\n/*!rules:re2c:fish\n    *                            { panic!(\"oh\"); }\n    \"haddock\" | \"salmon\" | \"eel\" { return Ans::Fish; }\n*/\n\nfn lex(yyinput: &[u8]) -> Ans {\n    assert!(yyinput.len() > 0); // expect nonempty input\n\n    let (mut yycursor, mut yymarker) = (0, 0);\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:YYCTYPE = u8;\n\n        !use:fish;\n        !use:colors;\n        * { return Ans::Dunno; }  // overrides inherited '*' rules\n    */\n}\n\nfn main() {\n    assert_eq!(lex(b\"salmon\"), Ans::Fish);\n    assert_eq!(lex(b\"what?\"), Ans::Dunno);\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "headers/header.re": {
      "content": "// re2rust $INPUT -o $OUTPUT --header lexer/state.rs\n\nmod lexer;\nuse lexer::state::State; // the module is generated by re2c\n\n/*!header:re2c:on*/\npub struct State<'a> {\n    pub yyinput: &'a [u8],\n    pub yycursor: usize,\n    /*!stags:re2c format = \"pub @@: usize,\"; */\n}\n/*!header:re2c:off*/\n\nfn lex(yyrecord: &mut State) -> usize {\n    assert_eq!(yyrecord.yyinput.last(), Some(&0)); // expect null-terminated input\n\n    let t: usize;\n    /*!re2c\n        re2c:header = \"lexer/state.rs\";\n        re2c:yyfill:enable = 0;\n        re2c:api = record;\n        re2c:YYCTYPE = \"u8\";\n        re2c:tags = 1;\n\n        [a]* @t [b]* { return t; }\n    */\n}\n\nfn main() {\n    let mut st = State {\n        yyinput: b\"ab\\0\",\n        yycursor: 0,\n        /*!stags:re2c format = \"@@: 0,\"; */\n    };\n    assert_eq!(lex(&mut st), 1);\n}\n",
      "extraCommandLineArguments": "--header lexer/state.rs"
    }
  },
  "d": {
    "01_basic.re": {
      "content": "// re2d $INPUT -o $OUTPUT -i\nmodule main;\n\nprivate bool lex(const(char)* yycursor) {\n    /*!re2c\n        re2c:YYCTYPE = char;\n        re2c:yyfill:enable = 0;\n\n        [1-9][0-9]* { return true; }\n        *           { return false; }\n    */\n}\n\nvoid main() {\n    assert(lex(\"1234\"));\n}\n",
      "extraCommandLineArguments": "-i"
    },
    "fill/01_fill.re": {
      "content": "// re2d $INPUT -o $OUTPUT\nmodule main;\n\nimport core.stdc.string;\nimport core.stdc.stdio;\n\nenum BUFSIZE = 4095;\n\nstruct Input {\n    FILE* file;\n    char[BUFSIZE + 1] buffer;// +1 for sentinel\n    char* yylimit, yycursor, yymarker, token;\n    bool eof;\n};\n\nprivate int fill(ref Input it) {\n    if (it.eof) return 1;\n\n    const size_t shift = it.token - it.buffer.ptr;\n    const size_t used = it.yylimit - it.token;\n\n    // Error: lexeme too long. In real life could reallocate a larger buffer.\n    if (shift < 1) return 2;\n\n    // Shift buffer contents (discard everything up to the current token).\n    memmove(cast(void*)it.buffer.ptr, it.token, used);\n    it.yylimit -= shift;\n    it.yycursor -= shift;\n    it.yymarker -= shift;\n    it.token -= shift;\n\n    // Fill free space at the end of buffer with new data from file.\n    it.yylimit += fread(it.yylimit, 1, BUFSIZE - used, it.file);\n    it.yylimit[0] = 0;\n    it.eof = it.yylimit < (it.buffer.ptr + BUFSIZE);\n    return 0;\n}\n\nprivate int lex(ref Input yyrecord) {\n    int count = 0;\n    for (;;) {\n        yyrecord.token = yyrecord.yycursor;\n    /*!re2c\n        re2c:api = record;\n        re2c:YYCTYPE = \"char\";\n        re2c:YYFILL = \"fill(yyrecord) == 0\";\n        re2c:eof = 0;\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        *    { return -1; }\n        $    { return count; }\n        str  { ++count; continue; }\n        [ ]+ { continue; }\n    */\n    }\n    assert(0);\n}\n\nvoid main() {\n    const char[] fname = \"input\";\n    const char[] content = \"'qu\\0tes' 'are' 'fine: \\\\'' \";\n\n    // Prepare input file: a few times the size of the buffer, containing\n    // strings with zeroes and escaped quotes.\n    FILE* f = fopen(fname.ptr, \"w\");\n    for (int i = 0; i < BUFSIZE; ++i) {\n        fwrite(cast(const(void*)) content.ptr, 1, content.length - 1, f);\n    }\n    fclose(f);\n    int count = 3 * BUFSIZE; // number of quoted strings written to file\n\n    // Initialize lexer state: all pointers are at the end of buffer.\n    Input it;\n    it.file = fopen(fname.ptr, \"r\");\n    it.yycursor = it.yymarker = it.token = it.yylimit = it.buffer.ptr + BUFSIZE;\n    it.eof = 0;\n    // Sentinel (at YYLIMIT pointer) is set to zero, which triggers YYFILL.\n    it.yylimit[0] = 0;\n\n    // Run the lexer.\n    assert(lex(it) == count);\n\n    // Cleanup: remove input file.\n    fclose(it.file);\n    remove(fname.ptr);\n}\n",
      "extraCommandLineArguments": ""
    },
    "fill/02_fill.re": {
      "content": "// re2d $INPUT -o $OUTPUT\nmodule main;\n\nimport core.stdc.string;\nimport core.stdc.stdio;\n\n/*!max:re2c*/\nenum BufSize = (4096 - YYMaxFill);\n\nstruct Input {\n    FILE* file;\n    char[BufSize + YYMaxFill] buffer;\n    char* yylimit, yycursor, token;\n    bool eof;\n};\n\nprivate int fill(ref Input it, size_t need) {\n    if (it.eof) return 1;\n\n    const size_t shift = it.token - it.buffer.ptr;\n    const size_t used = it.yylimit - it.token;\n\n    // Error: lexeme too long. In real life could reallocate a larger buffer.\n    if (shift < need) return 2;\n\n    // Shift buffer contents (discard everything up to the current token).\n    memmove(it.buffer.ptr, it.token, used);\n    it.yylimit -= shift;\n    it.yycursor -= shift;\n    it.token -= shift;\n\n    // Fill free space at the end of buffer with new data from file.\n    it.yylimit += fread(it.yylimit, 1, BufSize - used, it.file);\n\n    // If read less than expected, this is end of input => add zero padding\n    // so that the lexer can access characters at the end of buffer.\n    if (it.yylimit < it.buffer.ptr + BufSize) {\n        it.eof = true;\n        memset(it.yylimit, 0, YYMaxFill);\n        it.yylimit += YYMaxFill;\n    }\n\n    return 0;\n}\n\nprivate int lex(ref Input yyrecord) {\n    int count = 0;\n    for (;;) {\n        yyrecord.token = yyrecord.yycursor;\n    /*!re2c\n        re2c:api = record;\n        re2c:YYCTYPE = \"char\";\n        re2c:YYFILL = \"if (fill(yyrecord, @@) != 0) return -1;\";\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        [\\x00] {\n            // Check that it is the sentinel, not some unexpected null.\n            return yyrecord.token == yyrecord.yylimit - YYMaxFill ? count : -1;\n        }\n        str  { ++count; continue; }\n        [ ]+ { continue; }\n        *    { return -1; }\n    */\n    }\n    assert(0);\n}\n\nvoid main() {\n    const char[] fname = \"input\";\n    const char[] content = \"'qu\\0tes' 'are' 'fine: \\\\'' \";\n\n    // Prepare input file: a few times the size of the buffer, containing\n    // strings with zeroes and escaped quotes.\n    FILE* f = fopen(fname.ptr, \"w\");\n    for (int i = 0; i < BufSize; ++i) {\n        fwrite(content.ptr, 1, content.length - 1, f);\n    }\n    fclose(f);\n    int count = 3 * BufSize; // number of quoted strings written to file\n\n    // Initialize lexer state: all pointers are at the end of buffer.\n    // This immediately triggers YYFILL, as the check `it.yycursor < it.yylimit` fails.\n    Input it;\n    it.file = fopen(fname.ptr, \"r\");\n    it.yycursor = it.token = it.yylimit = it.buffer.ptr + BufSize;\n    it.eof = 0;\n\n    // Run the lexer.\n    assert(lex(it) == count);\n\n    // Cleanup: remove input file.\n    fclose(it.file);\n    remove(fname.ptr);\n}\n",
      "extraCommandLineArguments": ""
    },
    "conditions/parse_u32_conditions.re": {
      "content": "// re2d $INPUT -o $OUTPUT -ci\nmodule main;\n\nenum ERROR = ulong.max;\n/*!conditions:re2c*/\n\nprivate void add(ulong BASE)(ref ulong u, int d) {\n    u = u * BASE + d;\n    if (u > uint.max) { u = ERROR; }\n}\n\nprivate ulong parse_u32(const(char)* s) {\n    const(char)* yycursor = s, yymarker;\n    YYCond yycond = YYCond.yycinit;\n    ulong u = 0;\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:YYCTYPE = char;\n\n        <*> * { return ERROR; }\n        <init> '0b' / [01]        :=> bin\n        <init> \"0\"                :=> oct\n        <init> \"\" / [1-9]         :=> dec\n        <init> '0x' / [0-9a-fA-F] :=> hex\n        <bin, oct, dec, hex> \"\\x00\" { return u; }\n        <bin> [01]  { add!(2)(u,  yycursor[-1] - '0');      goto yyc_bin; }\n        <oct> [0-7] { add!(8)(u,  yycursor[-1] - '0');      goto yyc_oct; }\n        <dec> [0-9] { add!(10)(u, yycursor[-1] - '0');      goto yyc_dec; }\n        <hex> [0-9] { add!(16)(u, yycursor[-1] - '0');      goto yyc_hex; }\n        <hex> [a-f] { add!(16)(u, yycursor[-1] - 'a' + 10); goto yyc_hex; }\n        <hex> [A-F] { add!(16)(u, yycursor[-1] - 'A' + 10); goto yyc_hex; }\n    */\n}\n\n\n\nvoid main() {\n    assert(parse_u32(\"\") == ERROR);\n    assert(parse_u32(\"1234567890\") == 1234567890);\n    assert(parse_u32(\"0b1101\") == 13);\n    assert(parse_u32(\"0x7Fe\") == 2046);\n    assert(parse_u32(\"0644\") == 420);\n    assert(parse_u32(\"9999999999\") == ERROR);\n}\n",
      "extraCommandLineArguments": "-ci"
    },
    "conditions/parse_u32_blocks.re": {
      "content": "// re2d $INPUT -o $OUTPUT -i\nmodule main;\n\nenum ERROR = ulong.max;\n\nprivate void add(ulong BASE)(ref ulong u, int d) {\n    u = u * BASE + d;\n    if (u > uint.max) { u = ERROR; }\n}\n\nprivate ulong parse_u32(const(char)* s) {\n    const(char)* yycursor = s, yymarker;\n    ulong u = 0;\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:YYCTYPE = char;\n\n        end = \"\\x00\";\n\n        '0b' / [01]        { goto bin; }\n        \"0\"                { goto oct; }\n        \"\" / [1-9]         { goto dec; }\n        '0x' / [0-9a-fA-F] { goto hex; }\n        *                  { return ERROR; }\n    */\nbin:\n    /*!re2c\n        end   { return u; }\n        [01]  { add!(2)(u, yycursor[-1] - '0'); goto bin; }\n        *     { return ERROR; }\n    */\noct:\n    /*!re2c\n        end   { return u; }\n        [0-7] { add!(8)(u, yycursor[-1] - '0'); goto oct; }\n        *     { return ERROR; }\n    */\ndec:\n    /*!re2c\n        end   { return u; }\n        [0-9] { add!(10)(u, yycursor[-1] - '0'); goto dec; }\n        *     { return ERROR; }\n    */\nhex:\n    /*!re2c\n        end   { return u; }\n        [0-9] { add!(16)(u, yycursor[-1] - '0');      goto hex; }\n        [a-f] { add!(16)(u, yycursor[-1] - 'a' + 10); goto hex; }\n        [A-F] { add!(16)(u, yycursor[-1] - 'A' + 10); goto hex; }\n        *     { return ERROR; }\n    */\n}\n\nvoid main() {\n    assert(parse_u32(\"\") == ERROR);\n    assert(parse_u32(\"1234567890\") == 1234567890);\n    assert(parse_u32(\"0b1101\") == 13);\n    assert(parse_u32(\"0x7Fe\") == 2046);\n    assert(parse_u32(\"0644\") == 420);\n    assert(parse_u32(\"9999999999\") == ERROR);\n}\n",
      "extraCommandLineArguments": "-i"
    },
    "state/push.re": {
      "content": "// re2d $INPUT -o $OUTPUT -f\nmodule main;\n\nimport core.stdc.stdio;\nimport core.stdc.string;\n\n// Use a small buffer to cover the case when a lexeme doesn't fit.\n// In real world use a larger buffer.\nenum BUFSIZE = 10;\n\nstruct State {\n    FILE* file;\n    char[BUFSIZE + 1] buffer;\n    char* yylimit, yycursor, yymarker, token;\n    int yystate;\n};\n\nenum Status {END, READY, WAITING, BAD_PACKET, BIG_PACKET};\n\nprivate Status fill(ref State st) {\n    const size_t shift = st.token - cast(char*)st.buffer;\n    const size_t used = st.yylimit - st.token;\n    const size_t free = BUFSIZE - used;\n\n    // Error: no space. In real life can reallocate a larger buffer.\n    if (free < 1) return Status.BIG_PACKET;\n\n    // Shift buffer contents (discard already processed data).\n    memmove(cast(void*)st.buffer, st.token, used);\n    st.yylimit -= shift;\n    st.yycursor -= shift;\n    st.yymarker -= shift;\n    st.token -= shift;\n\n    // Fill free space at the end of buffer with new data.\n    const size_t read = fread(st.yylimit, 1, free, st.file);\n    st.yylimit += read;\n    st.yylimit[0] = 0; // append sentinel symbol\n\n    return Status.READY;\n}\n\nprivate Status lex(ref State yyrecord, uint* recv) {\n    char yych;\n    /*!getstate:re2c*/\n\n    for (;;) {\n        yyrecord.token = yyrecord.yycursor;\n    /*!re2c\n        re2c:api = record;\n        re2c:YYCTYPE = char;\n        re2c:YYFILL = \"return Status.WAITING;\";\n        re2c:eof = 0;\n\n        packet = [a-z]+[;];\n\n        *      { return Status.BAD_PACKET; }\n        $      { return Status.END; }\n        packet { *recv = *recv + 1; continue; }\n    */\n    }\n    assert(0); // unreachable\n}\n\nprivate void test(string[] packets, Status expect) {\n    // Create a pipe (open the same file for reading and writing).\n    const(char*) fname = \"pipe\";\n    FILE* fw = fopen(fname, \"w\");\n    FILE* fr = fopen(fname, \"r\");\n    setvbuf(fw, null, _IONBF, 0);\n    setvbuf(fr, null, _IONBF, 0);\n\n    // Initialize lexer state: `state` value is -1, all pointers are at the end\n    // of buffer.\n    State st;\n    st.file = fr;\n    st.yycursor = st.yymarker = st.token = st.yylimit = cast(char*)st.buffer + BUFSIZE;\n    // Sentinel (at YYLIMIT pointer) is set to zero, which triggers YYFILL.\n    st.yylimit[0] = 0;\n    st.yystate = -1;\n\n    // Main loop. The buffer contains incomplete data which appears packet by\n    // packet. When the lexer needs more input it saves its internal state and\n    // returns to the caller which should provide more input and resume lexing.\n    Status status;\n    uint send = 0, recv = 0;\n    for (;;) {\n        status = lex(st, &recv);\n        if (status == Status.END) {\n            debug{printf(\"done: got %u packets\\n\", recv);}\n            break;\n        } else if (status == Status.WAITING) {\n            debug{printf(\"waiting...\\n\");}\n            if (send < packets.length) {\n                debug{printf(\"sent packet %u\\n\", send);}\n                fprintf(fw, \"%s\", cast(char*)packets[send]);\n                ++send;\n            }\n            status = fill(st);\n            debug{printf(\"queue: '%s'\\n\", cast(char*)st.buffer);}\n            if (status == Status.BIG_PACKET) {\n                debug{printf(\"error: packet too big\\n\");}\n                break;\n            }\n            assert(status == Status.READY);\n        } else {\n            assert(status == Status.BAD_PACKET);\n            debug{printf(\"error: ill-formed packet\\n\");}\n            break;\n        }\n    }\n\n    // Check results.\n    assert(status == expect);\n    if (status == Status.END) assert(recv == send);\n\n    // Cleanup: remove input file.\n    fclose(fw);\n    fclose(fr);\n    remove(fname);\n}\n\nvoid main() {\n    string[] packets1 = [];\n    string[] packets2 = [\"zero;\", \"one;\", \"two;\", \"three;\", \"four;\"];\n    string[] packets3 = [\"zer0;\"];\n    string[] packets4 = [\"looooooooooong;\"];\n\n    test(packets1, Status.END);\n    test(packets2, Status.END);\n    test(packets3, Status.BAD_PACKET);\n    test(packets4, Status.BIG_PACKET);\n}\n",
      "extraCommandLineArguments": "-f"
    },
    "submatch/02_mtags.re": {
      "content": "// re2d $INPUT -o $OUTPUT\nmodule main;\n\nenum MtagRoot = -1;\n\n// An m-tag tree is a way to store histories with an O(1) copy operation.\n// Histories naturally form a tree, as they have common start and fork at some\n// point. The tree is stored as an array of pairs (tag value, link to parent).\n// An m-tag is represented with a single link in the tree (array index).\nstruct Mtag {\n    const(char)* elem; // tag value\n    int pred; // index of the predecessor node or root\n};\n\nalias MtagTrie = Mtag[];\nalias Ver = int[];\n\nprivate int s2n(const(char)* s, const(char)* e) { // pre-parsed string to number\n    int n = 0;\n    for (; s < e; ++s) n = n * 10 + (*s - '0');\n    return n;\n}\n\n// Append a single value to an m-tag history.\nprivate void add_mtag(ref MtagTrie trie, ref int mtag, const(char)* value) {\n    Mtag m = {value, mtag};\n    mtag = cast(int)trie.length;\n    trie ~= [m];\n}\n\n// Recursively unwind tag histories and collect version components.\nprivate void unfold(const ref MtagTrie trie, int x, int y, ref Ver ver) {\n    // Reached the root of the m-tag tree, stop recursion.\n    if (x == MtagRoot && y == MtagRoot) return;\n\n    // Unwind history further.\n    unfold(trie, trie[x].pred, trie[y].pred, ver);\n\n    // Get tag values. Tag histories must have equal length.\n    assert(x != MtagRoot && y != MtagRoot);\n    const(char)* ex = trie[x].elem, ey = trie[y].elem;\n\n    if (ex != null && ey != null) {\n        // Both tags are valid pointers, extract component.\n        ver ~= [s2n(ex, ey)];\n    } else {\n        // Both tags are null (this corresponds to zero repetitions).\n        assert(ex == null && ey == null);\n    }\n}\n\nprivate bool parse(const(char)* str, ref Ver ver) {\n    const(char)* yycursor = str, yymarker;\n    MtagTrie mt;\n\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = \"const(char)* @@;\"; */\n    /*!mvars:re2c format = \"int @@;\"; */\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = \"const(char)* @@ = null;\"; */\n    /*!mtags:re2c format = \"int @@ = MtagRoot;\"; */\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:tags = 1;\n        re2c:YYCTYPE = \"char\";\n        re2c:YYMTAGP = \"add_mtag(mt, @@, yycursor);\";\n        re2c:YYMTAGN = \"add_mtag(mt, @@, null);\";\n\n        num = [0-9]+;\n        @t1 num @t2 (\".\" #t3 num #t4)* [\\x00] {\n            ver = [];\n            ver ~= [s2n(t1, t2)];\n            unfold(mt, t3, t4, ver);\n            return true;\n        }\n        * { return false; }\n    */\n}\n\nvoid main() {\n    Ver v;\n    assert(parse(\"1\", v) && v == [1]);\n    assert(parse(\"1.2.3.4.5.6.7\", v) && v == [1, 2, 3, 4, 5, 6, 7]);\n    assert(!parse(\"1.2.\", v));\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/04_posix_captures.re": {
      "content": "// re2d $INPUT -o $OUTPUT\nmodule main;\n\n// Maximum number of capturing groups among all rules.\n/*!maxnmatch:re2c*/\n\nstruct SemVer { int major, minor, patch; };\n\nprivate int s2n(const(char)* s, const(char)* e) { // pre-parsed string to number\n    int n = 0;\n    for (; s < e; ++s) n = n * 10 + (*s - '0');\n    return n;\n}\n\nprivate bool lex(const(char)* str, ref SemVer ver) {\n    const(char)* yycursor = str, yymarker;\n\n    // Allocate memory for capturing parentheses (twice the number of groups).\n    const(char)*[YYMaxNMatch * 2] yypmatch;\n    size_t yynmatch;\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = 'const(char)* @@;\\n'; */\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:posix-captures = 1;\n        re2c:YYCTYPE = \"char\";\n\n        num = [0-9]+;\n\n        (num) \".\" (num) (\".\" num)? [\\x00] {\n            // `yynmatch` is the number of capturing groups\n            assert(yynmatch == 4);\n            // Even `yypmatch` values are for opening parentheses, odd values\n            // are for closing parentheses, the first group is the whole match.\n            ver.major = s2n(yypmatch[2], yypmatch[3]);\n            ver.minor = s2n(yypmatch[4], yypmatch[5]);\n            ver.patch = yypmatch[6] ? s2n(yypmatch[6] + 1, yypmatch[7]) : 0;\n            return true;\n        }\n        * { return false; }\n    */\n}\n\nvoid main() {\n    SemVer v;\n    assert(lex(\"23.34\", v) && v.major == 23 && v.minor == 34 && v.patch == 0);\n    assert(lex(\"1.2.999\", v) && v.major == 1 && v.minor == 2 && v.patch == 999);\n    assert(!lex(\"1.a\", v));\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags.re": {
      "content": "// re2d $INPUT -o $OUTPUT\nmodule main;\n\nstruct SemVer {\n    int major;\n    int minor;\n    int patch;\n};\n\nprivate int s2n(const(char)* s, const(char)* e) { // pre-parsed string to number\n    int n = 0;\n    for (; s < e; ++s) n = n * 10 + (*s - '0');\n    return n;\n}\n\nprivate bool lex(const(char)* str, ref SemVer ver) {\n    const(char)* yycursor = str, yymarker;\n\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = 'const(char)* @@;\\n'; */\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = 'const(char)* @@;\\n'; */\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:tags = 1;\n        re2c:YYCTYPE = \"char\";\n\n        num = [0-9]+;\n\n        @t1 num @t2 \".\" @t3 num @t4 (\".\" @t5 num)? [\\x00] {\n            ver.major = s2n(t1, t2);\n            ver.minor = s2n(t3, t4);\n            ver.patch = t5 != null ? s2n(t5, yycursor - 1) : 0;\n            return true;\n        }\n        * { return false; }\n    */\n}\n\nvoid main() {\n    SemVer v;\n    assert(lex(\"23.34\", v) && v.major == 23 && v.minor == 34 && v.patch == 0);\n    assert(lex(\"1.2.999\", v) && v.major == 1 && v.minor == 2 && v.patch == 999);\n    assert(!lex(\"1.a\", v));\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/03_captures.re": {
      "content": "// re2d $INPUT -o $OUTPUT\nmodule main;\n\nstruct SemVer { int major, minor, patch; };\n\nprivate int s2n(const(char)* s, const(char)* e) { // pre-parsed string to number\n    int n = 0;\n    for (; s < e; ++s) n = n * 10 + (*s - '0');\n    return n;\n}\n\nprivate bool lex(const(char)* str, ref SemVer ver) {\n    const(char)* yycursor = str, yymarker;\n\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = 'const(char)* @@;\\n'; */\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = 'const(char)* @@;\\n'; */\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:captvars = 1;\n        re2c:YYCTYPE = \"char\";\n\n        num = [0-9]+;\n\n        (num) \".\" (num) (\".\" num)? [\\x00] {\n            ver.major = s2n(yytl1, yytr1);\n            ver.minor = s2n(yytl2, yytr2);\n            ver.patch = yytl3 ? s2n(yytl3 + 1, yytr3) : 0;\n            return true;\n        }\n        * { return false; }\n    */\n}\n\nvoid main() {\n    SemVer v;\n    assert(lex(\"23.34\", v) && v.major == 23 && v.minor == 34 && v.patch == 0);\n    assert(lex(\"1.2.999\", v) && v.major == 1 && v.minor == 2 && v.patch == 999);\n    assert(!lex(\"1.a\", v));\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags_fill.re": {
      "content": "// re2d $INPUT -o $OUTPUT --tags\nmodule main;\n\nimport core.stdc.string;\nimport core.stdc.stdio;\nimport std.stdio;\n\nenum BUFSIZE = 4095;\n\nstruct Input {\n    FILE* file;\n    char[BUFSIZE + 1] buffer;// +1 for sentinel\n    char* yylimit, yycursor, yymarker, token;\n    // Intermediate tag variables must be part of the lexer state passed to YYFILL.\n    // They don't correspond to tags and should be autogenerated by re2c.\n    /*!stags:re2c format = 'char* @@;'; */\n    bool eof;\n};\n\nstruct SemVer {\n    int major;\n    int minor;\n    int patch;\n};\n\nprivate int s2n(const(char)* s, const(char)* e) { // pre-parsed string to number\n    int n = 0;\n    for (; s < e; ++s) n = n * 10 + (*s - '0');\n    return n;\n}\n\nprivate int fill(ref Input it) {\n    if (it.eof) return 1;\n\n    const size_t shift = it.token - it.buffer.ptr;\n    const size_t used = it.yylimit - it.token;\n\n    // Error: lexeme too long. In real life could reallocate a larger buffer.\n    if (shift < 1) return 2;\n\n    // Shift buffer contents (discard everything up to the current token).\n    memmove(cast(void*)it.buffer.ptr, it.token, used);\n    it.yylimit -= shift;\n    it.yycursor -= shift;\n    it.yymarker -= shift;\n    it.token -= shift;\n    // Tag variables need to be shifted like other input positions. The check\n    // for non-null is only needed if some tags are nested inside of alternative\n    // or repetition, so that they can have null value.\n    /*!stags:re2c format = \"if (it.@@) it.@@ -= shift;\\n\"; */\n\n    // Fill free space at the end of buffer with new data from file.\n    it.yylimit += fread(it.yylimit, 1, BUFSIZE - used, it.file);\n    it.yylimit[0] = 0;\n    it.eof = it.yylimit < (it.buffer.ptr + BUFSIZE);\n    return 0;\n}\n\nprivate bool lex(ref Input yyrecord, ref SemVer[] vers) {\n    // Final variables available in semantic actions.\n    /*!svars:re2c format = 'char* @@;'; */\n    for (;;) {\n        yyrecord.token = yyrecord.yycursor;\n    /*!re2c\n        re2c:api = record;\n        re2c:YYCTYPE = \"char\";\n        re2c:YYFILL = \"fill(yyrecord) == 0\";\n        re2c:eof = 0;\n\n        num = [0-9]+;\n\n        num @t1 \".\" @t2 num @t3 (\".\" @t4 num)? [\\n] {\n            int major = s2n(yyrecord.token, t1);\n            int minor = s2n(t2, t3);\n            int patch = t4 != null ? s2n(t4, yyrecord.yycursor - 1) : 0;\n            SemVer ver = SemVer(major, minor, patch);\n            vers ~= ver;\n            continue;\n        }\n        $ { return true; }\n        * { return false; }\n    */\n    }\n    assert(0);\n}\n\nvoid main() {\n    const char[] fname = \"input\";\n    const char[] content = \"1.22.333\\n' \";\n\n    SemVer[BUFSIZE] expect = SemVer(1, 22, 333);\n    SemVer[] actual;\n\n    // Prepare input file: a few times the size of the buffer, containing\n    // strings with zeroes and escaped quotes.\n    FILE* f = fopen(fname.ptr, \"w\");\n    for (int i = 0; i < BUFSIZE; ++i) {\n        fwrite(cast(const(void*)) content.ptr, 1, content.length - 2, f); // skip null-terminator\n    }\n    fclose(f);\n\n    // Initialize lexer state: all pointers are at the end of buffer.\n    Input it;\n    it.file = fopen(fname.ptr, \"r\");\n    it.yycursor = it.yymarker = it.token = it.yylimit = it.buffer.ptr + BUFSIZE;\n    it.eof = 0;\n    // Sentinel (at YYLIMIT pointer) is set to zero, which triggers YYFILL.\n    it.yylimit[0] = 0;\n\n    // Run the lexer.\n    assert(lex(it, actual) && actual == expect);\n\n    // Cleanup: remove input file.\n    fclose(it.file);\n    remove(fname.ptr);\n}\n",
      "extraCommandLineArguments": "--tags"
    },
    "eof/03_eof_rule.re": {
      "content": "// re2d $INPUT -o $OUTPUT\nmodule main;\n\n// Expect a null-terminated string.\nprivate int lex(immutable char[] s) {\n    const(char)* yycursor = s.ptr, yylimit = s.ptr + s.length, yymarker;\n    int count = 0;\n\n    for (;;) {\n    /*!re2c\n        re2c:YYCTYPE = char;\n        re2c:yyfill:enable = 0;\n        re2c:eof = 0;\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        *    { return -1; }\n        $    { return count; }\n        str  { ++count; continue; }\n        [ ]+ { continue; }\n    */\n    }\n    assert(0); // unreachable\n}\n\nvoid main() {\n    assert(lex(\"\") == 0);\n    assert(lex(\"'qu\\0tes' 'are' 'fine: \\\\'' \") == 3);\n    assert(lex(\"'unterminated\\\\'\") == -1);\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/04_fake_sentinel.re": {
      "content": "// re2d $INPUT -o $OUTPUT\nmodule main;\n\nimport core.stdc.stdlib;\nimport core.stdc.string;\n\nprivate int lex(immutable char[] s) {\n    // For the sake of example create a string without terminating null.\n    char *buf = cast(char*) malloc(s.length);\n    memcpy(buf, cast(const(void*)) s, s.length);\n\n    const(char) *cur = buf, lim = buf + s.length;\n    int count = 0;\n\n    for (;;) {\n    /*!re2c\n        re2c:api = generic;\n        re2c:yyfill:enable = 0;\n        re2c:YYCTYPE = char;\n        re2c:YYPEEK = \"cur < lim ? *cur : 0\";  // fake null\n        re2c:YYSKIP = \"++cur;\";\n\n        *      { count = -1; break; }\n        [\\x00] { break;{} }\n        [a-z]+ { ++count; continue;{} }\n        [ ]+   { continue; }\n    */\n    }\n\n    free(buf);\n    return count;\n}\n\nvoid main() {\n    assert(lex(\"\") == 0);\n    assert(lex(\"one two three \") == 3);\n    assert(lex(\"f0ur\") == -1);\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/02_bounds_checking.re": {
      "content": "// re2d $INPUT -o $OUTPUT\nmodule main;\n\nimport core.stdc.stdlib;\nimport core.stdc.string;\n\n/*!max:re2c*/\n\nprivate int lex(immutable char[] s) {\n    // Make a copy of the string with YYMAXFILL zeroes at the end.\n    char *buf = cast(char*) malloc(s.length + YYMaxFill);\n    memcpy(buf, cast(const(void*)) s, s.length);\n    memset(buf + s.length, 0, YYMaxFill);\n\n    const(char)* yycursor = buf;\n    const(char)* yylimit = buf + s.length + YYMaxFill;\n    int count = 0;\n\nloop:\n    /*!re2c\n        re2c:YYCTYPE = char;\n        re2c:YYFILL = \"goto fail;\";\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        [\\x00] {\n            // Check that it is the sentinel, not some unexpected null.\n            if (yycursor - 1 == buf + s.length) goto exit; else goto fail;\n        }\n        str  { ++count; goto loop; }\n        [ ]+ { goto loop; }\n        *    { goto fail; }\n    */\nfail:\n    count = -1;\nexit:\n    free(buf);\n    return count;\n}\n\nvoid main() {\n    assert(lex(\"\") == 0);\n    assert(lex(\"'qu\\0tes' 'are' 'fine: \\\\'' \") == 3);\n    assert(lex(\"'unterminated\\\\'\") == -1);\n    assert(lex(\"'unexpected \\0 null\\\\'\") == -1);\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/01_sentinel.re": {
      "content": "// re2d $INPUT -o $OUTPUT\nmodule main;\n\n// Expect a null-terminated string.\nprivate int lex(const(char)* yycursor) {\n    uint count = 0;\n\n    for (;;) {\n    /*!re2c\n        re2c:YYCTYPE = char;\n        re2c:yyfill:enable = 0;\n\n        *      { return -1; }\n        [\\x00] { return count; }\n        [a-z]+ { ++count; continue; }\n        [ ]+   { continue; }\n    */\n    }\n    assert(0); // unreachable\n}\n\nvoid main() {\n    assert(lex(\"\") == 0);\n    assert(lex(\"one two three\") == 3);\n    assert(lex(\"f0ur\") == -1);\n}\n",
      "extraCommandLineArguments": ""
    },
    "includes/include.re": {
      "content": "// re2d $INPUT -o $OUTPUT -i\n\n/*!include:re2c \"definitions.d\" */\n\nprivate Result lex(const(char)* s) {\n    const(char)* yycursor = s, yymarker;\n    /*!re2c\n        re2c:YYCTYPE = \"char\";\n        re2c:yyfill:enable = 0;\n\n        *      { return Result.FAIL; }\n        number { return Result.OK; }\n        !include \"extra_rules.re.inc\";\n    */\n}\n\nvoid main() {\n    assert(lex(\"123\") == Result.OK);\n    assert(lex(\"123.4567\") == Result.OK);\n}\n",
      "extraCommandLineArguments": "-i"
    },
    "encodings/unicode_identifier.re": {
      "content": "// re2d $INPUT -o $OUTPUT -8 -i\nmodule main;\n\n/*!include:re2c \"unicode_categories.re\" */\n\nprivate int lex(const(char)* s) {\n    const(char)* yycursor = s, yymarker;\n    /*!re2c\n        re2c:YYCTYPE = \"char\";\n        re2c:yyfill:enable = 0;\n\n        // Simplified \"Unicode Identifier and Pattern Syntax\"\n        // (see https://unicode.org/reports/tr31)\n        id_start    = L | Nl | [$_];\n        id_continue = id_start | Mn | Mc | Nd | Pc | [\\u200D\\u05F3];\n        identifier  = id_start id_continue*;\n        identifier { return 0; }\n        *          { return 1; }\n    */\n}\n\nvoid main() {\n    assert(lex(\"_\u042b\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\") == 0);\n    assert(lex(\"!!!\")==1);\n}\n",
      "extraCommandLineArguments": "-8 -i"
    },
    "reuse/reuse.re": {
      "content": "// re2d $INPUT -o $OUTPUT --input-encoding utf8\nmodule main;\n\nimport std.stdint;\n\n// This example supports multiple input encodings: UTF-8 and UTF-32.\n// Both lexers are generated from the same rules block, and the use\n// blocks add only encoding-specific configurations.\n/*!rules:re2c\n    re2c:yyfill:enable = 0;\n\n    \"\u2200x \u2203y\" { return 0; }\n    *       { return 1; }\n*/\n\nprivate int lex_utf8(const(uint8_t)* s) {\n    const(uint8_t)* yycursor = s, yymarker;\n    /*!use:re2c\n        re2c:YYCTYPE = uint8_t;\n        re2c:encoding:utf8 = 1;\n    */\n}\n\nprivate int lex_utf32(const(uint32_t)* s) {\n    const(uint32_t)* yycursor = s, yymarker;\n    /*!use:re2c\n        re2c:YYCTYPE = uint32_t;\n        re2c:encoding:utf32 = 1;\n    */\n}\n\nvoid main() {\n    immutable uint8_t[] s8 = // UTF-8\n        [ 0xe2, 0x88, 0x80, 0x78, 0x20, 0xe2, 0x88, 0x83, 0x79 ];\n\n    immutable uint32_t[] s32 = // UTF32\n        [ 0x00002200, 0x00000078, 0x00000020, 0x00002203, 0x00000079 ];\n\n    assert(lex_utf8(cast(const(uint8_t)*)s8) == 0);\n    assert(lex_utf32(cast(const(uint32_t)*)s32) == 0);\n}\n",
      "extraCommandLineArguments": "--input-encoding utf8"
    },
    "reuse/usedir.re": {
      "content": "// re2d $INPUT -o $OUTPUT\nmodule main;\n\n// This example shows how to combine reusable re2c blocks: two blocks\n// ('colors' and 'fish') are merged into one. The 'salmon' rule occurs\n// in both blocks; the 'fish' block takes priority because it is used\n// earlier. Default rule * occurs in all three blocks; the local (not\n// inherited) definition takes priority.\n\nenum What { COLOR, FISH, DUNNO };\n\n/*!rules:re2c:colors\n    *                            { assert(false); }\n    \"red\" | \"salmon\" | \"magenta\" { return What.COLOR; }\n*/\n\n/*!rules:re2c:fish\n    *                            { assert(false); }\n    \"haddock\" | \"salmon\" | \"eel\" { return What.FISH; }\n*/\n\nprivate What lex(const(char)* s) {\n    const(char)* yycursor = s, yymarker;\n    /*!re2c\n        re2c:YYCTYPE = \"char\";\n        re2c:yyfill:enable = 0;\n\n        !use:fish;\n        !use:colors;\n        * { return What.DUNNO; } // overrides inherited '*' rules\n    */\n}\n\nvoid main() {\n    assert(lex(\"salmon\") == What.FISH);\n    assert(lex(\"what?\") == What.DUNNO);\n}\n",
      "extraCommandLineArguments": ""
    },
    "headers/header.re": {
      "content": "// re2d $INPUT -o $OUTPUT -i --header lexer/state.d\nmodule main;\n\nimport core.stdc.stddef;\nimport lexer.state; // the module is generated by re2c\n\n/*!header:re2c:on*/\nmodule lexer.state;\n\nstruct LexerState {\n    const(char)* str, yycursor;\n    /*!stags:re2c format = \"const(char)* @@;\"; */\n};\n/*!header:re2c:off*/\n\nprivate long lex(ref LexerState yyrecord) {\n    const(char)* t;\n    /*!re2c\n        re2c:api = record;\n        re2c:YYCTYPE = \"char\";\n        re2c:tags = 1;\n        re2c:yyfill:enable = 0;\n        re2c:header = \"lexer/state.d\";\n\n        [a]* @t [b]* { return t - yyrecord.str; }\n    */\n}\n\nvoid main() {\n    const(char)* s = \"ab\";\n    LexerState st = {s, s /*!stags:re2c format = \", null\"; */};\n    assert(lex(st) == 1);\n\n    const(char)* s2 = \"aaabbbbbbbb\";\n    LexerState st2 = {s2, s2 /*!stags:re2c format = \", null\"; */};\n    assert(lex(st2) == 3);\n}\n",
      "extraCommandLineArguments": "-i --header lexer/state.d"
    }
  },
  "haskell": {
    "01_basic.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT -i\n{-# LANGUAGE OverloadedStrings #-}\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n\nimport Data.ByteString (ByteString, index)\n\ndata State = State {\n    _yyinput :: ByteString,\n    _yycursor :: Int\n}\n\n%{\n    re2c:YYFN = [\"lexer;Bool\", \"State{..};State\"];\n    re2c:yyfill:enable = 0;\n\n    [1-9][0-9]* { True }\n    *           { False }\n%}\n\nmain :: IO ()\nmain = case lexer State{_yyinput = \"1234\\0\", _yycursor = 0} of\n    True -> return ()\n    False -> error \"lexer failed!\"\n",
      "extraCommandLineArguments": "-i"
    },
    "fill/01_fill.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\nimport Control.Monad\nimport Data.ByteString as BS\nimport Data.Word\nimport GHC.IO.Handle\nimport System.Directory\nimport System.IO\n\nchunk_size :: Int\nchunk_size = 4096\n\ndata State = State {\n    _file :: !Handle,\n    _yyinput :: !BS.ByteString,\n    _yycursor :: !Int,\n    _yymarker :: !Int,\n    _yylimit :: !Int,\n    _token :: !Int,\n    _eof :: !Bool,\n    _count :: !Int\n}\n\n%{\n    re2c:YYFN = [\"lexer;IO Int\", \"State{..};State;!State{..}\"];\n    re2c:YYCTYPE = \"Word8\";\n    re2c:YYPEEK = \"BS.index\";\n    re2c:YYFILL = \"(State{..}, yyfill) <- fill State{..}\";\n    re2c:eof = 0;\n    re2c:monadic = 1;\n\n    str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n    *    { return (-1) }\n    $    { return _count }\n    str  { lexer State{_token = _yycursor, _count = _count + 1, ..} }\n    [ ]+ { lexer State{_token = _yycursor, ..} }\n%}\n\nfill :: State -> IO (State, Bool)\nfill State{..} = do\n    case _eof of\n        True -> return (State{..}, False)\n        False -> do\n            -- Discard everything up to the current token, cut off terminating null,\n            -- read new chunk from file and reappend terminating null at the end.\n            chunk <- BS.hGet _file chunk_size\n            return (State {\n                _yyinput = BS.concat [(BS.init . BS.drop _token) _yyinput, chunk, \"\\0\"],\n                _yycursor = _yycursor - _token,\n                _yymarker = _yymarker - _token,\n                _yylimit = _yylimit - _token + BS.length chunk, -- exclude terminating null\n                _token = 0,\n                _eof = BS.null chunk, -- end of file?\n                ..}, True)\n\nmain :: IO ()\nmain = do\n    let fname = \"input\"\n\n    -- Prepare input file.\n    BS.writeFile fname $ BS.concat [\"'qu\\0tes' 'are' 'fine: \\\\'' \" | _ <- [1..chunk_size]]\n    let expect = 3 * chunk_size -- the total number of strings in file\n\n    -- Run lexer on the prepared file.\n    fh <- openFile fname ReadMode\n    let st = State {\n        _file = fh,\n        _yyinput = BS.singleton 0,\n        _yycursor = 0,\n        _yymarker = 0,\n        _token = 0,\n        _yylimit = 0,\n        _eof = False,\n        _count = 0\n    }\n    result <- lexer st\n    hClose fh\n\n    -- Cleanup.\n    removeFile fname\n\n    -- Check result.\n    when (result /= expect) $ error $ \"expected \" ++ show expect ++ \", got \" ++ show result\n    return ()\n",
      "extraCommandLineArguments": ""
    },
    "fill/02_fill.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\nimport Control.Monad\nimport qualified Data.ByteString as BS\nimport GHC.IO.Handle\nimport System.Directory\nimport System.IO\n\nchunk_size :: Int\nchunk_size = 4096\n\ndata State = State {\n    _file :: !Handle,\n    _yyinput :: !BS.ByteString,\n    _yycursor :: !Int,\n    _yylimit :: !Int,\n    _token :: !Int,\n    _eof :: !Bool,\n    _count :: !Int\n}\n\n%{\n    re2c:YYFN = [\"lexer;IO Int\", \"State{..};State;!State{..}\"];\n    re2c:YYPEEK = \"BS.index\";\n\n    // We have to turn off autogenerated YFILL check and write it manually as part of YYFILL\n    // implementation, so that we can propagate the updated state out of it.\n    re2c:yyfill:check = 0;\n    re2c:YYFILL = \"State{..} <- fill State{..} @@\";\n    re2c:monadic = 1;\n\n    str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n    *      { return (-1) }\n    [\\x00] { return $ if _yycursor == _yylimit - yymaxfill + 1 then _count else (-1) }\n    str    { lexer State{_token = _yycursor, _count = _count + 1, ..} }\n    [ ]+   { lexer State{_token = _yycursor, ..} }\n%}\n\nyymaxfill :: Int\n%{max %}\n\nfill :: State -> Int -> IO State\nfill !st@State{..} !need =\n    if _yylimit - _yycursor >= need then\n        return st\n    else case _eof of\n        True -> error \"fill failed\"\n        False -> do\n            -- Discard everything up to the current token, cut off terminating null,\n            -- read new chunk from file and reappend terminating null at the end.\n            chunk <- BS.hGet _file chunk_size\n            let !eof = BS.length chunk < need -- end of file ?\n            let !buf = BS.concat [\n                    BS.drop _token _yyinput,\n                    chunk,\n                    if eof then (BS.replicate yymaxfill 0) else BS.empty]\n            return State {\n                _yyinput = buf,\n                _yycursor = _yycursor - _token,\n                _yylimit = BS.length buf,\n                _token = 0,\n                _eof = eof,\n                ..}\n\nmain :: IO ()\nmain = do\n    let fname = \"input\"\n\n    -- Prepare input file.\n    BS.writeFile fname $ BS.concat [\"'qu\\0tes' 'are' 'fine: \\\\'' \" | _ <- [1..chunk_size]]\n    let expect = 3 * chunk_size -- the total number of strings in file\n\n    -- Run lexer on the prepared file.\n    fh <- openFile fname ReadMode\n    let st = State {\n        _file = fh,\n        _yyinput = BS.empty,\n        _yycursor = 0,\n        _token = 0,\n        _yylimit = 0,\n        _eof = False,\n        _count = 0\n    }\n    result <- lexer st\n    hClose fh\n\n    -- Cleanup.\n    removeFile fname\n\n    -- Check result.\n    when (result /= expect) $ error $ \"expected \" ++ show expect ++ \", got \" ++ show result\n    return ()\n",
      "extraCommandLineArguments": ""
    },
    "conditions/parse_u32_conditions.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT -ci\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\nimport Control.Monad (when)\nimport Data.ByteString (ByteString, index)\n\n%{conditions %}\n\ndata State = State {\n    _yyinput :: !ByteString,\n    _yycursor :: !Int,\n    _yymarker :: !Int,\n    _yycond :: !YYCONDTYPE\n}\n\npeek_digit :: ByteString -> Int -> Int -> Int\npeek_digit str idx offs = fromIntegral (index str (idx - 1)) - offs\n\n%{\n    re2c:YYFN = [\"parse;Maybe Int\", \"State{..};State\", \"_num;Int\"];\n    re2c:yyfill:enable = 0;\n\n    <init> '0b' / [01]        :=> bin\n    <init> \"0\"                :=> oct\n    <init> \"\" / [1-9]         :=> dec\n    <init> '0x' / [0-9a-fA-F] :=> hex\n    <init> * { Nothing }\n\n    <bin> [01]  { yyfnbin State{..} $ _num * 2 + (peek_digit _yyinput _yycursor 48) }\n    <oct> [0-7] { yyfnoct State{..} $ _num * 8 + (peek_digit _yyinput _yycursor 48) }\n    <dec> [0-9] { yyfndec State{..} $ _num * 10 + (peek_digit _yyinput _yycursor 48) }\n    <hex> [0-9] { yyfnhex State{..} $ _num * 16 + (peek_digit _yyinput _yycursor 48) }\n    <hex> [a-f] { yyfnhex State{..} $ _num * 16 + (peek_digit _yyinput _yycursor 87) }\n    <hex> [A-F] { yyfnhex State{..} $ _num * 16 + (peek_digit _yyinput _yycursor 55) }\n\n    <bin, oct, dec, hex> * { Just _num }\n%}\n\ntest :: ByteString -> Maybe Int -> IO ()\ntest str expect = do\n    let s = State {\n            _yyinput = str,\n            _yycursor = 0,\n            _yymarker = 0,\n            _yycond = YYC_init}\n    when (parse s 0 /= expect) $ error \"failed!\"\n\nmain :: IO ()\nmain = do\n    test \"\\0\" Nothing\n    test \"1234567890\\0\" (Just 1234567890)\n    test \"0b1101\\0\" (Just 13)\n    test \"0x7Fe\\0\" (Just 2046)\n    test \"0644\\0\" (Just 420)\n    test \"9223372036854775807\\0\" (Just 9223372036854775807)\n",
      "extraCommandLineArguments": "-ci"
    },
    "conditions/parse_u32_blocks.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT -i\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\nimport Control.Monad (when)\nimport Data.ByteString (ByteString, index)\n\ndata State = State {\n    _yyinput :: !ByteString,\n    _yycursor :: !Int,\n    _yymarker :: !Int\n}\n\npeek_digit :: ByteString -> Int -> Int -> Int\npeek_digit str idx offs = fromIntegral (index str (idx - 1)) - offs\n\n%{\n    re2c:yyfill:enable = 0;\n%}\n\n%{local\n    re2c:YYFN = [\"parse_bin;Int\", \"State{..};State\", \"num;Int\"];\n    [01] { parse_bin State{..} $ num * 2 + (peek_digit _yyinput _yycursor 48) }\n    *    { num }\n%}\n\n%{local\n    re2c:YYFN = [\"parse_oct;Int\", \"State{..};State\", \"num;Int\"];\n    [0-7] { parse_oct State{..} $ num * 8 + (peek_digit _yyinput _yycursor 48) }\n    *     { num }\n%}\n\n%{local\n    re2c:YYFN = [\"parse_dec;Int\", \"State{..};State\", \"num;Int\"];\n    [0-9] { parse_dec State{..} $ num * 10 + (peek_digit _yyinput _yycursor 48) }\n    *     { num }\n%}\n\n%{local\n    re2c:YYFN = [\"parse_hex;Int\", \"State{..};State\", \"num;Int\"];\n    [0-9] { parse_hex State{..} $ num * 16 + (peek_digit _yyinput _yycursor 48) }\n    [a-f] { parse_hex State{..} $ num * 16 + (peek_digit _yyinput _yycursor 87) }\n    [A-F] { parse_hex State{..} $ num * 16 + (peek_digit _yyinput _yycursor 55) }\n    *     { num }\n%}\n\n%{local\n    re2c:YYFN = [\"parse;Maybe Int\", \"State{..};State\"];\n    '0b' / [01]        { Just $ parse_bin State{..} 0 }\n    \"0\"                { Just $ parse_oct State{..} 0 }\n    \"\" / [1-9]         { Just $ parse_dec State{..} 0 }\n    '0x' / [0-9a-fA-F] { Just $ parse_hex State{..} 0 }\n    *                  { Nothing }\n%}\n\ntest :: ByteString -> Maybe Int -> IO ()\ntest str expect = do\n    let s = State {_yyinput = str, _yycursor = 0, _yymarker = 0}\n    when (parse s /= expect) $ error \"failed!\"\n\nmain :: IO ()\nmain = do\n    test \"\\0\" Nothing\n    test \"1234567890\\0\" (Just 1234567890)\n    test \"0b1101\\0\" (Just 13)\n    test \"0x7Fe\\0\" (Just 2046)\n    test \"0644\\0\" (Just 420)\n    test \"9223372036854775807\\0\" (Just 9223372036854775807)\n",
      "extraCommandLineArguments": "-i"
    },
    "state/push.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT -fi\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\nimport Control.Concurrent.Chan\nimport Control.Monad\nimport Data.ByteString as BS\nimport Text.Printf\n\ndebug :: IO () -> IO ()\ndebug = when False\n\ndata State = State {\n    _pipe :: !(Chan BS.ByteString),\n    _yyinput :: !BS.ByteString,\n    _yycursor :: !Int,\n    _yymarker :: !Int,\n    _yylimit :: !Int,\n    _token :: !Int,\n    _eof :: !Bool,\n    _yystate :: !Int,\n    _recv :: !Int\n}\n\ndata Status = End | Ready | Waiting | BadPacket deriving (Eq)\n\n%{\n    re2c:YYFN = [\"lexer;IO (State, Status)\", \"State{..};State;!State{..}\"];\n    re2c:YYPEEK = \"BS.index\";\n    re2c:YYFILL = \"return (State{..}, Waiting)\";\n    re2c:eof = 0;\n    re2c:monadic = 1;\n\n    packet = [a-z]+[;];\n\n    *      { return (State{..}, BadPacket) }\n    $      { return (State{..}, End) }\n    packet { lexer State{_token = _yycursor, _recv = _recv + 1, ..} }\n%}\n\nfill :: State -> IO (State, Status)\nfill st@State{..} = do\n    case _eof of\n        True -> return (st, End)\n        False -> do\n            -- Discard everything up to the current token, cut off terminating null,\n            -- read new chunk from file and reappend terminating null at the end.\n            chunk <- readChan _pipe\n            return (State {\n                _yyinput = BS.concat [(BS.init . BS.drop _token) _yyinput, chunk, \"\\0\"],\n                _yycursor = _yycursor - _token,\n                _yymarker = _yymarker - _token,\n                _yylimit = _yylimit - _token + BS.length chunk, -- exclude terminating null\n                _token = 0,\n                _eof = BS.null chunk, -- end of file?\n                ..}, Ready)\n\nloop :: State -> [BS.ByteString] -> IO Status\nloop State{..} packets = do\n    (State{..}, status) <- lexer State{..}\n    case status of\n        End -> do\n            debug $ printf \"done: got %d packets\\n\" _recv\n            return End\n        Waiting -> do\n            debug $ printf \"waiting...\\n\"\n            packets' <- case packets of\n                [] -> do\n                    writeChan _pipe BS.empty\n                    return []\n                p:ps -> do\n                    debug $ printf \"sent packet '%s'\\n\" (show p)\n                    writeChan _pipe p\n                    return ps\n            (State{..}, status') <- fill State{..}\n            case status' of\n                Ready -> loop State{..} packets'\n                _ -> error \"unexpected status after fill\"\n        BadPacket -> do\n            debug $ printf \"error: ill-formed packet\\n\"\n            return BadPacket\n        _ -> error \"unexpected status\"\n\ntest :: [BS.ByteString] -> Status -> IO ()\ntest packets expect = do\n    pipe <- newChan -- emulate pipe using a chan of bytestrings\n    let st = State {\n        _pipe = pipe,\n        _yyinput = BS.singleton 0, -- null sentinel triggers YYFILL\n        _yycursor = 0,\n        _yymarker = 0,\n        _token = 0,\n        _yylimit = 0,\n        _eof = False,\n        _yystate = -1,\n        _recv = 0\n    }\n    status <- loop st packets\n    when (status /= expect) $ error \"failed\"\n    return ()\n\nmain :: IO ()\nmain = do\n    test [] End\n    test [\"ze\", \"ro;o\", \"ne\", \";t\", \"wo;thr\", \"e\", \"e\", \";\", \"four;\"] End\n    test [\"zer0;\"] BadPacket\n",
      "extraCommandLineArguments": "-fi"
    },
    "submatch/02_mtags.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\nimport Control.Monad (when)\nimport Data.ByteString (ByteString, index)\n\ndata State = State {\n    -- Final tag bindings available in semantic action.\n    %{svars format = \"\\n@@ :: !Int,\"; %}\n    %{mvars format = \"\\n@@ :: ![Int],\"; %}\n    -- Intermediate tag bindings used by the lexer (must be autogenerated).\n    %{stags format = \"\\n@@ :: !Int,\"; %}\n    %{mtags format = \"\\n@@ :: ![Int],\"; %}\n    _yyinput :: !ByteString,\n    _yycursor :: !Int,\n    _yymarker :: !Int\n}\n\ns2n :: ByteString -> Int -> Int -> Int\ns2n s i j = f i 0 where\n    f k n = if k >= j then n else f (k + 1) (n * 10 + (fromIntegral (index s k) - 48))\n\n%{\n    re2c:YYFN = [\"parse;Maybe [Int]\", \"State{..};State\"];\n    re2c:YYMTAGP = \"let tag = _yycursor : @@{tag} in let @@{tag} = tag in\";\n    re2c:YYMTAGN = \"\"; // alternatively could add -1 to the list\n    re2c:tags = 1;\n    re2c:yyfill:enable = 0;\n\n    num = [0-9]+;\n\n    @_1 num @_2 (\".\" #_3 num #_4)* [\\x00] {\n        Just $ (s2n _yyinput _1 _2) : (reverse $ zipWith (\\i j -> s2n _yyinput i j) _3 _4)\n    }\n    * { Nothing }\n%}\n\ntest :: ByteString -> Maybe [Int] -> IO ()\ntest str expect = do\n    let st = State {\n        %{svars format = \"\\n@@ = (-1),\"; %}\n        %{stags format = \"\\n@@ = (-1),\"; %}\n        %{mvars format = \"\\n@@ = [],\"; %}\n        %{mtags format = \"\\n@@ = [],\"; %}\n        _yyinput = str,\n        _yycursor = 0,\n        _yymarker = 0\n    }\n    when (parse st /= expect) $ error \"failed!\"\n\nmain :: IO ()\nmain = do\n    test \"1\\0\" (Just [1])\n    test \"1.2.3.4.5.6.7\\0\" (Just [1, 2, 3, 4, 5, 6, 7])\n    test \"1.2.\\0\" Nothing\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\nimport Control.Monad (when)\nimport Data.ByteString (ByteString, index)\n\ndata State = State {\n    -- Final tag bindings available in semantic action.\n    %{svars format = \"\\n@@ :: !Int,\"; %}\n    -- Intermediate tag bindings used by the lexer (must be autogenerated).\n    %{stags format = \"\\n@@ :: !Int,\"; %}\n    _yyinput :: !ByteString,\n    _yycursor :: !Int,\n    _yymarker :: !Int\n}\n\ndata SemVer = SemVer {\n    major :: !Int,\n    minor :: !Int,\n    patch :: !Int\n} deriving (Eq)\n\ns2n :: ByteString -> Int -> Int -> Int\ns2n s i j = f i 0 where\n    f k n = if k >= j then n else f (k + 1) (n * 10 + (fromIntegral (index s k) - 48))\n\n%{\n    re2c:YYFN = [\"parse;Maybe SemVer\", \"State{..};State\"];\n    re2c:tags = 1;\n    re2c:yyfill:enable = 0;\n\n    num = [0-9]+;\n\n    @_1 num @_2 \".\" @_3 num @_4 (\".\" @_5 num)? [\\x00] {\n        Just SemVer {\n            major = s2n _yyinput _1 _2,\n            minor = s2n _yyinput _3 _4,\n            patch = if _5 == (-1) then 0 else s2n _yyinput _5 (_yycursor - 1)\n        }\n    }\n    * { Nothing }\n%}\n\ntest :: ByteString -> Maybe SemVer -> IO ()\ntest str expect = do\n    let s = State {\n        %{svars format = \"\\n@@ = (-1),\"; %}\n        %{stags format = \"\\n@@ = (-1),\"; %}\n        _yyinput = str,\n        _yycursor = 0,\n        _yymarker = 0\n    }\n    when (parse s /= expect) $ error \"failed!\"\n\nmain :: IO ()\nmain = do\n    test \"23.34\\0\" (Just SemVer {major = 23, minor = 34, patch = 0})\n    test \"1.2.99999\\0\" (Just SemVer {major = 1, minor = 2, patch = 99999})\n    test \"1.a\\0\" Nothing\n",
      "extraCommandLineArguments": ""
    },
    "submatch/03_captures.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\nimport Control.Monad (when)\nimport Data.ByteString (ByteString, index)\nimport Data.Word (Word8)\n\nnone :: Int\nnone = -1\n\ndata State = State {\n    -- Final tag bindings available in semantic action.\n    %{svars format = \"\\n@@ :: !Int,\"; %}\n    -- Intermediate tag bindings used by the lexer (must be autogenerated).\n    %{stags format = \"\\n@@ :: !Int,\"; %}\n    _yyinput :: !ByteString,\n    _yycursor :: !Int,\n    _yymarker :: !Int\n}\n\ndata SemVer = SemVer {\n    major :: !Int,\n    minor :: !Int,\n    patch :: !Int\n} deriving (Eq)\n\ns2n :: ByteString -> Int -> Int -> Int\ns2n s i j = f i 0 where\n    f k n = if k >= j then n else f (k + 1) (n * 10 + (fromIntegral (index s k) - 48))\n\n%{\n    re2c:YYFN = [\"parse;Maybe SemVer\", \"State{..};State\"];\n    re2c:YYCTYPE = \"Word8\";\n    re2c:captvars = 1;\n    re2c:yypmatch = _;\n    re2c:yyfill:enable = 0;\n\n    num = [0-9]+;\n\n    (num) \".\" (num) (\".\" num)? [\\x00] {\n        Just SemVer {\n            major = s2n _yyinput _yytl1 _yytr1,\n            minor = s2n _yyinput _yytl2 _yytr2,\n            patch = if _yytl3 == none then 0 else s2n _yyinput (_yytl3 + 1) _yytr3\n        }\n    }\n    * { Nothing }\n%}\n\ntest :: ByteString -> Maybe SemVer -> IO ()\ntest str expect = do\n    let s = State {\n        %{svars format = \"\\n@@ = none,\"; %}\n        %{stags format = \"\\n@@ = none,\"; %}\n        _yyinput = str,\n        _yycursor = 0,\n        _yymarker = 0\n    }\n    when (parse s /= expect) $ error \"failed!\"\n\nmain :: IO ()\nmain = do\n    test \"23.34\\0\" (Just SemVer {major = 23, minor = 34, patch = 0})\n    test \"1.2.99999\\0\" (Just SemVer {major = 1, minor = 2, patch = 99999})\n    test \"1.a\\0\" Nothing\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags_fill.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\nimport Control.Monad\nimport Data.ByteString as BS\nimport GHC.IO.Handle\nimport System.Directory\nimport System.IO\n\nchunk_size :: Int\nchunk_size = 4096\n\ndata State = State {\n    _file :: !Handle,\n    _yyinput :: !BS.ByteString,\n    _yycursor :: !Int,\n    _yymarker :: !Int,\n    _yylimit :: !Int,\n    _token :: !Int,\n    -- Final tag bindings available in semantic action.\n    %{svars format = \"\\n@@ :: !Int,\"; %}\n    -- Intermediate tag bindings used by the lexer (must be autogenerated).\n    %{stags format = \"\\n@@ :: !Int,\"; %}\n    _eof :: !Bool\n}\n\ndata SemVer = SemVer {\n    major :: !Int,\n    minor :: !Int,\n    patch :: !Int\n} deriving (Eq, Show)\n\ns2n :: BS.ByteString -> Int -> Int -> Int\ns2n s i j = f i 0 where\n    f k n = if k >= j then n else f (k + 1) (n * 10 + (fromIntegral (BS.index s k) - 48))\n\n%{\n    re2c:YYFN = [\"lexer;IO [SemVer]\", \"State{..};State\", \"_vers;[SemVer]\"];\n    re2c:YYPEEK = \"BS.index\";\n    re2c:YYFILL = \"(State{..}, yyfill) <- fill State{..}\";\n    re2c:eof = 0;\n    re2c:monadic = 1;\n    re2c:tags = 1;\n\n    num = [0-9]+;\n\n    @_1 num @_2 \".\" @_3 num @_4 (\".\" @_5 num)? [\\n] {\n        let ver = SemVer {\n            major = s2n _yyinput _1 _2,\n            minor = s2n _yyinput _3 _4,\n            patch = if _5 == (-1) then 0 else s2n _yyinput _5 (_yycursor - 1)\n        }\n        lexer State{..} (ver: _vers)\n    }\n    $ { return _vers }\n    * { error \"lexer failed\" }\n%}\n\nfill :: State -> IO (State, Bool)\nfill State{..} = do\n    case _eof of\n        True -> return (State{..}, False)\n        False -> do\n            -- Discard everything up to the current token, cut off terminating null,\n            -- read new chunk from file and reappend terminating null at the end.\n            chunk <- BS.hGet _file chunk_size\n            return (State{\n                _yyinput = BS.concat [(BS.init . BS.drop _token) _yyinput, chunk, \"\\0\"],\n                _yycursor = _yycursor - _token,\n                _yymarker = _yymarker - _token,\n                _yylimit = _yylimit - _token + BS.length chunk, -- exclude terminating null\n                _token = 0,\n                _eof = BS.null chunk, -- end of file?\n                ..}, True)\n\nmain :: IO ()\nmain = do\n    let fname = \"input\"\n\n    -- Prepare input file.\n    BS.writeFile fname $ BS.concat [\"1.22.333\\n\" | _ <- [1..chunk_size]]\n    let expect = [SemVer {major = 1, minor = 22, patch = 333} | _ <- [1..chunk_size]]\n\n    -- Run lexer on the prepared file.\n    fh <- openFile fname ReadMode\n    let st = State {\n        _file = fh,\n        _yyinput = BS.singleton 0,\n        _yycursor = 0,\n        _yymarker = 0,\n        _yylimit = 0,\n        _token = 0,\n        %{svars format = \"\\n@@ = (-1),\"; %}\n        %{stags format = \"\\n@@ = (-1),\"; %}\n        _eof = False\n    }\n    result <- lexer st []\n    hClose fh\n\n    -- Cleanup.\n    removeFile fname\n\n    -- Check result.\n    when (result /= expect) $ error $ \"expected \" ++ show expect ++ \", got \" ++ show result\n    return ()\n",
      "extraCommandLineArguments": ""
    },
    "eof/03_eof_rule.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\nimport Control.Monad (when)\nimport qualified Data.ByteString as BS\nimport Data.Word\n\ndata State = State {\n    _yyinput :: BS.ByteString,\n    _yycursor :: Int,\n    _yymarker :: Int,\n    _yylimit :: Int,\n    _count :: Int\n}\n\n-- expect a null-terminated string\n%{\n    re2c:YYFN = [\"lexer;Int\", \"State{..};State\"];\n    re2c:YYCTYPE = \"Word8\";\n    re2c:YYPEEK = \"BS.index\";\n    re2c:eof = 0;\n    re2c:yyfill:enable = 0;\n\n    str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n    *    { (-1) }\n    $    { _count }\n    str  { lexer State{_count = _count + 1, ..} }\n    [ ]+ { lexer State{..} }\n%}\n\nmain :: IO ()\nmain = do\n    let test s n = do\n            let st = State {\n                    _yyinput = s,\n                    _yycursor = 0, \n                    _yymarker = 0,\n                    _yylimit = BS.length s - 1, -- terminating null not included\n                    _count = 0}\n\n            when (lexer st /= n) $ error \"failed\"\n\n    test \"\\0\" 0\n    test \"'qu\\0tes' 'are' 'fine: \\\\'' \\0\" 3\n    test \"'unterminated\\\\'\\0\" (-1)\n",
      "extraCommandLineArguments": ""
    },
    "eof/04_fake_sentinel.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\nimport Control.Monad (when)\nimport qualified Data.ByteString as BS\n\ndata State = State {\n    _str :: BS.ByteString,\n    _cur :: Int,\n    _lim :: Int,\n    _cnt :: Int\n}\n\n-- Expect a string without terminating null.\n%{\n    re2c:api = generic;\n    re2c:YYFN = [\"lexer;Int\", \"State{..};State\"];\n    re2c:YYPEEK = \"if _cur < _lim then BS.index _str _cur else 0\";\n    re2c:YYSKIP = \"let cur = _cur + 1 in let _cur = cur in\";\n    re2c:yyfill:enable = 0;\n\n    *      { (-1) }\n    [\\x00] { _cnt }\n    [a-z]+ { lexer State{_cnt = _cnt + 1, ..} }\n    [ ]+   { lexer State{..} }\n%}\n\nmain :: IO ()\nmain = do\n    let test s n =\n            let st = State {_str = s, _cur = 0, _lim = BS.length s, _cnt = 0}\n            in when (lexer st /= n) $ error \"failed\"\n\n    test \"\" 0\n    test \"one two three \" 3\n    test \"f0ur\" (-1)\n",
      "extraCommandLineArguments": ""
    },
    "eof/02_bounds_checking.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\nimport Control.Exception\nimport Control.Monad (when)\nimport qualified Data.ByteString as BS\n\ndata State = State {\n    _yyinput :: BS.ByteString,\n    _yycursor :: Int,\n    _yylimit :: Int,\n    _count :: Int\n}\n\ndata FillException = UnexpectedFill deriving (Show)\ninstance Exception FillException\n\nyymaxfill :: Int\n%{max %}\n\n%{\n    re2c:YYFN  = [\"lexer;IO Int\", \"State{..};State\"];\n    re2c:YYPEEK = \"BS.index\";\n    re2c:YYFILL = \"throw UnexpectedFill\";\n    re2c:monadic = 1; // YYFILL requires monadic do-notation for `when` conditions\n\n    str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n    [\\x00] {\n        -- check that it is the sentinel, not some unexpected null\n        return $ if _yycursor == BS.length _yyinput - yymaxfill + 1 then _count else (-1)\n    }\n    str  { lexer State{_count = _count + 1, ..} }\n    [ ]+ { lexer State{..} }\n    *    { return (-1) }\n%}\n\nmain :: IO ()\nmain = do\n    let test s n = do\n            let buf = BS.concat [s, BS.replicate yymaxfill 0]\n            let st = State {\n                    _yyinput = buf,\n                    _yycursor = 0,\n                    _yylimit = BS.length buf,\n                    _count = 0}\n            m <- catch (lexer st) (\\(_ :: FillException) -> return (-2))\n            when (m /= n) $ error \"failed\"\n\n    test \"\" 0\n    test \"'unterminated\\\\'\" (-2)\n    test \"'qu\\0tes' 'are' 'fine: \\\\'' \" 3\n    test \"'unexpected' \\0 'null'\" (-1)\n",
      "extraCommandLineArguments": ""
    },
    "eof/01_sentinel.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\nimport Control.Monad (when)\nimport Data.ByteString (ByteString, index)\n\ndata State = State {\n    _yyinput :: ByteString,\n    _yycursor :: Int,\n    _count :: Int\n}\n\n-- expect a null-terminated string\n%{\n    re2c:YYFN = [\"lexer;Int\", \"State{..};State\"];\n    re2c:yyfill:enable = 0;\n\n    *      { (-1) }\n    [\\x00] { _count }\n    [a-z]+ { lexer State{_count = _count + 1, ..} }\n    [ ]+   { lexer State{..} }\n%}\n\nmain :: IO ()\nmain = do\n    let test s n = when (lexer st  /= n) $ error \"failed\"\n                   where st = State{_yyinput = s, _yycursor = 0, _count = 0}\n    test \"\\0\" 0\n    test \"one two three\\0\" 3\n    test \"f0ur\\0\" (-1)\n",
      "extraCommandLineArguments": ""
    },
    "includes/include.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT -i\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\nimport Control.Monad (when)\nimport Data.ByteString (ByteString, index)\n\n%{include \"definitions.hs\" %}\n\ndata State = State {\n    _yyinput :: ByteString,\n    _yycursor :: Int,\n    _yymarker :: Int,\n    _yyaccept :: Int\n}\n\n%{\n    re2c:YYFN = [\"lexer;Number\", \"State{..};State\"];\n    re2c:yyfill:enable = 0;\n\n    *      { NNaN }\n    number { INum }\n    !include \"extra_rules.re.inc\";\n%}\n\nmain :: IO ()\nmain = do\n    let test s n = do\n            let st = State {\n                    _yyinput = s,\n                    _yycursor = 0,\n                    _yymarker = 0,\n                    _yyaccept = 0}\n\n            when (lexer st /= n) $ error \"failed\"\n\n    test \"123\\0\" INum\n    test \"123.4567\\0\" FNum\n",
      "extraCommandLineArguments": "-i"
    },
    "encodings/unicode_identifier.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT --utf8 -i\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\nimport Control.Monad (when)\nimport Data.ByteString (ByteString, index)\n\n%{include \"unicode_categories.re\" %}\n\ndata State = State {\n    _yyinput :: ByteString,\n    _yycursor :: Int,\n    _yymarker :: Int,\n    _yyaccept :: Int\n}\n\n%{\n    re2c:YYFN = [\"lexer;Bool\", \"State{..};State\"];\n    re2c:yyfill:enable = 0;\n\n    // Simplified \"Unicode Identifier and Pattern Syntax\"\n    // (see https://unicode.org/reports/tr31)\n    id_start    = L | Nl | [$_];\n    id_continue = id_start | Mn | Mc | Nd | Pc | [\\u200D\\u05F3];\n    identifier  = id_start id_continue*;\n\n    identifier { True }\n    *          { False }\n%}\n\nmain :: IO ()\nmain = do\n    let st = State {\n            _yyinput = \"_\u042b\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\\x00\",\n            _yycursor = 0,\n            _yymarker = 0,\n            _yyaccept = 0}\n\n    when (not $ lexer st) $ error \"failed\"\n",
      "extraCommandLineArguments": "--utf8 -i"
    },
    "reuse/reuse.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT --input-encoding utf8\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\n-- This example supports multiple input encodings: UTF-8 and UTF-32.\n-- Both lexers are generated from the same rules block, and the use\n-- blocks add only encoding-specific configurations.\n\nimport Control.Monad (when)\nimport Data.Array\nimport Data.Word\n\ndata State a = State {\n    _yyinput :: a,\n    _yycursor :: Int,\n    _yymarker :: Int\n}\n\n%{rules\n    re2c:yyfill:enable = 0;\n    re2c:YYPEEK = \"(!)\";\n\n    \"\u2200x \u2203y\" { Just _yycursor }\n    *       { Nothing }\n%}\n\n%{use\n    re2c:YYFN = [\"lex8;Maybe Int\", \"State{..};State (Array Int Word8)\"];\n    re2c:encoding:utf8 = 1;\n    re2c:YYCTYPE = Word8;\n%}\n\n%{use\n    re2c:YYFN = [\"lex32;Maybe Int\", \"State{..};State (Array Int Int)\"];\n    re2c:encoding:utf32 = 1;\n    re2c:YYCTYPE = Int;\n%}\n\nmain :: IO ()\nmain = do\n    let make_st l = State {\n            _yyinput = listArray (0, length l - 1) l,\n            _yycursor = 0,\n            _yymarker = 0}\n\n    let s8 = [0xe2, 0x88, 0x80, 0x78, 0x20, 0xe2, 0x88, 0x83, 0x79]\n    when (lex8 (make_st s8) /= Just (length s8)) $ error \"lex8 failed\"\n\n    let s32 = [0x2200, 0x78, 0x20, 0x2203, 0x79]\n    when (lex32 (make_st s32) /= Just (length s32)) $ error \"lex32 failed\"\n",
      "extraCommandLineArguments": "--input-encoding utf8"
    },
    "reuse/usedir.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\n-- This example shows how to combine reusable re2c blocks: two blocks\n-- ('colors' and 'fish') are merged into one. The 'salmon' rule occurs\n-- in both blocks; the 'fish' block takes priority because it is used\n-- earlier. Default rule * occurs in all three blocks; the local (not\n-- inherited) definition takes priority.\n\nimport Control.Monad (when)\nimport Data.ByteString (ByteString, index)\n\ndata Answer = Color | Fish | Dunno deriving (Eq)\n\ndata State = State {\n    _yyinput :: ByteString,\n    _yycursor :: Int,\n    _yymarker :: Int\n}\n\n%{rules:colors\n    *                            { error \"ah\" }\n    \"red\" | \"salmon\" | \"magenta\" { Color }\n%}\n\n%{rules:fish\n    *                            { error \"oh\" }\n    \"haddock\" | \"salmon\" | \"eel\" { Fish }\n%}\n\n%{\n    re2c:YYFN = [\"lexer;Answer\", \"State{..};State\"];\n    re2c:yyfill:enable = 0;\n\n    !use:fish;\n    !use:colors;\n    * { Dunno } // overrides inherited '*' rules\n%}\n\nmain :: IO ()\nmain = do\n    let test str ans = do\n            let st = State {_yyinput = str, _yycursor = 0, _yymarker = 0}\n            when (lexer st /= ans) $ error \"failed\"\n\n    test \"salmon\" Fish\n    test \"what?\" Dunno\n",
      "extraCommandLineArguments": ""
    },
    "headers/header.re": {
      "content": "-- re2hs $INPUT -o $OUTPUT --header lexer/state.hs -i\n{-# OPTIONS_GHC -Wno-unused-record-wildcards #-}\n{-# LANGUAGE OverloadedStrings #-}\n\nimport Control.Monad (when)\nimport Data.ByteString (index)\nimport State\n\n%{header:on %}\nmodule State where\n\nimport Data.ByteString (ByteString)\n\ndata State = State {\n    _yyinput :: !ByteString,\n    _yycursor :: !Int,\n    %{stags format = \"\\n@@{tag} :: !Int,\"; %}\n    _tag :: !Int\n}\n%{header:off %}\n\n%{\n    re2c:YYFN = [\"lexer;Int\", \"State{..};State\"];\n    re2c:tags = 1;\n    re2c:yyfill:enable = 0;\n    re2c:header = \"lexer/state.hs\";\n\n    [a]* @_tag [b]* { _tag }\n%}\n\nmain :: IO ()\nmain = do\n    let s = State {\n        _yyinput = \"ab\\0\",\n        _yycursor = 0,\n        %{stags format = \"\\n@@{tag} = -1,\"; %}\n        _tag = 0}\n\n    when (lexer s /= 1) $ error \"failed!\"\n",
      "extraCommandLineArguments": "--header lexer/state.hs -i"
    }
  },
  "js": {
    "01_basic.re": {
      "content": "// re2js $INPUT -o $OUTPUT\n\nfunction lex(yyinput) {\n    let yycursor = 0;\n    /*!re2c\n        re2c:yyfill:enable = 0;\n\n        [1-9][0-9]* { return true; }\n        *           { return false; }\n    */\n}\n\nif (!lex(\"1234\\0\")) {\n    throw \"error!\"\n}\n",
      "extraCommandLineArguments": ""
    },
    "fill/01_fill.re": {
      "content": "// re2js $INPUT -o $OUTPUT\n\nconst fs = require('fs')\n\nconst BUFSIZE = 4096\nconst OK = 0\nconst EOF = 1\nconst LONG_LEXEME = 2\n\nfunction fill(st) {\n    if (st.eof) return EOF\n\n    // Error: lexeme too long. In real life could reallocate a larger buffer.\n    if (st.token < 1) return LONG_LEXEME\n\n    // Shift buffer contents (discard everything up to the current token).\n    st.yyinput.copy(st.yyinput, 0, st.token, st.yylimit)\n    st.yycursor -= st.token;\n    st.yymarker -= st.token;\n    st.yylimit -= st.token;\n    st.token = 0;\n\n    // Read a new chunk of data from file and append it to `yyinput`.\n    let want = BUFSIZE - st.yylimit - 1 // -1 for sentinel\n    let nread = fs.readSync(st.file, st.yyinput, st.yylimit, want)\n    st.eof = nread < want // end of file?\n    st.yylimit += nread\n    st.yyinput.writeUInt8(0, st.yylimit) // sentinel\n\n    return OK\n}\n\nfunction lex(yyrecord, count) {\n    loop: while (true) {\n        yyrecord.token = yyrecord.yycursor\n        /*!re2c\n            re2c:api = record;\n            re2c:YYPEEK = \"readUInt8\";\n            re2c:YYFILL = \"fill(yyrecord) == OK\";\n            re2c:eof = 0;\n\n            str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n            *    { return -1 }\n            $    { return count }\n            [ ]+ { continue loop }\n            str  { count += 1; continue loop }\n        */\n    }\n}\n\nfunction main() {\n    let fname = \"input\"\n\n    // Create input file.\n    let content = \"'qu\\0tes' 'are' 'fine: \\\\'' \".repeat(BUFSIZE)\n    fs.writeFileSync(fname, content, function(err) { if (err) throw err; })\n\n    // Init lexer state.\n    let limit = BUFSIZE - 1 // exclude terminating null\n    let st = {\n        file: fs.openSync(fname, 'r'),\n        yyinput: Buffer.alloc(BUFSIZE),\n        yylimit: limit,\n        yycursor: limit,\n        yymarker: limit,\n        token: limit,\n        eof: false\n    }\n\n    // Run lexer on the prepared file.\n    if (lex(st, 0) != 3 * BUFSIZE) { throw \"error :[\" }\n\n    // Cleanup.\n    fs.unlink(fname, function(err){ if (err) throw err; })\n}\n\nmain()\n",
      "extraCommandLineArguments": ""
    },
    "fill/02_fill.re": {
      "content": "// re2js $INPUT -o $OUTPUT\n\nconst fs = require('fs')\n\nconst BUFSIZE = 4096\nconst OK = 0\nconst EOF = 1\nconst LONG_LEXEME = 2\n/*!max:re2c*/\n\nfunction fill(st, need) {\n    if (st.eof) return EOF\n\n    // Error: lexeme too long. In real life could reallocate a larger buffer.\n    if (st.token < need) return LONG_LEXEME\n\n    // Shift buffer contents (discard everything up to the current token).\n    st.yyinput.copy(st.yyinput, 0, st.token, st.yylimit)\n    st.yycursor -= st.token;\n    st.yylimit -= st.token;\n    st.token = 0;\n\n    // Read a new chunk of data from file and append it to `yyinput`.\n    let want = BUFSIZE - st.yylimit - 1 // -1 for sentinel\n    let nread = fs.readSync(st.file, st.yyinput, st.yylimit, want)\n    st.yylimit += nread\n    if (nread < want) {\n        st.eof = true // end of file\n        st.yyinput.write(\"\\0\".repeat(YYMAXFILL), st.yylimit)\n        st.yylimit += YYMAXFILL\n    }\n\n    return OK\n}\n\nfunction lex(yyrecord, count) {\n    loop: while (true) {\n        yyrecord.token = yyrecord.yycursor\n        /*!re2c\n            re2c:api = record;\n            re2c:YYPEEK = \"readUInt8\";\n            re2c:YYFILL = \"if (fill(yyrecord, @@) != OK) return -1;\";\n\n            str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n            [\\x00] {\n                // Check that it is the sentinel, not some unexpected null.\n                return yyrecord.token == yyrecord.yylimit - YYMAXFILL ? count : -1\n            }\n            str  { count += 1; continue loop }\n            [ ]+ { continue loop }\n            *    { return -1 }\n        */\n    }\n}\n\nfunction main() {\n    let fname = \"input\"\n\n    // Create input file.\n    let content = \"'qu\\0tes' 'are' 'fine: \\\\'' \".repeat(BUFSIZE)\n    fs.writeFileSync(fname, content, function(err) { if (err) throw err; })\n\n    // Init lexer state.\n    let limit = BUFSIZE - 1 // exclude terminating null\n    let st = {\n        file: fs.openSync(fname, 'r'),\n        yyinput: Buffer.alloc(BUFSIZE),\n        yylimit: limit,\n        yycursor: limit,\n        token: limit,\n        eof: false\n    }\n\n    // Run lexer on the prepared file.\n    if (lex(st, 0) != 3 * BUFSIZE) { throw \"error :[\" }\n\n    // Cleanup.\n    fs.unlink(fname, function(err){ if (err) throw err; })\n}\n\nmain()\n",
      "extraCommandLineArguments": ""
    },
    "conditions/parse_u32_conditions.re": {
      "content": "// re2js $INPUT -o $OUTPUT -c\n\n/*!conditions:re2c*/\n\nfunction parse_u32(yyinput) {\n    let yycursor = 0\n    let yycond = YYC_INIT\n    let n = 0\n\n    loop: while (true) {\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:indent:top = 2;\n\n        <INIT> '0b' / [01]        :=> BIN\n        <INIT> \"0\"                :=> OCT\n        <INIT> \"\" / [1-9]         :=> DEC\n        <INIT> '0x' / [0-9a-fA-F] :=> HEX\n        <INIT> * { return null }\n\n        <BIN> [01]  { n = n * 2 + (yyinput.charCodeAt(yycursor - 1) - 48); continue loop }\n        <OCT> [0-7] { n = n * 8 + (yyinput.charCodeAt(yycursor - 1) - 48); continue loop }\n        <DEC> [0-9] { n = n * 10 + (yyinput.charCodeAt(yycursor - 1) - 48); continue loop }\n        <HEX> [0-9] { n = n * 16 + (yyinput.charCodeAt(yycursor - 1) - 48); continue loop }\n        <HEX> [a-f] { n = n * 16 + (yyinput.charCodeAt(yycursor - 1) - 87); continue loop }\n        <HEX> [A-F] { n = n * 16 + (yyinput.charCodeAt(yycursor - 1) - 55); continue loop }\n\n        <BIN, OCT, DEC, HEX> * { return n }\n    */\n    }\n}\n\nfunction test(s, n) {\n    if (parse_u32(s) != n) throw \"error!\"\n}\n\ntest(\"\\0\", null)\ntest(\"1234567890\\0\", 1234567890)\ntest(\"0b1101\\0\", 13)\ntest(\"0x7Fe\\0\", 2046)\ntest(\"0644\\0\", 420)\ntest(\"9999999999\\0\", 9999999999)\n",
      "extraCommandLineArguments": "-c"
    },
    "conditions/parse_u32_blocks.re": {
      "content": "// re2js $INPUT -o $OUTPUT\n\n/*!re2c // Common re2c definitions shared between all functions.\n    re2c:api = record;\n    re2c:yyrecord = st;\n    re2c:yyfill:enable = 0;\n*/\n\nfunction parse_u32(str) {\n    let st = {\n        yyinput: str,\n        yycursor: 0,\n        yymarker: 0\n    }\n    /*!re2c\n        '0b' / [01]        { return parse_bin(st) }\n        \"0\"                { return parse_oct(st) }\n        \"\" / [1-9]         { return parse_dec(st) }\n        '0x' / [0-9a-fA-F] { return parse_hex(st) }\n        *                  { return null }\n    */\n}\n\nfunction parse_bin(st) {\n    n = 0\n    loop: while (true) {\n    /*!re2c\n        [01] { n = n * 2 + (st.yyinput.charCodeAt(st.yycursor - 1) - 48); continue loop }\n        *    { return n }\n    */\n    }\n}\n\nfunction parse_oct(st) {\n    n = 0\n    loop: while (true) {\n    /*!re2c\n        [0-7] { n = n * 8 + (st.yyinput.charCodeAt(st.yycursor - 1) - 48); continue loop }\n        *     { return n }\n    */\n    }\n}\n\nfunction parse_dec(st) {\n    n = 0\n    loop: while (true) {\n    /*!re2c\n        [0-9] { n = n * 10 + (st.yyinput.charCodeAt(st.yycursor - 1) - 48); continue loop }\n        *     { return n }\n    */\n    }\n}\n\nfunction parse_hex(st) {\n    n = 0\n    loop: while (true) {\n    /*!re2c\n        [0-9] { n = n * 16 + (st.yyinput.charCodeAt(st.yycursor - 1) - 48); continue loop }\n        [a-f] { n = n * 16 + (st.yyinput.charCodeAt(st.yycursor - 1) - 87); continue loop }\n        [A-F] { n = n * 16 + (st.yyinput.charCodeAt(st.yycursor - 1) - 55); continue loop }\n        *     { return n }\n    */\n    }\n}\n\nfunction test(s, n) {\n    if (parse_u32(s) != n) throw \"error!\"\n}\n\ntest(\"\\0\", null)\ntest(\"1234567890\\0\", 1234567890)\ntest(\"0b1101\\0\", 13)\ntest(\"0x7Fe\\0\", 2046)\ntest(\"0644\\0\", 420)\ntest(\"9999999999\\0\", 9999999999)\n",
      "extraCommandLineArguments": ""
    },
    "state/push.re": {
      "content": "// re2js $INPUT -o $OUTPUT -f\n\nconst fs = require('fs')\n\n// Use a small buffer to cover the case when a lexeme doesn't fit.\n// In real world use a larger buffer.\nconst BUFSIZE = 10\nconst DEBUG = false\nconst END = 0\nconst READY = 1\nconst WAITING = 2\nconst BIG_PACKET = 3\nconst BAD_PACKET = 4\n\nfunction log() {\n    if (DEBUG) console.log.apply(console, arguments)\n}\n\nfunction fill(st) {\n    // Error: lexeme too long. In real life could reallocate a larger buffer.\n    if (st.token < 1) return BIG_PACKET\n\n    // Shift buffer contents (discard everything up to the current token).\n    st.yyinput.copy(st.yyinput, 0, st.token, st.yylimit)\n    st.yycursor -= st.token;\n    st.yymarker -= st.token;\n    st.yylimit -= st.token;\n    st.token = 0;\n\n    // Read a new chunk of data from file and append it to `yyinput`.\n    let want = BUFSIZE - st.yylimit - 1 // -1 for sentinel\n    let nread = fs.readSync(st.file, st.yyinput, st.yylimit, want)\n    st.yylimit += nread\n    st.yyinput.writeUInt8(0, st.yylimit) // sentinel\n\n    return READY\n}\n\nfunction lex(yyrecord) {\n    loop: while (true) {\n        yyrecord.token = yyrecord.yycursor\n        /*!re2c\n            re2c:api = record;\n            re2c:YYPEEK = \"readUInt8\";\n            re2c:YYFILL = \"return WAITING\";\n            re2c:eof = 0;\n\n            packet = [a-z]+[;];\n\n            *      { return BAD_PACKET }\n            $      { return END }\n            packet { yyrecord.received += 1; continue loop }\n        */\n    }\n}\n\nfunction test(packets, expect) {\n    // Emulate a \"pipe\" by opening the same file for reading and writing.\n    let fname = \"input\"\n    let fw = fs.openSync(fname, 'w');\n    let fr = fs.openSync(fname, 'r');\n\n    // Init lexer state.\n    let limit = BUFSIZE - 1 // exclude terminating null\n    let st = {\n        file: fr,\n        yyinput: Buffer.alloc(BUFSIZE),\n        yylimit: limit,\n        yycursor: limit,\n        yymarker: limit,\n        token: limit,\n        yystate: -1,\n        received: 0\n    }\n\n    // Main loop. The buffer contains incomplete data which appears packet by\n    // packet. When the lexer needs more input it saves its internal state and\n    // returns to the caller which should provide more input and resume lexing.\n    let send = 0\n    let status\n    loop: while (true) {\n        status = lex(st)\n\n        if (status == END) {\n            log(\"done: got\", st.received, \"packets\")\n            break loop\n        } else if (status == WAITING) {\n            log(\"waiting...\");\n\n            if (send < packets.length) {\n                log(\"sent packet\", send, packets[send])\n                fs.writeFileSync(fw, packets[send])\n                send += 1\n            }\n\n            status = fill(st)\n            log(\"queue:\", st.yyinput.toString())\n            if (status == BIG_PACKET) {\n                log(\"error: packet too big\")\n                break loop\n            }\n\n            if (status != READY) throw \"expected READY\"\n        } else {\n            if (status != BAD_PACKET) throw \"expected BAD_PACKET\"\n            log(\"error: ill-formed packet\")\n            break loop\n        }\n    }\n\n    // Check results.\n    if (status != expect) throw \"unexpected status\"\n    if (status == END && st.received != send) \"unexpected packet count\"\n\n    // Cleanup.\n    fs.unlinkSync(fname, function(err){ if (err) throw err; })\n}\n\nfunction main() {\n    test([], END)\n    test([\"zero;\", \"one;\", \"two;\", \"three;\", \"four;\"], END)\n    test([\"zer0;\"], BAD_PACKET)\n    test([\"goooooooooogle;\"], BIG_PACKET)\n}\n\nmain()\n",
      "extraCommandLineArguments": "-f"
    },
    "submatch/02_mtags.re": {
      "content": "// re2js $INPUT -o $OUTPUT\n\nconst assert = require('assert')\n\nfunction parse(yyinput) {\n    let yycursor = 0\n\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = \"let @@\\n\"; */\n    /*!mvars:re2c format = \"let @@\\n\"; */\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = \"let @@\\n\"; */\n    /*!mtags:re2c format = \"let @@ = []\\n\"; */\n\n    /*!re2c\n        re2c:YYMTAGP = \"@@.push(yycursor)\";\n        re2c:YYMTAGN = \"\"; // do nothing\n        re2c:yyfill:enable = 0;\n        re2c:tags = 1;\n\n        num = [0-9]+;\n\n        @t1 num @t2 (\".\" #t3 num #t4)* [\\x00] {\n            let vers = [Number(yyinput.substring(t1, t2))]\n            for (let i = 0; i < t3.length; ++i) {\n                vers.push(Number(yyinput.substring(t3[i], t4[i])))\n            }\n            return vers\n        }\n        * { return null }\n    */\n}\n\nassert.deepEqual(parse(\"1\\0\"), [1])\nassert.deepEqual(parse(\"1.2.3.4.5.6.7\\0\"), [1, 2, 3, 4, 5, 6, 7])\nassert.deepEqual(parse(\"1.2.\\0\"), null)\n",
      "extraCommandLineArguments": ""
    },
    "submatch/04_posix_captures.re": {
      "content": "// re2js $INPUT -o $OUTPUT\n\nconst assert = require('assert');\n\n// Maximum number of capturing groups among all rules.\n/*!maxnmatch:re2c*/\n\nfunction parse(yyinput) {\n    let yycursor = 0\n\n    // A list for capturing parentheses (twice the number of groups).\n    let yynmatch\n    let yypmatch = Array(YYMAXNMATCH * 2).fill(null)\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = \"let @@\\n\"; */\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:posix-captures = 1;\n\n        num = [0-9]+;\n\n        (num) \".\" (num) (\".\" num)? [\\x00] {\n            // `yynmatch` is the number of capturing groups\n            assert.equal(yynmatch, 4)\n\n            // Even `yypmatch` values are for opening parentheses, odd values\n            // are for closing parentheses, the first group is the whole match.\n            return {\n                major: Number(yyinput.substring(yypmatch[2], yypmatch[3])),\n                minor: Number(yyinput.substring(yypmatch[4], yypmatch[5])),\n                patch: yypmatch[6] == -1 ? 0\n                    : Number(yyinput.substring(yypmatch[6] + 1, yypmatch[7]))\n            }\n        }\n        * { return null }\n    */\n}\n\nassert.deepEqual(parse(\"23.34\\0\"), {major: 23, minor: 34, patch: 0})\nassert.deepEqual(parse(\"1.2.99999\\0\"), {major: 1, minor: 2, patch: 99999})\nassert.deepEqual(parse(\"1.a\\0\"), null)\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags.re": {
      "content": "// re2js $INPUT -o $OUTPUT\n\nconst assert = require('assert');\n\nfunction parse(yyinput) {\n    let yycursor = 0\n\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = \"let @@\\n\"; */\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = \"let @@\\n\"; */\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:tags = 1;\n\n        num = [0-9]+;\n\n        @t1 num @t2 \".\" @t3 num @t4 (\".\" @t5 num)? [\\x00] {\n            return {\n                major: Number(yyinput.substring(t1, t2)),\n                minor: Number(yyinput.substring(t3, t4)),\n                patch: t5 == -1 ? 0 : Number(yyinput.substring(t5, yycursor - 1))\n            }\n        }\n        * { return null }\n    */\n}\n\nassert.deepEqual(parse(\"23.34\\0\"), {major: 23, minor: 34, patch: 0})\nassert.deepEqual(parse(\"1.2.99999\\0\"), {major: 1, minor: 2, patch: 99999})\nassert.deepEqual(parse(\"1.a\\0\"), null)\n",
      "extraCommandLineArguments": ""
    },
    "submatch/03_captures.re": {
      "content": "// re2js $INPUT -o $OUTPUT\n\nconst assert = require('assert');\n\nfunction parse(yyinput) {\n    let yycursor = 0\n\n    // Final tag variables available in semantic action.\n    /*!svars:re2c format = \"let @@\\n\"; */\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = \"let @@\\n\"; */\n\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:captvars = 1;\n\n        num = [0-9]+;\n\n        (num) \".\" (num) (\".\" num)? [\\x00] {\n            return {\n                major: Number(yyinput.substring(yytl1, yytr1)),\n                minor: Number(yyinput.substring(yytl2, yytr2)),\n                patch: yytl3 == -1 ? 0 : Number(yyinput.substring(yytl3 + 1, yytr3))\n            }\n        }\n        * { return null }\n    */\n}\n\nassert.deepEqual(parse(\"23.34\\0\"), {major: 23, minor: 34, patch: 0})\nassert.deepEqual(parse(\"1.2.99999\\0\"), {major: 1, minor: 2, patch: 99999})\nassert.deepEqual(parse(\"1.a\\0\"), null)\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags_fill.re": {
      "content": "// re2js $INPUT -o $OUTPUT\n\nconst assert = require('assert');\nconst fs = require('fs')\n\nconst BUFSIZE = 4096\nconst OK = 0\nconst EOF = 1\nconst LONG_LEXEME = 2\n\nfunction fill(st) {\n    if (st.eof) return EOF\n\n    // Error: lexeme too long. In real life could reallocate a larger buffer.\n    if (st.token < 1) return LONG_LEXEME\n\n    // Shift buffer contents (discard everything up to the current token).\n    st.yyinput.copy(st.yyinput, 0, st.token, st.yylimit)\n    st.yycursor -= st.token;\n    st.yymarker -= st.token;\n    st.yylimit -= st.token;\n    /*!stags:re2c format = \"if (st.@@ != -1) st.@@ -= st.token\\n\"; */\n    st.token = 0;\n\n    // Read a new chunk of data from file and append it to `yyinput`.\n    let want = BUFSIZE - st.yylimit - 1 // -1 for sentinel\n    let nread = fs.readSync(st.file, st.yyinput, st.yylimit, want)\n    st.eof = nread < want // end of file?\n    st.yylimit += nread\n    st.yyinput.writeUInt8(0, st.yylimit) // sentinel\n\n    return OK\n}\n\nfunction lex(st) {\n    let vers = []\n    loop: while (true) {\n        st.token = st.yycursor\n\n        // Final tag variables available in semantic action.\n        /*!svars:re2c format = \"let @@\\n\"; */\n\n        /*!re2c\n            re2c:api = record;\n            re2c:yyrecord = st;\n            re2c:YYPEEK = \"readUInt8\";\n            re2c:YYFILL = \"fill(st) == OK\";\n            re2c:eof = 0;\n            re2c:tags = 1;\n\n            num = [0-9]+;\n\n            num @t1 \".\" @t2 num @t3 (\".\" @t4 num)? [\\n] {\n                vers.push({\n                    major: Number(st.yyinput.subarray(st.token, t1)),\n                    minor: Number(st.yyinput.subarray(t2, t3)),\n                    patch: t4 == -1 ? 0 : Number(st.yyinput.subarray(t4, st.yycursor - 1))\n                })\n                continue loop\n            }\n            $ { return vers }\n            * { return null }\n        */\n    }\n}\n\nfunction main() {\n    let fname = \"input\"\n\n    // Create input file.\n    let content = \"1.22.333\\n\".repeat(BUFSIZE)\n    fs.writeFileSync(fname, content, function(err) { if (err) throw err; })\n\n    // Init lexer state.\n    let limit = BUFSIZE - 1 // exclude terminating null\n    let st = {\n        file: fs.openSync(fname, 'r'),\n        yyinput: Buffer.alloc(BUFSIZE),\n        yylimit: limit,\n        yycursor: limit,\n        yymarker: limit,\n        token: limit,\n        // Intermediate tag variables used by the lexer (must be autogenerated).\n        /*!stags:re2c format = \"@@: -1,\\n\"; */\n        eof: false\n    }\n\n    // Run lexer on the prepared file.\n    assert.deepEqual(lex(st), Array(BUFSIZE).fill({major: 1, minor: 22, patch: 333}))\n\n    // Cleanup.\n    fs.unlink(fname, function(err){ if (err) throw err; })\n}\n\nmain()\n",
      "extraCommandLineArguments": ""
    },
    "eof/03_eof_rule.re": {
      "content": "// re2js $INPUT -o $OUTPUT\n\n// expects a null-terminated string\nfunction lex(yyinput) {\n    let yycursor = 0;\n    let yylimit = yyinput.length - 1 // terminating null not included\n    let count = 0\n\n    loop: while (true) {\n    /*!re2c\n        re2c:yyfill:enable = 0;\n        re2c:eof = 0;\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        *    { return -1 }\n        $    { return count }\n        [ ]+ { continue loop }\n        str  { count += 1; continue loop }\n    */\n    }\n}\n\nfunction test(s, n) { if (lex(s) != n) throw \"error!\"; }\ntest(\"\\0\", 0)\ntest(\"'qu\\0tes' 'are' 'fine: \\\\'' \\0\", 3)\ntest(\"'unterminated\\\\'\\0\", -1)\n",
      "extraCommandLineArguments": ""
    },
    "eof/04_fake_sentinel.re": {
      "content": "// re2js $INPUT -o $OUTPUT\n\n// expects a string without terminating null\nfunction lex(str) {\n    let cur = 0;\n    let lim = str.length\n    let count = 0\n\n    loop: while (true) {\n    /*!re2c\n        re2c:api = generic;\n        re2c:YYPEEK = \"cur < lim ? str.charCodeAt(cur) : 0\";\n        re2c:YYSKIP = \"cur += 1\";\n        re2c:yyfill:enable = 0;\n\n        *      { return -1 }\n        [\\x00] { return count }\n        [ ]+   { continue loop }\n        [a-z]+ { count += 1; continue loop }\n    */\n    }\n}\n\nfunction test(s, n) { if (lex(s) != n) throw \"error!\"; }\ntest(\"\", 0)\ntest(\"one two three\", 3)\ntest(\"f0ur\", -1)\n",
      "extraCommandLineArguments": ""
    },
    "eof/02_bounds_checking.re": {
      "content": "// re2js $INPUT -o $OUTPUT\n\n/*!max:re2c*/\n\nfunction lex(yyinput) {\n    let yycursor = 0;\n    let yylimit = yyinput.length\n    let count = 0\n\n    loop: while (true) {\n    /*!re2c\n        re2c:YYFILL = \"return -1\";\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        [\\x00] {\n            // check that it is the sentinel, not some unexpected null\n            return (yycursor == yylimit - YYMAXFILL + 1) ? count : -1\n        }\n        str  { count += 1; continue loop }\n        [ ]+ { continue loop }\n        *    { return -1 }\n    */\n    }\n}\n\nfunction test(s, n) {\n    let padded_s = s + \"\\0\".repeat(YYMAXFILL)\n    if (lex(padded_s) != n) throw \"error!\"\n}\n\ntest(\"\", 0)\ntest(\"'unterminated\\\\'\", -1)\ntest(\"'qu\\0tes' 'are' 'fine: \\\\'' \", 3)\ntest(\"'unexpected \\0 null\", -1)\n",
      "extraCommandLineArguments": ""
    },
    "eof/01_sentinel.re": {
      "content": "// re2js $INPUT -o $OUTPUT\n\n// expects a null-terminated string\nfunction lex(yyinput) {\n    let yycursor = 0;\n    let count = 0\n\n    loop: while (true) {\n    /*!re2c\n        re2c:yyfill:enable = 0;\n\n        *      { return -1 }\n        [\\x00] { return count }\n        [ ]+   { continue loop }\n        [a-z]+ { count += 1; continue loop }\n    */\n    }\n}\n\nfunction test(s, n) { if (lex(s) != n) throw \"error!\"; }\ntest(\"\\0\", 0)\ntest(\"one two three\\0\", 3)\ntest(\"f0ur\\0\", -1)\n",
      "extraCommandLineArguments": ""
    },
    "includes/include.re": {
      "content": "// re2js $INPUT -o $OUTPUT\n\n/*!include:re2c \"definitions.js\" */\n\nfunction lex(yyinput) {\n    let yycursor = 0\n    /*!re2c\n        re2c:yyfill:enable = 0;\n\n        *      { return NAN }\n        number { return INT }\n        !include \"extra_rules.re.inc\";\n    */\n}\n\nfunction test(s, n) {\n    if (lex(s) != n) throw \"error!\"\n}\n\ntest(\"123\\0\", INT)\ntest(\"123.4567\\0\", FLOAT)\n",
      "extraCommandLineArguments": ""
    },
    "encodings/unicode_identifier.re": {
      "content": "// re2js $INPUT -o $OUTPUT --utf8 -s\n\n/*!include:re2c \"unicode_categories.re\" */\n\nfunction lex(yyinput) {\n    let yycursor = 0\n    /*!re2c\n        re2c:yyfill:enable = 0;\n\n        // Simplified \"Unicode Identifier and Pattern Syntax\"\n        // (see https://unicode.org/reports/tr31)\n        id_start    = L | Nl | [$_];\n        id_continue = id_start | Mn | Mc | Nd | Pc | [\\u200D\\u05F3];\n        identifier  = id_start id_continue*;\n\n        identifier { return true }\n        *          { return false }\n    */\n}\n\nif (!lex(\"_\u042b\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\\0\")) throw \"error!\"\n",
      "extraCommandLineArguments": "--utf8 -s"
    },
    "reuse/reuse.re": {
      "content": "// re2js $INPUT -o $OUTPUT --input-encoding utf8\n\n// This example supports multiple input encodings: UTF-8 and UTF-32.\n// Both lexers are generated from the same rules block, and the use\n// blocks add only encoding-specific configurations.\n/*!rules:re2c\n    re2c:yyfill:enable = 0;\n    re2c:YYPEEK = \"at\";\n\n    \"\u2200x \u2203y\" { return yycursor }\n    *       { return null }\n*/\n\nfunction lex_utf8(yyinput) {\n    let yycursor = 0\n    /*!use:re2c\n        re2c:encoding:utf8 = 1;\n    */\n}\n\nfunction lex_utf32(yyinput) {\n    let yycursor = 0\n    /*!use:re2c\n        re2c:encoding:utf32 = 1;\n    */\n}\n\nfunction test(f, s) {\n    if (f(s) != s.length) throw \"error!\"\n}\n\ntest(lex_utf8, [0xe2, 0x88, 0x80, 0x78, 0x20, 0xe2, 0x88, 0x83, 0x79])\ntest(lex_utf32, [0x2200, 0x78, 0x20, 0x2203, 0x79])\n",
      "extraCommandLineArguments": "--input-encoding utf8"
    },
    "reuse/usedir.re": {
      "content": "// re2js $INPUT -o $OUTPUT\n\n// This example shows how to combine reusable re2c blocks: two blocks\n// ('colors' and 'fish') are merged into one. The 'salmon' rule occurs\n// in both blocks; the 'fish' block takes priority because it is used\n// earlier. Default rule * occurs in all three blocks; the local (not\n// inherited) definition takes priority.\n\nconst COLOR = 1\nconst FISH = 2\nconst DUNNO = 3\n\n/*!rules:re2c:colors\n    *                            { throw \"ah\" }\n    \"red\" | \"salmon\" | \"magenta\" { return COLOR }\n*/\n\n/*!rules:re2c:fish\n    *                            { throw \"oh\" }\n    \"haddock\" | \"salmon\" | \"eel\" { return FISH }\n*/\n\nfunction lex(yyinput) {\n    let yycursor = 0\n    /*!re2c\n        re2c:yyfill:enable = 0;\n\n        !use:fish;\n        !use:colors;\n        * { return DUNNO } // overrides inherited '*' rules\n    */\n}\n\nfunction test(s, n) { if (lex(s) != n) throw \"error!\"; }\n\ntest(\"salmon\", FISH)\ntest(\"what?\", DUNNO)\n",
      "extraCommandLineArguments": ""
    },
    "headers/header.re": {
      "content": "// re2js $INPUT -o $OUTPUT --header lexer/state.js\n\nlet state = require('./lexer/state.js');\n\n/*!header:re2c:on*/\nexports.mk_state = function(str) {\n    return {\n        yyinput: str,\n        /*!stags:re2c format = \"@@: 0,\\n\"; */\n        yycursor: 0\n    }\n}\n/*!header:re2c:off*/\n\nfunction lex(yyrecord) {\n    let t\n    /*!re2c\n        re2c:api = record;\n        re2c:tags = 1;\n        re2c:yyfill:enable = 0;\n        re2c:header = \"lexer/state.js\";\n\n        [a]* @t [b]* { return t }\n    */\n}\n\nif (lex(state.mk_state(\"ab\\0\")) != 1) {\n    throw \"error!\"\n}\n",
      "extraCommandLineArguments": "--header lexer/state.js"
    }
  },
  "go": {
    "01_basic.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT -i --api simple\npackage main\n\nfunc lex(yyinput string) {\n\tvar yycursor int\n\t/*!re2c\n\t\tre2c:YYCTYPE = byte;\n\t\tre2c:yyfill:enable = 0;\n\n\t\t[1-9][0-9]* { return }\n\t\t*           { panic(\"error!\") }\n\t*/\n}\n\nfunc main() {\n\tlex(\"1234\\x00\")\n}\n",
      "extraCommandLineArguments": "-i --api simple"
    },
    "fill/01_fill.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT\npackage main\n\nimport (\n\t\"os\"\n\t\"strings\"\n)\n\nconst BUFSIZE uint = 4096\n\ntype Input struct {\n\tfile     *os.File\n\tyyinput  []byte\n\tyycursor uint\n\tyymarker uint\n\tyylimit  uint\n\ttoken    uint\n\teof      bool\n}\n\nfunc fill(in *Input) int {\n\tif in.eof { return -1 } // unexpected EOF\n\n\t// Error: lexeme too long. In real life can reallocate a larger buffer.\n\tif in.token < 1 { return -2 }\n\n\t// Shift buffer contents (discard everything up to the current token).\n\tcopy(in.yyinput[0:], in.yyinput[in.token:in.yylimit])\n\tin.yycursor -= in.token\n\tin.yymarker -= in.token\n\tin.yylimit -= in.token\n\tin.token = 0\n\n\t// Fill free space at the end of buffer with new data from file.\n\tn, _ := in.file.Read(in.yyinput[in.yylimit:BUFSIZE])\n\tin.yylimit += uint(n)\n\tin.yyinput[in.yylimit] = 0\n\n\t// If read less than expected, this is the end of input.\n\tin.eof = in.yylimit < BUFSIZE\n\n\treturn 0\n}\n\nfunc lex(yyrecord *Input) int {\n\tcount := 0\n\tfor {\n\t\tyyrecord.token = yyrecord.yycursor\n\t/*!re2c\n\t\tre2c:api = record;\n\t\tre2c:eof = 0;\n\t\tre2c:YYCTYPE = byte;\n\t\tre2c:YYFILL = \"fill(yyrecord) == 0\";\n\n\t\tstr = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n\t\t*    { return -1 }\n\t\t$    { return count }\n\t\tstr  { count += 1; continue }\n\t\t[ ]+ { continue }\n\t*/\n\t}\n}\n\nfunc main() () {\n\tfname := \"input\"\n\tcontent := \"'qu\\000tes' 'are' 'fine: \\\\'' \";\n\n\t// Prepare input file: a few times the size of the buffer, containing\n\t// strings with zeroes and escaped quotes.\n\tf, _ := os.Create(fname)\n\tf.WriteString(strings.Repeat(content, int(BUFSIZE)))\n\tf.Seek(0, 0)\n\tcount := 3 * int(BUFSIZE) // number of quoted strings written to file\n\n\t// Prepare lexer state: all offsets are at the end of buffer.\n\tin := &Input{\n\t\tfile:     f,\n\t\t// Sentinel at `yylimit` offset is set to zero, which triggers YYFILL.\n\t\tyyinput:  make([]byte, BUFSIZE+1),\n\t\tyycursor: BUFSIZE,\n\t\tyymarker: BUFSIZE,\n\t\tyylimit:  BUFSIZE,\n\t\ttoken:    BUFSIZE,\n\t\teof:      false,\n\t}\n\n\t// Run the lexer.\n\tif lex(in) != count { panic(\"error\"); }\n\n\t// Cleanup: remove input file.\n\tf.Close();\n\tos.Remove(fname);\n}\n",
      "extraCommandLineArguments": ""
    },
    "fill/02_fill.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT\npackage main\n\nimport (\n\t\"os\"\n\t\"strings\"\n)\n\n/*!max:re2c*/\nconst BUFSIZE uint = 4096\n\ntype Input struct {\n\tfile     *os.File\n\tyyinput  []byte\n\tyycursor uint\n\tyylimit  uint\n\ttoken    uint\n\teof      bool\n}\n\nfunc fill(in *Input, need uint) int {\n\tif in.eof { return -1 } // unexpected EOF\n\n\t// Error: lexeme too long. In real life can reallocate a larger buffer.\n\tif in.token < need { return -2 }\n\n\t// Shift buffer contents (discard everything up to the current token).\n\tcopy(in.yyinput[0:], in.yyinput[in.token:in.yylimit])\n\tin.yycursor -= in.token\n\tin.yylimit -= in.token\n\tin.token = 0\n\n\t// Fill free space at the end of buffer with new data from file.\n\tn, _ := in.file.Read(in.yyinput[in.yylimit:BUFSIZE])\n\tin.yylimit += uint(n)\n\n\t// If read less than expected, this is end of input => add zero padding\n\t// so that the lexer can access characters at the end of buffer.\n\tif in.yylimit < BUFSIZE {\n\t\tin.eof = true\n\t\tfor i := uint(0); i < YYMAXFILL; i += 1 { in.yyinput[in.yylimit+i] = 0 }\n\t\tin.yylimit += YYMAXFILL\n\t}\n\n\treturn 0\n}\n\nfunc lex(yyrecord *Input) int {\n\tcount := 0\n\tfor {\n\t\tyyrecord.token = yyrecord.yycursor\n\t/*!re2c\n\t\tre2c:api = record;\n\t\tre2c:YYCTYPE = byte;\n\t\tre2c:YYFILL = \"if r := fill(yyrecord, @@); r != 0 { return r }\";\n\n\t\tstr = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n\t\t[\\x00] {\n\t\t\t// Check that it is the sentinel, not some unexpected null.\n\t\t\tif yyrecord.token == yyrecord.yylimit - YYMAXFILL { return count } else { return -1 }\n\t\t}\n\t\tstr  { count += 1; continue }\n\t\t[ ]+ { continue }\n\t\t*    { return -1 }\n\t*/\n\t}\n}\n\nfunc main() () {\n\tfname := \"input\"\n\tcontent := \"'qu\\000tes' 'are' 'fine: \\\\'' \";\n\n\t// Prepare input file: a few times the size of the buffer, containing\n\t// strings with zeroes and escaped quotes.\n\tf, _ := os.Create(fname)\n\tf.WriteString(strings.Repeat(content, int(BUFSIZE)))\n\tf.Seek(0, 0)\n\tcount := 3 * int(BUFSIZE) // number of quoted strings written to file\n\n\t// Prepare lexer state: all offsets are at the end of buffer.\n\t// This immediately triggers YYFILL, as the YYLESSTHAN condition is true.\n\tin := &Input{\n\t\tfile:     f,\n\t\tyyinput:  make([]byte, BUFSIZE+YYMAXFILL),\n\t\tyycursor: BUFSIZE,\n\t\tyylimit:  BUFSIZE,\n\t\ttoken:    BUFSIZE,\n\t\teof:      false,\n\t}\n\n\t// Run the lexer.\n\tif lex(in) != count { panic(\"error\"); }\n\n\t// Cleanup: remove input file.\n\tf.Close();\n\tos.Remove(fname);\n}\n",
      "extraCommandLineArguments": ""
    },
    "conditions/parse_u32_conditions.re": {
      "content": "//go:generate re2go -c $INPUT -o $OUTPUT -i --api simple\npackage main\n\nimport \"errors\"\n\nvar (\n\teSyntax   = errors.New(\"syntax error\")\n\teOverflow = errors.New(\"overflow error\")\n)\n\n/*!conditions:re2c*/\n\nconst u32Limit uint64 = 1<<32\n\nfunc parse_u32(yyinput string) (uint32, error) {\n\tvar yycursor, yymarker int\n\tresult := uint64(0)\n\tyycond := yycinit\n\n\tadd := func(base uint64, offset byte) {\n\t\tresult = result * base + uint64(yyinput[yycursor-1] - offset)\n\t\tif result >= u32Limit {\n\t\t\tresult = u32Limit\n\t\t}\n\t}\n\n\t/*!re2c\n\t\tre2c:yyfill:enable = 0;\n\t\tre2c:YYCTYPE = byte;\n\t\tre2c:YYGETCOND = \"cond\";\n\t\tre2c:YYSETCOND = \"cond = @@\";\n\n\t\t<*> * { return 0, eSyntax }\n\n\t\t<init> '0b' / [01]        :=> bin\n\t\t<init> \"0\"                :=> oct\n\t\t<init> \"\"   / [1-9]       :=> dec\n\t\t<init> '0x' / [0-9a-fA-F] :=> hex\n\n\t\t<bin, oct, dec, hex> \"\\x00\" {\n\t\t\tif result < u32Limit {\n\t\t\t\treturn uint32(result), nil\n\t\t\t} else {\n\t\t\t\treturn 0, eOverflow\n\t\t\t}\n\t\t}\n\n\t\t<bin> [01]  { add(2, '0');     goto yyc_bin }\n\t\t<oct> [0-7] { add(8, '0');     goto yyc_oct }\n\t\t<dec> [0-9] { add(10, '0');    goto yyc_dec }\n\t\t<hex> [0-9] { add(16, '0');    goto yyc_hex }\n\t\t<hex> [a-f] { add(16, 'a'-10); goto yyc_hex }\n\t\t<hex> [A-F] { add(16, 'A'-10); goto yyc_hex }\n\t*/\n}\n\nfunc main() {\n\ttest := func(num uint32, str string, err error) {\n\t\tif n, e := parse_u32(str); !(n == num && e == err) {\n\t\t\tpanic(\"error\")\n\t\t}\n\t}\n\ttest(1234567890, \"1234567890\\000\", nil)\n\ttest(13, \"0b1101\\000\", nil)\n\ttest(0x7fe, \"0x007Fe\\000\", nil)\n\ttest(0644, \"0644\\000\", nil)\n\ttest(0, \"9999999999\\000\", eOverflow)\n\ttest(0, \"123??\\000\", eSyntax)\n}\n",
      "extraCommandLineArguments": "-i --api simple"
    },
    "conditions/parse_u32_blocks.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT -i --api simple\npackage main\n\nimport \"errors\"\n\nconst u32Limit uint64 = 1<<32\nvar (\n\teSyntax   = errors.New(\"syntax error\")\n\teOverflow = errors.New(\"overflow error\")\n)\n\nfunc parse_u32(yyinput string) (uint32, error) {\n\tvar yycursor, yymarker int\n\tresult := uint64(0)\n\n\tadd := func(base uint64, offset byte) {\n\t\tresult = result * base + uint64(yyinput[yycursor-1] - offset)\n\t\tif result >= u32Limit {\n\t\t\tresult = u32Limit\n\t\t}\n\t}\n\n\t/*!re2c\n\t\tre2c:yyfill:enable = 0;\n\t\tre2c:YYCTYPE = byte;\n\n\t\tend = \"\\x00\";\n\n\t\t'0b' / [01]        { goto bin }\n\t\t\"0\"                { goto oct }\n\t\t\"\"   / [1-9]       { goto dec }\n\t\t'0x' / [0-9a-fA-F] { goto hex }\n\t\t*                  { goto err }\n\t*/\nbin:\n\t/*!re2c\n\t\tend   { goto end }\n\t\t[01]  { add(2, '0'); goto bin }\n\t\t*     { goto err }\n\t*/\noct:\n\t/*!re2c\n\t\tend   { goto end }\n\t\t[0-7] { add(8, '0'); goto oct }\n\t\t*     { goto err }\n\t*/\ndec:\n\t/*!re2c\n\t\tend   { goto end }\n\t\t[0-9] { add(10, '0'); goto dec }\n\t\t*     { goto err }\n\t*/\nhex:\n\t/*!re2c\n\t\tend   { goto end }\n\t\t[0-9] { add(16, '0');    goto hex }\n\t\t[a-f] { add(16, 'a'-10); goto hex }\n\t\t[A-F] { add(16, 'A'-10); goto hex }\n\t\t*     { goto err }\n\t*/\nend:\n\tif result < u32Limit {\n\t\treturn uint32(result), nil\n\t} else {\n\t\treturn 0, eOverflow\n\t}\nerr:\n\treturn 0, eSyntax\n}\n\nfunc main() {\n\ttest := func(num uint32, str string, err error) {\n\t\tif n, e := parse_u32(str); !(n == num && e == err) {\n\t\t\tpanic(\"error\")\n\t\t}\n\t}\n\ttest(1234567890, \"1234567890\\000\", nil)\n\ttest(13, \"0b1101\\000\", nil)\n\ttest(0x7fe, \"0x007Fe\\000\", nil)\n\ttest(0644, \"0644\\000\", nil)\n\ttest(0, \"9999999999\\000\", eOverflow)\n\ttest(0, \"123??\\000\", eSyntax)\n}\n",
      "extraCommandLineArguments": "-i --api simple"
    },
    "state/push.re": {
      "content": "//go:generate re2go -f $INPUT -o $OUTPUT\npackage main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n)\n\n// Use a small buffer to cover the case when a lexeme doesn't fit.\n// In real world use a larger buffer.\nconst BUFSIZE int = 10\n\ntype State struct {\n\tfile     *os.File\n\tyyinput  []byte\n\tyycursor int\n\tyymarker int\n\tyylimit  int\n\ttoken    int\n\tyystate  int\n}\n\nconst (\n\tlexEnd = iota\n\tlexReady\n\tlexWaitingForInput\n\tlexPacketBroken\n\tlexPacketTooBig\n)\n\nfunc fill(st *State) int {\n\tshift := st.token\n\tused := st.yylimit - st.token\n\tfree := BUFSIZE - used\n\n\t// Error: no space. In real life can reallocate a larger buffer.\n\tif free < 1 { return lexPacketTooBig }\n\n\t// Shift buffer contents (discard already processed data).\n\tcopy(st.yyinput[0:], st.yyinput[shift:shift+used])\n\tst.yycursor -= shift\n\tst.yymarker -= shift\n\tst.yylimit -= shift\n\tst.token -= shift\n\n\t// Fill free space at the end of buffer with new data.\n\tn, _ := st.file.Read(st.yyinput[st.yylimit:BUFSIZE])\n\tst.yylimit += n\n\tst.yyinput[st.yylimit] = 0 // append sentinel symbol\n\n\treturn lexReady\n}\n\nfunc lex(yyrecord *State, recv *int) int {\n\tvar yych byte\n\t/*!getstate:re2c*/\nloop:\n\tyyrecord.token = yyrecord.yycursor\n\t/*!re2c\n\t\tre2c:api = record;\n\t\tre2c:eof = 0;\n\t\tre2c:YYFILL = \"return lexWaitingForInput\";\n\n\t\tpacket = [a-z]+[;];\n\n\t\t*      { return lexPacketBroken }\n\t\t$      { return lexEnd }\n\t\tpacket { *recv = *recv + 1; goto loop }\n\t*/\n}\n\nfunc test(expect int, packets []string) {\n\t// Create a pipe (open the same file for reading and writing).\n\tfname := \"pipe\"\n\tfw, _ := os.Create(fname)\n\tfr, _ := os.Open(fname)\n\n\t// Initialize lexer state: `state` value is -1, all offsets are at the end\n\t// of buffer.\n\tst := &State{\n\t\tfile:     fr,\n\t\t// Sentinel at `yylimit` offset is set to zero, which triggers YYFILL.\n\t\tyyinput:  make([]byte, BUFSIZE+1),\n\t\tyycursor: BUFSIZE,\n\t\tyymarker: BUFSIZE,\n\t\tyylimit:  BUFSIZE,\n\t\ttoken:    BUFSIZE,\n\t\tyystate:  -1,\n\t}\n\n\t// Main loop. The buffer contains incomplete data which appears packet by\n\t// packet. When the lexer needs more input it saves its internal state and\n\t// returns to the caller which should provide more input and resume lexing.\n\tvar status int\n\tsend := 0\n\trecv := 0\n\tfor {\n\t\tstatus = lex(st, &recv)\n\t\tif status == lexEnd {\n\t\t\tbreak\n\t\t} else if status == lexWaitingForInput {\n\t\t\tif send < len(packets) {\n\t\t\t\tfw.WriteString(packets[send])\n\t\t\t\tsend += 1\n\t\t\t}\n\t\t\tstatus = fill(st)\n\t\t\tif status != lexReady {\n\t\t\t\tbreak\n\t\t\t}\n\t\t} else if status == lexPacketBroken {\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// Check results.\n\tif status != expect || (status == lexEnd && recv != send) {\n\t\tpanic(fmt.Sprintf(\"got %d, want %d\", status, expect))\n\t}\n\n\t// Cleanup: remove input file.\n\tfr.Close()\n\tfw.Close()\n\tos.Remove(fname)\n}\n\nfunc main() {\n\ttest(lexEnd, []string{})\n\ttest(lexEnd, []string{\"zero;\", \"one;\", \"two;\", \"three;\", \"four;\"})\n\ttest(lexPacketBroken, []string{\"??;\"})\n\ttest(lexPacketTooBig, []string{\"looooooooooooong;\"})\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/02_mtags.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT --api simple\npackage main\n\nimport \"reflect\"\n\nconst (\n\tmtagRoot int = -1\n\ttagNone int = -1\n)\n\n// An m-tag tree is a way to store histories with an O(1) copy operation.\n// Histories naturally form a tree, as they have common start and fork at some\n// point. The tree is stored as an array of pairs (tag value, link to parent).\n// An m-tag is represented with a single link in the tree (array index).\ntype mtagElem struct {\n\telem int\n\tpred int\n}\ntype mtagTrie = []mtagElem\n\ntype Ver = []int // unbounded number of version components\n\nfunc s2n(s string) int { // convert pre-parsed string to a number\n\tn := 0\n\tfor _, c := range s { n = n*10 + int(c-'0') }\n\treturn n\n}\n\n// Append a single value to an m-tag history.\nfunc add_mtag(trie *mtagTrie, mtag int, value int) int {\n\t*trie = append(*trie, mtagElem{value, mtag})\n\treturn len(*trie) - 1\n}\n\n// Recursively unwind tag histories and collect version components.\nfunc unwind(trie mtagTrie, x int, y int, str string) Ver {\n\t// Reached the root of the m-tag tree, stop recursion.\n\tif x == mtagRoot && y == mtagRoot {\n\t\treturn []int{}\n\t}\n\n\t// Unwind history further.\n\tver := unwind(trie, trie[x].pred, trie[y].pred, str)\n\n\t// Get tag values. Tag histories must have equal length.\n\tif x == mtagRoot || y == mtagRoot {\n\t\tpanic(\"tag histories have different length\")\n\t}\n\tex := trie[x].elem\n\tey := trie[y].elem\n\n\tif ex != tagNone && ey != tagNone {\n\t\t// Both tags are valid string indices, extract component.\n\t\tver = append(ver, s2n(str[ex:ey]))\n\t} else if !(ex == tagNone && ey == tagNone) {\n\t\tpanic(\"both tags should be tagNone\")\n\t}\n\treturn ver\n}\n\nfunc parse(yyinput string) []int {\n\tvar yycursor, yymarker int\n\ttrie := make([]mtagElem, 0)\n\n\t// Final tag variables available in semantic action.\n\t/*!svars:re2c format = 'var @@ int;'; */\n\t/*!mvars:re2c format = \"var @@ int;\"; */\n\n\t// Intermediate tag variables used by the lexer (must be autogenerated).\n\t/*!stags:re2c format = 'var @@ int'; separator = \"\\n\\t\"; */\n\t/*!mtags:re2c format = \"\\t@@ := mtagRoot\\n\"; */\n\n\t/*!re2c\n\t\tre2c:tags = 1;\n\t\tre2c:yyfill:enable = 0;\n\t\tre2c:YYCTYPE = byte;\n\t\tre2c:YYMTAGP = \"@@ = add_mtag(&trie, @@, yycursor)\";\n\t\tre2c:YYMTAGN = \"@@ = add_mtag(&trie, @@, tagNone)\";\n\n\t\tnum = [0-9]+;\n\n\t\t@t1 num @t2 (\".\" #t3 num #t4)* [\\x00] {\n\t\t\tver := make([]int, 0)\n\t\t\tver = append(ver, s2n(yyinput[t1:t2]))\n\t\t\tver = append(ver, unwind(trie, t3, t4, yyinput)...)\n\t\t\treturn ver\n\t\t}\n\t\t* { return nil }\n\t*/\n}\n\nfunc main() {\n\tassert_eq := func(x, y []int) {\n\t\tif !reflect.DeepEqual(x, y) { panic(\"error\") }\n\t}\n\tassert_eq(parse(\"1\\000\"), []int{1})\n\tassert_eq(parse(\"1.2.3.4.5.6.7\\000\"), []int{1, 2, 3, 4, 5, 6, 7})\n\tassert_eq(parse(\"1.\\000\"), nil)\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "submatch/04_posix_captures.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT --api simple\npackage main\n\nimport \"reflect\"\n\n// Maximum number of capturing groups among all rules.\n/*!maxnmatch:re2c*/\n\ntype SemVer struct { major, minor, patch int }\n\nfunc s2n(s string) int { // convert pre-parsed string to a number\n\tn := 0\n\tfor _, c := range s { n = n*10 + int(c-'0') }\n\treturn n\n}\n\nfunc parse(yyinput string) *SemVer {\n\tvar yycursor, yymarker int\n\n\t// Allocate memory for capturing parentheses (twice the number of groups).\n\tyypmatch := make([]int, YYMAXNMATCH*2)\n\tvar yynmatch int\n\n\t// Intermediate tag variables used by the lexer (must be autogenerated).\n\t/*!stags:re2c format = 'var @@ int;'; */\n\n\t/*!re2c\n\t\tre2c:yyfill:enable = 0;\n\t\tre2c:YYCTYPE = byte;\n\t\tre2c:posix-captures = 1;\n\n\t\tnum = [0-9]+;\n\n\t\t(num) \".\" (num) (\".\" num)? [\\x00] {\n\t\t\t// `yynmatch` is the number of capturing groups\n\t\t\tif yynmatch != 4 { panic(\"expected 4 submatch groups\") }\n\n\t\t\t// Even `yypmatch` values are for opening parentheses, odd values\n\t\t\t// are for closing parentheses, the first group is the whole match.\n\t\t\tmajor := s2n(yyinput[yypmatch[2]:yypmatch[3]])\n\t\t\tminor := s2n(yyinput[yypmatch[4]:yypmatch[5]])\n\t\t\tpatch := 0\n\t\t\tif yypmatch[6] != -1 { patch = s2n(yyinput[yypmatch[6]+1:yypmatch[7]]) }\n\n\t\t\treturn &SemVer{major, minor, patch}\n\t\t}\n\t\t* { return nil }\n\t*/\n}\n\nfunc main() {\n\tassert_eq := func(x, y *SemVer) {\n\t\tif !reflect.DeepEqual(x, y) { panic(\"error\") }\n\t}\n\tassert_eq(parse(\"23.34\\000\"), &SemVer{23, 34, 0})\n\tassert_eq(parse(\"1.2.9999\\000\"), &SemVer{1, 2, 9999})\n\tassert_eq(parse(\"1.a\\000\"), nil)\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "submatch/01_stags.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT --api simple\npackage main\n\nimport \"reflect\"\n\ntype SemVer struct { major, minor, patch int }\n\nfunc s2n(s string) int { // convert pre-parsed string to a number\n\tn := 0\n\tfor _, c := range s { n = n*10 + int(c-'0') }\n\treturn n\n}\n\nfunc parse(yyinput string) *SemVer {\n\tvar yycursor, yymarker int\n\n\t// Final tag variables available in semantic action.\n\t/*!svars:re2c format = 'var @@ int;'; */\n\n\t// Intermediate tag variables used by the lexer (must be autogenerated).\n\t/*!stags:re2c format = 'var @@ int;'; */\n\n\t/*!re2c\n\t\tre2c:yyfill:enable = 0;\n\t\tre2c:YYCTYPE = byte;\n\t\tre2c:tags = 1;\n\n\t\tnum = [0-9]+;\n\n\t\t@t1 num @t2 \".\" @t3 num @t4 (\".\" @t5 num)? [\\x00] {\n\t\t\tmajor := s2n(yyinput[t1:t2])\n\t\t\tminor := s2n(yyinput[t3:t4])\n\t\t\tpatch := 0\n\t\t\tif t5 != -1 { patch = s2n(yyinput[t5:yycursor-1]) }\n\t\t\treturn &SemVer{major, minor, patch}\n\t\t}\n\t\t* { return nil }\n\t*/\n}\n\nfunc main() {\n\tassert_eq := func(x, y *SemVer) {\n\t\tif !reflect.DeepEqual(x, y) { panic(\"error\") }\n\t}\n\tassert_eq(parse(\"23.34\\000\"), &SemVer{23, 34, 0})\n\tassert_eq(parse(\"1.2.9999\\000\"), &SemVer{1, 2, 9999})\n\tassert_eq(parse(\"1.a\\000\"), nil)\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "submatch/03_captures.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT --api simple\npackage main\n\nimport \"reflect\"\n\ntype SemVer struct { major, minor, patch int }\n\nfunc s2n(s string) int { // convert pre-parsed string to a number\n\tn := 0\n\tfor _, c := range s { n = n*10 + int(c-'0') }\n\treturn n\n}\n\nfunc parse(yyinput string) *SemVer {\n\tvar yycursor, yymarker int\n\n\t// Final tag variables used in semantic action.\n\t/*!svars:re2c format = 'var @@ int;'; */\n\n\t// Intermediate tag variables used by the lexer (must be autogenerated).\n\t/*!stags:re2c format = 'var @@ int;'; */\n\n\t/*!re2c\n\t\tre2c:yyfill:enable = 0;\n\t\tre2c:YYCTYPE = byte;\n\t\tre2c:captvars = 1;\n\n\t\tnum = [0-9]+;\n\n\t\t(num) \".\" (num) (\".\" num)? [\\x00] {\n\t\t\t_ = yytl0; _ = yytr0; // some variables are unused\n\t\t\tmajor := s2n(yyinput[yytl1:yytr1])\n\t\t\tminor := s2n(yyinput[yytl2:yytr2])\n\t\t\tpatch := 0\n\t\t\tif yytl3 != -1 { patch = s2n(yyinput[yytl3+1:yytr3]) }\n\n\t\t\treturn &SemVer{major, minor, patch}\n\t\t}\n\t\t* { return nil }\n\t*/\n}\n\nfunc main() {\n\tassert_eq := func(x, y *SemVer) {\n\t\tif !reflect.DeepEqual(x, y) { panic(\"error\") }\n\t}\n\tassert_eq(parse(\"23.34\\000\"), &SemVer{23, 34, 0})\n\tassert_eq(parse(\"1.2.9999\\000\"), &SemVer{1, 2, 9999})\n\tassert_eq(parse(\"1.a\\000\"), nil)\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "submatch/01_stags_fill.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT --tags\npackage main\n\nimport (\n\t\"os\"\n\t\"reflect\"\n\t\"strings\"\n)\n\nconst BUFSIZE int = 4095\n\ntype Input struct {\n\tfile     *os.File\n\tyyinput  []byte\n\tyycursor int\n\tyymarker int\n\tyylimit  int\n\ttoken    int\n\t// Intermediate tag variables must be part of the lexer state passed to YYFILL.\n\t// They don't correspond to tags and should be autogenerated by re2c.\n\t/*!stags:re2c format = \"\\t@@ int\\n\"; */\n\teof      bool\n}\n\ntype SemVer struct { major, minor, patch int }\n\nfunc s2n(s []byte) int { // convert pre-parsed string to a number\n\tn := 0\n\tfor _, c := range s { n = n*10 + int(c-'0') }\n\treturn n\n}\n\nfunc fill(in *Input) int {\n\tif in.eof { return -1 } // unexpected EOF\n\n\t// Error: lexeme too long. In real life can reallocate a larger buffer.\n\tif in.token < 1 { return -2 }\n\n\t// Shift buffer contents (discard everything up to the current token).\n\tcopy(in.yyinput[0:], in.yyinput[in.token:in.yylimit])\n\tin.yycursor -= in.token\n\tin.yymarker -= in.token\n\tin.yylimit -= in.token\n\t// Tag variables need to be shifted like other input positions. The check\n\t// for -1 is only needed if some tags are nested inside of alternative or\n\t// repetition, so that they can have -1 value.\n\t/*!stags:re2c format = \"\\tif in.@@ != -1 { in.@@ -= in.token }\\n\"; */\n\tin.token = 0\n\n\t// Fill free space at the end of buffer with new data from file.\n\tn, _ := in.file.Read(in.yyinput[in.yylimit:BUFSIZE])\n\tin.yylimit += n\n\tin.yyinput[in.yylimit] = 0\n\n\t// If read less than expected, this is the end of input.\n\tin.eof = in.yylimit < BUFSIZE\n\n\treturn 0\n}\n\nfunc parse(in *Input) []SemVer {\n\t// Final tag variables available in semantic action.\n\t/*!svars:re2c format = \"var @@ int;\"; */\n\n\tvers := make([]SemVer, 0)\n\n\tfor {\n\t\tin.token = in.yycursor\n\t/*!re2c\n\t\tre2c:api = record;\n\t\tre2c:eof = 0;\n\t\tre2c:yyrecord = in;\n\t\tre2c:YYCTYPE = byte;\n\t\tre2c:YYFILL = \"fill(in) == 0\";\n\n\t\tnum = [0-9]+;\n\n\t\tnum @t1 \".\" @t2 num @t3 (\".\" @t4 num)? [\\n] {\n\t\t\tmajor := s2n(in.yyinput[in.token:t1])\n\t\t\tminor := s2n(in.yyinput[t2:t3])\n\t\t\tpatch := 0\n\t\t\tif t4 != -1 { patch = s2n(in.yyinput[t4:in.yycursor-1]) }\n\t\t\tvers = append(vers, SemVer{major, minor, patch})\n\t\t\tcontinue\n\t\t}\n\t\t$ { return vers }\n\t\t* { return nil }\n\t*/\n\t}\n}\n\n\nfunc main() () {\n\tfname := \"input\"\n\tcontent := \"1.22.333\\n\";\n\n\texpect := make([]SemVer, 0, BUFSIZE)\n\tfor i := 0; i < BUFSIZE; i += 1 { expect = append(expect, SemVer{1, 22, 333}) }\n\n\t// Prepare input file (make sure it exceeds buffer size).\n\tf, _ := os.Create(fname)\n\tf.WriteString(strings.Repeat(content, BUFSIZE))\n\tf.Seek(0, 0)\n\n\t// Initialize lexer state: all offsets are at the end of buffer.\n\tin := &Input{\n\t\tfile:     f,\n\t\t// Sentinel at `yylimit` offset is set to zero, which triggers YYFILL.\n\t\tyyinput:  make([]byte, BUFSIZE+1),\n\t\tyycursor: BUFSIZE,\n\t\tyymarker: BUFSIZE,\n\t\tyylimit:  BUFSIZE,\n\t\ttoken:    BUFSIZE,\n\t\teof:      false,\n\t}\n\n\t// Run the lexer and check results.\n\tif !reflect.DeepEqual(parse(in), expect) { panic(\"error\"); }\n\n\t// Cleanup: remove input file.\n\tf.Close();\n\tos.Remove(fname);\n}\n",
      "extraCommandLineArguments": "--tags"
    },
    "eof/03_eof_rule.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT --api simple\npackage main\n\n// Expects a null-terminated string.\nfunc lex(yyinput string) int {\n\tvar yycursor, yymarker int\n\tyylimit := len(yyinput) - 1 // lim points at the terminating null\n\tcount := 0\n\n\tfor { /*!re2c\n\t\tre2c:YYCTYPE = byte;\n\t\tre2c:yyfill:enable = 0;\n\t\tre2c:eof = 0;\n\n\t\tstr = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n\t\t*    { return -1 }\n\t\t$    { return count }\n\t\tstr  { count += 1; continue }\n\t\t[ ]+ { continue }\n\t*/\n\t}\n}\n\nfunc main() {\n\tassert_eq := func(x, y int) { if x != y { panic(\"error\") } }\n\tassert_eq(lex(\"\\000\"), 0)\n\tassert_eq(lex(\"'qu\\000tes' 'are' 'fine: \\\\'' \\000\"), 3)\n\tassert_eq(lex(\"'unterminated\\\\'\\000\"), -1)\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "eof/04_fake_sentinel.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT\npackage main\n\n// Returns \"fake\" terminating null if cursor has reached limit.\nfunc peek(str string, cur int) byte {\n\tif cur >= len(str) {\n\t\treturn 0 // fake null\n\t} else {\n\t\treturn str[cur]\n\t}\n}\n\n// Expects a string without terminating null.\nfunc lex(str string) int {\n\tvar cur int\n\tcount := 0\n\n\tfor { /*!re2c\n\t\tre2c:yyfill:enable = 0;\n\t\tre2c:YYCTYPE = byte;\n\t\tre2c:YYPEEK = \"peek(str, cur)\";\n\t\tre2c:YYSKIP = \"cur += 1\";\n\n\t\t*      { return -1 }\n\t\t[\\x00] { return count }\n\t\t[a-z]+ { count += 1; continue }\n\t\t[ ]+   { continue }\n\t*/\n\t}\n}\n\nfunc main() {\n\tassert_eq := func(x, y int) { if x != y { panic(\"error\") } }\n\tassert_eq(lex(\"\"), 0)\n\tassert_eq(lex(\"one two three\"), 3)\n\tassert_eq(lex(\"f0ur\"), -1)\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/02_bounds_checking.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT --api simple\npackage main\n\nimport \"strings\"\n\n/*!max:re2c*/\n\n// Expects YYMAXFILL-padded string.\nfunc lex(str string) int {\n\t// Pad string with YYMAXFILL zeroes at the end.\n\tyyinput := str + strings.Repeat(\"\\000\", int(YYMAXFILL))\n\n\tyycursor := 0\n\tyylimit := len(yyinput)\n\tcount := 0\n\n\tfor { /*!re2c\n\t\tre2c:YYCTYPE = byte;\n\t\tre2c:YYFILL = \"return -1\";\n\n\t\tstr = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n\t\t[\\x00] {\n\t\t\t// Check that it is the sentinel, not some unexpected null.\n\t\t\tif yycursor - 1 == len(str) { return count } else { return -1 }\n\t\t}\n\t\tstr  { count += 1; continue }\n\t\t[ ]+ { continue }\n\t\t*    { return -1 }\n\t*/\n\t}\n}\n\nfunc main() {\n\tassert_eq := func(x, y int) { if x != y { panic(\"error\") } }\n\tassert_eq(lex(\"\"), 0)\n\tassert_eq(lex(\"'qu\\000tes' 'are' 'fine: \\\\'' \"), 3)\n\tassert_eq(lex(\"'unterminated\\\\'\"), -1)\n\tassert_eq(lex(\"'unexpected \\000 null\\\\'\"), -1)\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "eof/01_sentinel.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT --api simple\npackage main\n\n// Expect a null-terminated string.\nfunc lex(yyinput string) int {\n\tyycursor := 0\n\tcount := 0\n\n\tfor { /*!re2c\n\t\tre2c:yyfill:enable = 0;\n\t\tre2c:YYCTYPE = byte;\n\n\t\t*      { return -1 }\n\t\t[\\x00] { return count }\n\t\t[a-z]+ { count += 1; continue }\n\t\t[ ]+   { continue }\n\t*/\n\t}\n}\n\nfunc main() {\n\tassert_eq := func(x, y int) { if x != y { panic(\"error\") } }\n\tassert_eq(lex(\"\\000\"), 0)\n\tassert_eq(lex(\"one two three\\000\"), 3)\n\tassert_eq(lex(\"f0ur\\000\"), -1)\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "includes/include.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT -i --api simple\npackage main\n\n/*!include:re2c \"definitions.go\" */\n\nfunc lex(yyinput string) int {\n\tvar yycursor, yymarker int\n\t/*!re2c\n\t\tre2c:YYCTYPE = byte;\n\t\tre2c:yyfill:enable = 0;\n\n\t\t*      { return ResultFail }\n\t\tnumber { return ResultOk }\n\t\t!include \"extra_rules.re.inc\";\n\t*/\n}\n\nfunc main() {\n\tassert_eq := func(x, y int) { if x != y { panic(\"error\") } }\n\tassert_eq(lex(\"123\\000\"), ResultOk)\n\tassert_eq(lex(\"123.4567\\000\"), ResultOk)\n}\n",
      "extraCommandLineArguments": "-i --api simple"
    },
    "encodings/unicode_identifier.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT -8si --api simple\npackage main\n\n/*!include:re2c \"unicode_categories.re\" */\n\nfunc lex(yyinput string) int {\n\tvar yycursor, yymarker int\n\t/*!re2c\n\t\tre2c:yyfill:enable = 0;\n\t\tre2c:YYCTYPE = byte;\n\n\t\t// Simplified \"Unicode Identifier and Pattern Syntax\"\n\t\t// (see https://unicode.org/reports/tr31)\n\t\tid_start    = L | Nl | [$_];\n\t\tid_continue = id_start | Mn | Mc | Nd | Pc | [\\u200D\\u05F3];\n\t\tidentifier  = id_start id_continue*;\n\n\t\tidentifier { return 0 }\n\t\t*          { return 1 }\n\t*/\n}\n\nfunc main() {\n\tif lex(\"_\u042b\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\\000\") != 0 {\n\t\tpanic(\"error\")\n\t}\n}\n",
      "extraCommandLineArguments": "-8si --api simple"
    },
    "reuse/reuse.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT --input-encoding utf8 --api simple\npackage main\n\n// This example supports multiple input encodings: UTF-8 and UTF-32.\n// Both lexers are generated from the same rules block, and the use\n// blocks add only encoding-specific configurations.\n/*!rules:re2c\n\tre2c:yyfill:enable = 0;\n\n\t\"\u2200x \u2203y\" { return 0; }\n\t*       { return 1; }\n*/\n\nfunc lexUTF8(yyinput []uint8) int {\n\tvar yycursor, yymarker int\n\t/*!use:re2c\n\t\tre2c:encoding:utf8 = 1;\n\t\tre2c:YYCTYPE = uint8;\n\t*/\n}\n\nfunc lexUTF32(yyinput []uint32) int {\n\tvar yycursor, yymarker int\n\t/*!use:re2c\n\t\tre2c:encoding:utf32 = 1;\n\t\tre2c:YYCTYPE = uint32;\n\t*/\n}\n\nfunc main() {\n\tassert_eq := func(x, y int) { if x != y { panic(\"error\") } }\n\tassert_eq(lexUTF8([]uint8{0xe2, 0x88, 0x80, 0x78, 0x20, 0xe2, 0x88, 0x83, 0x79}), 0)\n\tassert_eq(lexUTF32([]uint32{0x2200, 0x78, 0x20, 0x2203, 0x79}), 0)\n}\n",
      "extraCommandLineArguments": "--input-encoding utf8 --api simple"
    },
    "reuse/usedir.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT --api simple\npackage main\n\n// This example shows how to combine reusable re2c blocks: two blocks\n// ('colors' and 'fish') are merged into one. The 'salmon' rule occurs\n// in both blocks; the 'fish' block takes priority because it is used\n// earlier. Default rule * occurs in all three blocks; the local (not\n// inherited) definition takes priority.\n\nconst (\n\tColor = iota\n\tFish\n\tDunno\n)\n\n/*!rules:re2c:colors\n\t*                            { panic(\"eh!\") }\n\t\"red\" | \"salmon\" | \"magenta\" { return Color }\n*/\n\n/*!rules:re2c:fish\n\t*                            { panic(\"oh!\") }\n\t\"haddock\" | \"salmon\" | \"eel\" { return Fish }\n*/\n\nfunc lex(yyinput string) int {\n\tvar yycursor, yymarker int\n\t/*!re2c\n\t\tre2c:yyfill:enable = 0;\n\t\tre2c:YYCTYPE = byte;\n\n\t\t!use:fish;\n\t\t!use:colors;\n\t\t* { return Dunno }  // overrides inherited '*' rules\n\t*/\n}\n\nfunc main() {\n\tassert_eq := func(x, y int) { if x != y { panic(\"error\") } }\n\tassert_eq(lex(\"salmon\"), Fish);\n\tassert_eq(lex(\"what?\"), Dunno);\n}\n",
      "extraCommandLineArguments": "--api simple"
    },
    "headers/header.re": {
      "content": "//go:generate re2go $INPUT -o $OUTPUT -i --header lexer/state.go\npackage main\n\nimport \"./lexer\" // the package is generated by re2c\n\n/*!header:re2c:on*/\npackage lexer\n\ntype State struct {\n\tData string\n\tCur /*!stags:re2c format=\", @@\"; */ int\n}\n/*!header:re2c:off*/\n\nfunc lex(yyrecord *lexer.State) int {\n\tvar t int\n\t/*!re2c\n\t\tre2c:header = \"lexer/state.go\";\n\t\tre2c:api = record;\n\t\tre2c:YYCTYPE = byte;\n\t\tre2c:YYINPUT = \"yyrecord.Data\";\n\t\tre2c:YYCURSOR = \"yyrecord.Cur\";\n\t\tre2c:yyfill:enable = 0;\n\t\tre2c:tags = 1;\n\t\tre2c:tags:prefix = \"Tag\";\n\n\t\t[a]* @t [b]* { return t }\n\t*/\n}\n\nfunc main() {\n\tst := &lexer.State{Data:\"ab\\x00\",}\n\tif lex(st) != 1 {\n\t\tpanic(\"error\")\n\t}\n}\n",
      "extraCommandLineArguments": "-i --header lexer/state.go"
    }
  },
  "java": {
    "01_basic.re": {
      "content": "// re2java $INPUT -o $OUTPUT\n\nclass Main {\n    static boolean lex(String yyinput) {\n        int yycursor = 0;\n\n        /*!re2c\n            re2c:YYCTYPE = \"char\";\n            re2c:YYPEEK = \"yyinput.charAt(yycursor)\";\n            re2c:yyfill:enable = 0;\n\n            [1-9][0-9]* { return true; }\n            *           { return false; }\n        */\n    }\n\n    public static void main(String []args) {\n        assert lex(\"1234\\0\");\n    }\n};\n",
      "extraCommandLineArguments": ""
    },
    "fill/01_fill.re": {
      "content": "// re2java $INPUT -o $OUTPUT\n\nimport java.io.*;\nimport java.nio.file.*;\n\nclass Lexer {\n    public static final int BUFSIZE = 4096;\n\n    private BufferedInputStream stream;\n    private byte[] yyinput;\n    private int yycursor;\n    private int yymarker;\n    private int yylimit;\n    private int token;\n    private boolean eof;\n\n    public Lexer(File file) throws FileNotFoundException {\n        stream = new BufferedInputStream(new FileInputStream(file));\n        // Sentinel at `yylimit` offset is set to zero, which triggers YYFILL.\n        yyinput = new byte[BUFSIZE + 1];\n        yycursor = yymarker = yylimit = token = BUFSIZE;\n        eof = false;\n    }\n\n    private int fill() throws IOException {\n        if (eof) { return -1; } // unexpected EOF\n\n        // Error: lexeme too long. In real life can reallocate a larger buffer.\n        if (token < 1) { return -2; }\n\n        // Shift buffer contents (discard everything up to the current token).\n        System.arraycopy(yyinput, token, yyinput, 0, yylimit - token); \n        yycursor -= token;\n        yymarker -= token;\n        yylimit -= token;\n        token = 0;\n\n        // Fill free space at the end of buffer with new data from file.\n        yylimit += stream.read(yyinput, yylimit, BUFSIZE - yylimit);\n        yyinput[yylimit] = 0; // append sentinel symbol\n\n        // If read less than expected, this is the end of input.\n        eof = yylimit < BUFSIZE;\n\n        return 0;\n    }\n\n    // Expects a null-terminated string.\n    public int lex() throws IOException {\n        int count = 0;\n        loop: while (true) {\n            token = yycursor;\n            /*!re2c\n                re2c:YYCTYPE = \"byte\";\n                re2c:YYPEEK = \"yyinput[yycursor]\";\n                re2c:YYFILL = \"fill() == 0\";\n                re2c:eof = 0;\n\n                str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n                *    { return -1; }\n                $    { return count; }\n                str  { count += 1; continue loop; }\n                [ ]+ { continue loop; }\n            */\n        }\n    }\n\n    public static void main(String []args) throws FileNotFoundException, IOException {\n        String fname = \"input\";\n        String content = \"'qu\\0tes' 'are' 'fine: \\\\'' \".repeat(Lexer.BUFSIZE);\n\n        // Prepare input file: a few times the size of the buffer, containing\n        // strings with zeroes and escaped quotes.\n        Files.writeString(Paths.get(fname), content);\n\n        int count = 3 * Lexer.BUFSIZE; // number of quoted strings written to file\n\n        // Prepare lexer state: all offsets are at the end of buffer.\n        File file = new File(\".\", fname);\n        Lexer lexer = new Lexer(file);\n\n        // Run the lexer.\n        int n = lexer.lex();\n        assert n == count;\n\n        // Cleanup: remove input file.\n        file.delete();\n    }\n};\n",
      "extraCommandLineArguments": ""
    },
    "fill/02_fill.re": {
      "content": "// re2java $INPUT -o $OUTPUT\n\nimport java.io.*;\nimport java.nio.file.*;\nimport java.util.Arrays;\n\nclass Lexer {\n    /*!max:re2c*/\n    public static final int BUFSIZE = 4096;\n\n    private BufferedInputStream stream;\n    private byte[] yyinput;\n    private int yycursor;\n    private int yylimit;\n    private int token;\n    private boolean eof;\n\n    public Lexer(File file) throws FileNotFoundException {\n        stream = new BufferedInputStream(new FileInputStream(file));\n        // Prepare lexer state: all offsets are at the end of buffer.\n        // This immediately triggers YYFILL, as the YYLESSTHAN condition is true.\n        yyinput = new byte[BUFSIZE + YYMAXFILL];\n        yycursor = yylimit = token = BUFSIZE;\n        eof = false;\n    }\n\n    private int fill(int need) throws IOException {\n        if (eof) { return -1; } // unexpected EOF\n\n        // Error: lexeme too long. In real life can reallocate a larger buffer.\n        if (token < need) { return -2; }\n\n        // Shift buffer contents (discard everything up to the current token).\n        System.arraycopy(yyinput, token, yyinput, 0, yylimit - token); \n        yycursor -= token;\n        yylimit -= token;\n        token = 0;\n\n        // Fill free space at the end of buffer with new data from file.\n        yylimit += stream.read(yyinput, yylimit, BUFSIZE - yylimit);\n        yyinput[yylimit] = 0; // append sentinel symbol\n\n        // If read less than expected, this is the end of input.\n        if (yylimit < BUFSIZE) {\n            eof = true;\n            Arrays.fill(yyinput, yylimit, yylimit + YYMAXFILL, (byte)0);\n            yylimit += YYMAXFILL;\n        }\n\n        return 0;\n    }\n\n    // Expects a null-terminated string.\n    public int lex() throws IOException {\n        int count = 0;\n        loop: while (true) {\n            token = yycursor;\n            /*!re2c\n                re2c:YYCTYPE = \"byte\";\n                re2c:YYPEEK = \"yyinput[yycursor]\";\n                re2c:YYFILL = \"if (fill(@@) != 0) { return -2; }\";\n\n                str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n                [\\x00] {\n                    // Check that it is the sentinel, not some unexpected null.\n                    return (token == yylimit - YYMAXFILL) ? count : -1;\n                }\n                str  { count += 1; continue loop; }\n                [ ]+ { continue loop; }\n                *    { return -1; }\n            */\n        }\n    }\n\n    public static void main(String []args) throws FileNotFoundException, IOException {\n        String fname = \"input\";\n        String content = \"'qu\\0tes' 'are' 'fine: \\\\'' \".repeat(Lexer.BUFSIZE);\n\n        // Prepare input file: a few times the size of the buffer, containing\n        // strings with zeroes and escaped quotes.\n        Files.writeString(Paths.get(fname), content);\n\n        int count = 3 * Lexer.BUFSIZE; // number of quoted strings written to file\n\n        // Prepare lexer state: all offsets are at the end of buffer.\n        File file = new File(\".\", fname);\n        Lexer lexer = new Lexer(file);\n\n        // Run the lexer.\n        int n = lexer.lex();\n        assert n == count;\n\n        // Cleanup: remove input file.\n        file.delete();\n    }\n};\n",
      "extraCommandLineArguments": ""
    },
    "conditions/parse_u32_conditions.re": {
      "content": "// re2java $INPUT -o $OUTPUT -c\n\nclass Parser {\n    /*!conditions:re2c*/\n    private String yyinput;\n    private int yycursor;\n    private int yymarker;\n    private int number;\n\n    private void add_digit(int base, int offset) throws ArithmeticException {\n        number = Math.addExact(\n            Math.multiplyExact(number, base),\n            yyinput.charAt(yycursor - 1) - offset);\n    }\n\n    public int parse(String str) throws ArithmeticException, IllegalArgumentException {\n        yyinput = str;\n        yycursor = 0;\n        int yycond = YYC_init;\n\n        number = 0;\n        try {\n            loop: while (true) {\n            /*!re2c\n                re2c:YYCTYPE = \"char\";\n                re2c:YYPEEK = \"yyinput.charAt(yycursor)\";\n                re2c:yyfill:enable = 0;\n\n                <*> * { throw new IllegalArgumentException(\"ill-formed number\"); }\n\n                <init> '0b' / [01]        :=> bin\n                <init> \"0\"                :=> oct\n                <init> \"\"   / [1-9]       :=> dec\n                <init> '0x' / [0-9a-fA-F] :=> hex\n\n                <bin, oct, dec, hex> \"\\x00\" { return number; }\n\n                <bin> [01]  { add_digit(2, 48); continue loop; }\n                <oct> [0-7] { add_digit(8, 48); continue loop; }\n                <dec> [0-9] { add_digit(10, 48); continue loop; }\n                <hex> [0-9] { add_digit(16, 48); continue loop; }\n                <hex> [a-f] { add_digit(16, 87); continue loop; }\n                <hex> [A-F] { add_digit(16, 55); continue loop; }\n            */\n            }\n        } catch (Exception e) {\n            return -1;\n        }\n    }\n\n    public static void main(String []args) {\n        Parser parser = new Parser();\n        assert parser.parse(\"1234567890\\0\") == 1234567890;\n        assert parser.parse(\"0b1101\\0\") == 0b1101;\n        assert parser.parse(\"0x007Fe\\0\") == 0x7fe;\n        assert parser.parse(\"0644\\0\") == 0644;\n        assert parser.parse(\"9999999999\\0\") == -1;\n        assert parser.parse(\"123??\\0\") == -1;\n    }\n};\n",
      "extraCommandLineArguments": "-c"
    },
    "conditions/parse_u32_blocks.re": {
      "content": "// re2java $INPUT -o $OUTPUT\n\nclass Parser {\n    private String yyinput;\n    private int yycursor;\n    private int yymarker;\n    private int number;\n\n    private void add_digit(int base, int offset) throws ArithmeticException {\n        number = Math.addExact(\n            Math.multiplyExact(number, base),\n            yyinput.charAt(yycursor - 1) - offset);\n    }\n\n    public int parse(String str) throws ArithmeticException, IllegalArgumentException {\n        yyinput = str;\n        yycursor = 0;\n        number = 0;\n\n        try {\n            /*!re2c\n                re2c:YYCTYPE = \"char\";\n                re2c:YYPEEK = \"yyinput.charAt(yycursor)\";\n                re2c:yyfill:enable = 0;\n\n                end = \"\\x00\";\n\n                '0b' / [01]        { return parse_bin(); }\n                \"0\"                { return parse_oct(); }\n                \"\"   / [1-9]       { return parse_dec(); }\n                '0x' / [0-9a-fA-F] { return parse_hex(); }\n                *                  { throw new IllegalArgumentException(\"not a number\"); }\n            */\n        } catch (Exception e) {\n            return -1;\n        }\n    }\n\n    private int parse_bin() throws ArithmeticException, IllegalArgumentException {\n        /*!re2c\n            end   { return number; }\n            [01]  { add_digit(2, 48); return parse_bin(); }\n            *     { throw new IllegalArgumentException(\"ill-formed binary number\"); }\n        */\n    }\n\n    private int parse_oct() throws ArithmeticException, IllegalArgumentException {\n        /*!re2c\n            end   { return number; }\n            [0-7] { add_digit(8, 48); return parse_oct(); }\n            *     { throw new IllegalArgumentException(\"ill-formed octal number\"); }\n        */\n    }\n\n    private int parse_dec() throws ArithmeticException, IllegalArgumentException {\n        /*!re2c\n            end   { return number; }\n            [0-9] { add_digit(10, 48); return parse_dec(); }\n            *     { throw new IllegalArgumentException(\"ill-formed decimal number\"); }\n        */\n    }\n\n    private int parse_hex() throws ArithmeticException, IllegalArgumentException {\n        /*!re2c\n            end   { return number; }\n            [0-9] { add_digit(16, 48); return parse_hex(); }\n            [a-f] { add_digit(16, 87); return parse_hex(); }\n            [A-F] { add_digit(16, 55); return parse_hex(); }\n            *     { throw new IllegalArgumentException(\"ill-formed hexadecimal number\"); }\n        */\n    }\n\n    public static void main(String []args) {\n        Parser parser = new Parser();\n        assert parser.parse(\"1234567890\\0\") == 1234567890;\n        assert parser.parse(\"0b1101\\0\") == 0b1101;\n        assert parser.parse(\"0x007Fe\\0\") == 0x7fe;\n        assert parser.parse(\"0644\\0\") == 0644;\n        assert parser.parse(\"9999999999\\0\") == -1;\n        assert parser.parse(\"123??\\0\") == -1;\n    }\n};\n",
      "extraCommandLineArguments": ""
    },
    "state/push.re": {
      "content": "// re2java $INPUT -o $OUTPUT -f\n\nimport java.io.IOException;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.Pipe;\n\nclass Lexer {\n    enum Status {\n        END,\n        READY,\n        WAITING,\n        BIG_PACKET,\n        BAD_PACKET\n    };\n\n    // Use a small buffer to cover the case when a lexeme doesn't fit.\n    // In real world use a larger buffer.\n    public static final int BUFSIZE = 10;\n\n    public static class State {\n        Pipe.SourceChannel source;\n        byte[] yyinput;\n        int yycursor;\n        int yymarker;\n        int yylimit;\n        int token;\n        int yystate;\n        int received;\n\n        public State(Pipe pipe) {\n            source = pipe.source();\n            // Sentinel at `yylimit` offset is set to zero, which triggers YYFILL.\n            yyinput = new byte[BUFSIZE + 1];\n            yycursor = yymarker = yylimit = token = BUFSIZE;\n            yystate = -1;\n            received = 0;\n        }\n    }\n\n    private static void log(String format, Object... args) {\n        if (false) { System.out.printf(format + \"\\n\", args); }\n    }\n\n    private static Status fill(State st) throws IOException {\n        // Error: lexeme too long. In real life can reallocate a larger buffer.\n        if (st.token < 1) { return Status.BIG_PACKET; }\n\n        // Shift buffer contents (discard everything up to the current token).\n        System.arraycopy(st.yyinput, st.token, st.yyinput, 0, st.yylimit - st.token); \n        st.yycursor -= st.token;\n        st.yymarker -= st.token;\n        st.yylimit -= st.token;\n        st.token = 0;\n\n        // Fill free space at the end of buffer with new data from file.\n        ByteBuffer buffer = ByteBuffer.wrap(st.yyinput, st.yylimit, BUFSIZE - st.yylimit);\n        int have = st.source.read(buffer);\n        if (have != -1) st.yylimit += have; // -1 means that pipe is closed\n        st.yyinput[st.yylimit] = 0; // append sentinel symbol\n\n        return Status.READY;\n    }\n\n    private static Status lex(State yyrecord) {\n        byte yych;\n        loop: while (true) {\n            yyrecord.token = yyrecord.yycursor;\n            /*!re2c\n                re2c:api = record;\n                re2c:YYCTYPE = \"byte\";\n                re2c:YYPEEK = \"yyrecord.yyinput[yyrecord.yycursor]\";\n                re2c:YYFILL = \"return Status.WAITING;\";\n                re2c:eof = 0;\n\n                packet = [a-z]+[;];\n\n                *      { return Status.BAD_PACKET; }\n                $      { return Status.END; }\n                packet { yyrecord.received += 1; continue loop; }\n            */\n        }\n    }\n\n    public static void test(String[] packets, Status expect) throws IOException {\n        // Create a pipe.\n        Pipe pipe = Pipe.open();\n        Pipe.SinkChannel sink = pipe.sink();\n\n        // Initialize lexer state\n        Lexer.State st = new Lexer.State(pipe);\n\n        // Main loop. The buffer contains incomplete data which appears packet by\n        // packet. When the lexer needs more input it saves its internal state and\n        // returns to the caller which should provide more input and resume lexing.\n        int send = 0;\n        Status status;\n        while (true) {\n            status = lex(st);\n\n            if (status == Status.END) {\n                log(\"done: got %d packets\", st.received);\n                break;\n            } else if (status == Status.WAITING) {\n                log(\"waiting...\");\n\n                if (send < packets.length) {\n                    log(\"sent packet %d: %s\", send, packets[send]);\n                    ByteBuffer buffer = ByteBuffer.wrap(packets[send].getBytes());\n                    sink.write(buffer);\n                    send += 1;\n                } else {\n                    sink.close();\n                }\n\n                status = fill(st);\n                if (status == Status.BIG_PACKET) {\n                    log(\"error: packet too big\");\n                    break;\n                }\n                assert status == Status.READY;\n            } else {\n                assert status == Status.BAD_PACKET;\n                log(\"error: ill-formed packet\");\n                break;\n            }\n        }\n\n        // Check results.\n        assert status == expect;\n        if (status == Status.END) {\n            assert send == st.received;\n        }\n    }\n\n    public static void main(String []args) throws IOException {\n        test(new String[]{}, Status.END);\n        test(new String[]{\"zero;\", \"one;\", \"two;\", \"three;\", \"four;\"}, Status.END);\n        test(new String[]{\"zer0;\"}, Status.BAD_PACKET);\n        test(new String[]{\"goooooooooogle;\"}, Status.BIG_PACKET);\n    }\n};\n",
      "extraCommandLineArguments": "-f"
    },
    "submatch/02_mtags.re": {
      "content": "// re2java $INPUT -o $OUTPUT\n\nimport java.util.*;\n\nclass Main {\n    static Optional<int[]> parse(String yyinput) {\n        int yycursor = 0;\n        int yymarker = 0;\n\n        // Final tag variables available in semantic action.\n        /*!svars:re2c format = \"int @@;\"; */\n        /*!mvars:re2c format = \"List<Integer> @@;\"; */\n\n        // Intermediate tag variables used by the lexer (must be autogenerated).\n        /*!stags:re2c format = \"int @@ = -1;\"; */\n        /*!mtags:re2c format = \"List<Integer> @@ = new ArrayList<>();\"; */\n\n        /*!re2c\n            re2c:YYCTYPE = \"char\";\n            re2c:YYPEEK = \"yyinput.charAt(yycursor)\";\n            re2c:YYMTAGP = \"@@.add(yycursor);\";\n            re2c:YYMTAGN = \"\"; // do nothing\n            re2c:yyfill:enable = 0;\n            re2c:tags = 1;\n\n            num = [0-9]+;\n\n            @t1 num @t2 (\".\" #t3 num #t4)* [\\x00] {\n                int[] vers = new int[t3.size() + 1];\n                vers[0] = Integer.valueOf(yyinput.substring(t1, t2));\n                for (int i = 0; i < t3.size(); ++i) {\n                    vers[i + 1] = Integer.valueOf(yyinput.substring(t3.get(i), t4.get(i)));\n                }\n                return Optional.of(vers);\n            }\n            * { return Optional.empty(); }\n        */\n    }\n\n    public static void main(String []args) {\n        assert Arrays.equals(parse(\"1\\0\").get(), new int[]{1});\n        assert Arrays.equals(parse(\"1.2.3.4.5.6.7\\0\").get(), new int[]{1, 2, 3, 4, 5, 6, 7});\n        assert !parse(\"1.2.\\0\").isPresent();\n    }\n};\n",
      "extraCommandLineArguments": ""
    },
    "submatch/04_posix_captures.re": {
      "content": "// re2java $INPUT -o $OUTPUT\n\nimport java.util.Optional;\n\nclass Main {\n    // Maximum number of capturing groups among all rules.\n    /*!maxnmatch:re2c*/\n\n    static class SemVer {\n        int major;\n        int minor;\n        int patch;\n\n        public SemVer(int m, int n, int k) {\n            major = m;\n            minor = n;\n            patch = k;\n        }\n\n        public boolean equals(SemVer v) {\n            return major == v.major && minor == v.minor && patch == v.patch;\n        }\n    };\n\n    static Optional<SemVer> parse(String yyinput) {\n        int yycursor = 0;\n        int yymarker = 0;\n\n        // Array for capturing parentheses (twice the number of groups).\n        int yynmatch;\n        int[] yypmatch = new int[YYMAXNMATCH * 2];\n\n        // Intermediate tag variables used by the lexer (must be autogenerated).\n        /*!stags:re2c format = \"int @@ = -1;\"; */\n\n        /*!re2c\n            re2c:YYCTYPE = \"char\";\n            re2c:YYPEEK = \"yyinput.charAt(yycursor)\";\n            re2c:yyfill:enable = 0;\n            re2c:posix-captures = 1;\n\n            num = [0-9]+;\n\n            (num) \".\" (num) (\".\" num)? [\\x00] {\n                // `yynmatch` is the number of capturing groups\n                assert yynmatch == 4;\n\n                // Even `yypmatch` values are for opening parentheses, odd values\n                // are for closing parentheses, the first group is the whole match.\n                int major = Integer.valueOf(yyinput.substring(yypmatch[2], yypmatch[3]));\n                int minor = Integer.valueOf(yyinput.substring(yypmatch[4], yypmatch[5]));\n                int patch = (yypmatch[6] == -1) ? 0\n                        : Integer.valueOf(yyinput.substring(yypmatch[6] + 1, yypmatch[7]));\n                return Optional.of(new SemVer(major, minor, patch));\n            }\n            * { return Optional.empty(); }\n        */\n    }\n\n    public static void main(String []args) {\n        assert parse(\"23.34\\0\").get().equals(new SemVer(23, 34, 0));\n        assert parse(\"1.2.99999\\0\").get().equals(new SemVer(1, 2, 99999));\n        assert !parse(\"1.a\\0\").isPresent();\n    }\n};\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags.re": {
      "content": "// re2java $INPUT -o $OUTPUT\n\nimport java.util.Optional;\n\nclass Main {\n    static class SemVer {\n        int major;\n        int minor;\n        int patch;\n\n        public SemVer(int m, int n, int k) {\n            major = m;\n            minor = n;\n            patch = k;\n        }\n\n        public boolean equals(SemVer v) {\n            return major == v.major && minor == v.minor && patch == v.patch;\n        }\n    };\n\n    static Optional<SemVer> parse(String yyinput) {\n        int yycursor = 0;\n        int yymarker = 0;\n\n        // Final tag variables available in semantic action.\n        /*!svars:re2c format = \"int @@;\"; */\n\n        // Intermediate tag variables used by the lexer (must be autogenerated).\n        /*!stags:re2c format = \"int @@ = -1;\"; */\n\n        /*!re2c\n            re2c:YYCTYPE = \"char\";\n            re2c:YYPEEK = \"yyinput.charAt(yycursor)\";\n            re2c:yyfill:enable = 0;\n            re2c:tags = 1;\n\n            num = [0-9]+;\n\n            @t1 num @t2 \".\" @t3 num @t4 (\".\" @t5 num)? [\\x00] {\n                int major = Integer.valueOf(yyinput.substring(t1, t2));\n                int minor = Integer.valueOf(yyinput.substring(t3, t4));\n                int patch = (t5 == -1) ? 0 : Integer.valueOf(yyinput.substring(t5, yycursor - 1));\n                return Optional.of(new SemVer(major, minor, patch));\n            }\n            * { return Optional.empty(); }\n        */\n    }\n\n    public static void main(String []args) {\n        assert parse(\"23.34\\0\").get().equals(new SemVer(23, 34, 0));\n        assert parse(\"1.2.99999\\0\").get().equals(new SemVer(1, 2, 99999));\n        assert !parse(\"1.a\\0\").isPresent();\n    }\n};\n",
      "extraCommandLineArguments": ""
    },
    "submatch/03_captures.re": {
      "content": "// re2java $INPUT -o $OUTPUT\n\nimport java.util.Optional;\n\nclass Main {\n    static class SemVer {\n        int major;\n        int minor;\n        int patch;\n\n        public SemVer(int m, int n, int k) {\n            major = m;\n            minor = n;\n            patch = k;\n        }\n\n        public boolean equals(SemVer v) {\n            return major == v.major && minor == v.minor && patch == v.patch;\n        }\n    };\n\n    static Optional<SemVer> parse(String yyinput) {\n        int yycursor = 0;\n        int yymarker = 0;\n\n        // Final tag variables available in semantic action.\n        /*!svars:re2c format = \"int @@;\"; */\n\n        // Intermediate tag variables used by the lexer (must be autogenerated).\n        /*!stags:re2c format = \"int @@ = -1;\"; */\n\n        /*!re2c\n            re2c:YYCTYPE = \"char\";\n            re2c:YYPEEK = \"yyinput.charAt(yycursor)\";\n            re2c:yyfill:enable = 0;\n            re2c:captvars = 1;\n\n            num = [0-9]+;\n\n            (num) \".\" (num) (\".\" num)? [\\x00] {\n                int major = Integer.valueOf(yyinput.substring(yytl1, yytr1));\n                int minor = Integer.valueOf(yyinput.substring(yytl2, yytr2));\n                int patch = (yytl3 == -1) ? 0\n                        : Integer.valueOf(yyinput.substring(yytl3 + 1, yytr3));\n                return Optional.of(new SemVer(major, minor, patch));\n            }\n            * { return Optional.empty(); }\n        */\n    }\n\n    public static void main(String []args) {\n        assert parse(\"23.34\\0\").get().equals(new SemVer(23, 34, 0));\n        assert parse(\"1.2.99999\\0\").get().equals(new SemVer(1, 2, 99999));\n        assert !parse(\"1.a\\0\").isPresent();\n    }\n};\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags_fill.re": {
      "content": "// re2java $INPUT -o $OUTPUT\n\nimport java.io.*;\nimport java.nio.file.*;\nimport java.util.*;\n\nclass Lexer {\n    static class SemVer {\n        int major;\n        int minor;\n        int patch;\n\n        public SemVer(int m, int n, int k) {\n            major = m;\n            minor = n;\n            patch = k;\n        }\n\n        public boolean equals(SemVer v) {\n            return major == v.major && minor == v.minor && patch == v.patch;\n        }\n    };\n\n    public static final int BUFSIZE = 4096;\n\n    private BufferedInputStream stream;\n    private byte[] yyinput;\n    private int yycursor;\n    private int yymarker;\n    private int yylimit;\n    private int token;\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    /*!stags:re2c format = \"private int @@;\\n\"; */\n    private boolean eof;\n\n    public Lexer(File file) throws FileNotFoundException {\n        stream = new BufferedInputStream(new FileInputStream(file));\n        // Sentinel at `yylimit` offset is set to zero, which triggers YYFILL.\n        yyinput = new byte[BUFSIZE + 1];\n        yycursor = yymarker = yylimit = token = BUFSIZE;\n        /*!stags:re2c format = \"@@ = -1;\\n\"; */\n        eof = false;\n    }\n\n    private int fill() throws IOException {\n        if (eof) { return -1; } // unexpected EOF\n\n        // Error: lexeme too long. In real life can reallocate a larger buffer.\n        if (token < 1) { return -2; }\n\n        // Shift buffer contents (discard everything up to the current token).\n        System.arraycopy(yyinput, token, yyinput, 0, yylimit - token); \n        yycursor -= token;\n        yymarker -= token;\n        yylimit -= token;\n        /*!stags:re2c format = \"if (@@ != -1) {@@ -= token;}\\n\"; */\n        token = 0;\n\n        // Fill free space at the end of buffer with new data from file.\n        yylimit += stream.read(yyinput, yylimit, BUFSIZE - yylimit);\n        yyinput[yylimit] = 0; // append sentinel symbol\n\n        // If read less than expected, this is the end of input.\n        eof = yylimit < BUFSIZE;\n\n        return 0;\n    }\n\n    private int readInt(int tag1, int tag2) {\n        int n = 0;\n        for (int i = tag1; i < tag2; ++i) { n = n * 10 + (yyinput[i] - 48); }\n        return n;\n    }\n\n    public Optional<ArrayList<SemVer>> lex() throws IOException {\n        ArrayList<SemVer> vers = new ArrayList<SemVer>();\n\n        // Final tag variables available in semantic action.\n        /*!svars:re2c format = \"int @@;\"; */\n\n        loop: while (true) {\n            token = yycursor;\n            /*!re2c\n                re2c:YYCTYPE = \"byte\";\n                re2c:YYPEEK = \"yyinput[yycursor]\";\n                re2c:YYFILL = \"fill() == 0\";\n                re2c:eof = 0;\n                re2c:tags = 1;\n\n                num = [0-9]+;\n\n                @t1 num @t2 \".\" @t3 num @t4 (\".\" @t5 num)? [\\n] {\n                    int major = readInt(t1, t2);\n                    int minor = readInt(t3, t4);\n                    int patch = (t5 == -1) ? 0 : readInt(t5, yycursor - 1);\n                    vers.add(new SemVer(major, minor, patch));\n                    continue loop;\n                }\n                $ { return Optional.of(vers); }\n                * { return Optional.empty(); }\n            */\n        }\n    }\n\n    public static void main(String []args) throws FileNotFoundException, IOException {\n        String fname = \"input\";\n        String content = \"1.22.333\\n\".repeat(Lexer.BUFSIZE);\n\n        // Prepare input file: a few times the size of the buffer, containing\n        // strings with zeroes and escaped quotes.\n        Files.writeString(Paths.get(fname), content);\n\n        // Prepare lexer state: all offsets are at the end of buffer.\n        File file = new File(\".\", fname);\n        Lexer lexer = new Lexer(file);\n\n        // Run the lexer.\n        Optional<ArrayList<SemVer>> vers = lexer.lex();\n\n        // Check resuts.\n        assert vers.isPresent() && vers.get().size() == BUFSIZE;\n        SemVer v = new SemVer(1, 22, 333);\n        for (int i = 0; i < BUFSIZE; ++i) {\n            assert vers.get().get(i).equals(v);\n        }\n\n        // Cleanup: remove input file.\n        file.delete();\n    }\n};\n",
      "extraCommandLineArguments": ""
    },
    "eof/03_eof_rule.re": {
      "content": "// re2java $INPUT -o $OUTPUT\n\nclass Main {\n    // Expects a null-terminated string.\n    static int lex(String yyinput) {\n        int yycursor = 0;\n        int yymarker = 0;\n        int yylimit = yyinput.length() - 1; // yylimit points at the terminating null\n        int count = 0;\n\n        loop: while (true) {\n            /*!re2c\n                re2c:YYCTYPE = \"char\";\n                re2c:YYPEEK = \"yyinput.charAt(yycursor)\";\n                re2c:yyfill:enable = 0;\n                re2c:eof = 0;\n\n                str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n                *    { return -1; }\n                $    { return count; }\n                str  { count += 1; continue loop; }\n                [ ]+ { continue loop; }\n            */\n        }\n    }\n\n    public static void main(String []args) {\n        assert lex(\"\\0\") == 0;\n        assert lex(\"'qu\\0tes' 'are' 'fine: \\\\'' \\0\") == 3;\n        assert lex(\"'unterminated\\\\'\\0\") == -1;\n    }\n};\n",
      "extraCommandLineArguments": ""
    },
    "eof/04_fake_sentinel.re": {
      "content": "// re2java $INPUT -o $OUTPUT\n\nclass Main {\n    // Expects a string without terminating null.\n    static int lex(String str) {\n        byte[] yyinput = str.getBytes();\n        int yycursor = 0;\n        int count = 0;\n\n        loop: while (true) {\n            /*!re2c\n                re2c:api = generic;\n                re2c:YYCTYPE = \"byte\";\n                re2c:YYPEEK = \"(yycursor < yyinput.length) ? yyinput[yycursor] : 0\";\n                re2c:YYSKIP = \"yycursor += 1;\";\n                re2c:yyfill:enable = 0;\n\n                *      { return -1; }\n                [\\x00] { return count; }\n                [a-z]+ { count += 1; continue loop; }\n                [ ]+   { continue loop; }\n            */\n        }\n    }\n\n    public static void main(String []args) {\n        assert lex(\"\") == 0;\n        assert lex(\"one two three\") == 3;\n        assert lex(\"f0ur\") == -1;\n    }\n};\n",
      "extraCommandLineArguments": ""
    },
    "eof/02_bounds_checking.re": {
      "content": "// re2java $INPUT -o $OUTPUT\n\nclass Main {\n    /*!max:re2c*/\n\n    // Expects yymaxfill-padded string.\n    static int lex(String str) {\n        // Pad string with yymaxfill zeroes at the end.\n        byte[] yyinput = new byte[str.length() + YYMAXFILL];\n        System.arraycopy(str.getBytes(), 0, yyinput, 0, str.length()); \n\n        int yycursor = 0;\n        int yylimit = yyinput.length;\n        int count = 0;\n\n        loop: while (true) {\n            /*!re2c\n                re2c:YYCTYPE = \"byte\";\n                re2c:YYPEEK = \"yyinput[yycursor]\";\n                re2c:YYFILL = \"return -1;\";\n\n                str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n                [\\x00] {\n                    // Check that it is the sentinel, not some unexpected null.\n                    return (yycursor - 1 == str.length()) ? count : -1;\n                }\n                str  { count += 1; continue loop; }\n                [ ]+ { continue loop; }\n                *    { return -1; }\n            */\n        }\n    }\n\n    public static void main(String []args) {\n        assert lex(\"\") == 0;\n        assert lex(\"'qu\\0tes' 'are' 'fine: \\\\'' \") == 3;\n        assert lex(\"'unterminated\\\\'\") == -1;\n        assert lex(\"'unexpected \\00 null\\\\'\") == -1;\n    }\n};\n",
      "extraCommandLineArguments": ""
    },
    "eof/01_sentinel.re": {
      "content": "// re2java $INPUT -o $OUTPUT\n\nclass Main {\n    // Expects a null-terminated string.\n    static int lex(String yyinput) {\n        int yycursor = 0;\n        int count = 0;\n\n        loop: while (true) {\n            /*!re2c\n                re2c:YYCTYPE = \"char\";\n                re2c:YYPEEK = \"yyinput.charAt(yycursor)\";\n                re2c:yyfill:enable = 0;\n\n                *      { return -1; }\n                [\\x00] { return count; }\n                [a-z]+ { count += 1; continue loop; }\n                [ ]+   { continue loop; }\n            */\n        }\n    }\n\n    public static void main(String []args) {\n        assert lex(\"\\0\") == 0;\n        assert lex(\"one two three\\0\") == 3;\n        assert lex(\"f0ur\\0\") == -1;\n    }\n};\n",
      "extraCommandLineArguments": ""
    },
    "includes/include.re": {
      "content": "// re2java $INPUT -o $OUTPUT\n\n/*!include:re2c \"definitions.java\" */\n\nclass Main {\n    enum Num {INT, FLOAT, NAN};\n\n    static Num lex(String yyinput) {\n        int yycursor = 0;\n        int yymarker = 0;\n\n        /*!re2c\n            re2c:YYCTYPE = \"char\";\n            re2c:YYPEEK = \"yyinput.charAt(yycursor)\";\n            re2c:yyfill:enable = 0;\n\n            *      { return Num.NAN; }\n            number { return Num.INT; }\n            !include \"extra_rules.re.inc\";\n        */\n    }\n\n    public static void main(String []args) {\n        assert lex(\"123\\0\") == Num.INT;\n        assert lex(\"123.4567\\0\") == Num.FLOAT;\n    }\n};\n",
      "extraCommandLineArguments": ""
    },
    "encodings/unicode_identifier.re": {
      "content": "// re2java $INPUT -o $OUTPUT --utf8 -s\n\n/*!include:re2c \"unicode_categories.re\" */\n\nclass Main {\n    static boolean lex(String yyinput) {\n        int yycursor = 0;\n        int yymarker = 0;\n\n        /*!re2c\n            re2c:YYCTYPE = \"char\";\n            re2c:YYPEEK = \"yyinput.charAt(yycursor)\";\n            re2c:yyfill:enable = 0;\n\n            // Simplified \"Unicode Identifier and Pattern Syntax\"\n            // (see https://unicode.org/reports/tr31)\n            id_start    = L | Nl | [$_];\n            id_continue = id_start | Mn | Mc | Nd | Pc | [\\u200D\\u05F3];\n            identifier  = id_start+;\n            // It should be `id_start id_continue*`, but that causes `error: code too large`\n\n            identifier { return true; }\n            *          { return false; }\n        */\n    }\n\n    public static void main(String []args) {\n        assert lex(\"_\u042b\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\\0\");\n    }\n};\n",
      "extraCommandLineArguments": "--utf8 -s"
    },
    "reuse/reuse.re": {
      "content": "// re2java $INPUT -o $OUTPUT --input-encoding utf8\n\n// This example supports multiple input encodings: UTF-8 and UTF-32.\n// Both lexers are generated from the same rules block, and the use\n// blocks add only encoding-specific configurations.\n\n/*!rules:re2c\n    re2c:yyfill:enable = 0;\n    re2c:YYPEEK = \"yyinput[yycursor]\";\n    re2c:indent:top = 1;\n\n    \"\u2200x \u2203y\" { return true; }\n    *       { return false; }\n*/\n\nclass Main {\n    static boolean lex_utf8(int[] yyinput) {\n        int yycursor = 0;\n        int yymarker = 0;\n        /*!use:re2c\n            re2c:YYCTYPE = \"int\"; // should be `byte`, but it's signed in Java\n            re2c:encoding:utf8 = 1;\n        */\n    }\n\n    static boolean lex_utf32(int[] yyinput) {\n        int yycursor = 0;\n        int yymarker = 0;\n        /*!use:re2c\n            re2c:YYCTYPE = \"int\";\n            re2c:encoding:utf32 = 1;\n        */\n    }\n\n    public static void main(String []args) {\n        // we have to use `int`, because `byte`in Java cannot represent values greater than 127\n        int[] s_utf8 = new int[]{0xe2, 0x88, 0x80, 0x78, 0x20, 0xe2, 0x88, 0x83, 0x79};\n        assert lex_utf8(s_utf8);\n\n        int[] s_utf32 = new int[]{0x2200, 0x78, 0x20, 0x2203, 0x79};\n        assert lex_utf32(s_utf32);\n    }\n};\n",
      "extraCommandLineArguments": "--input-encoding utf8"
    },
    "reuse/usedir.re": {
      "content": "// re2java $INPUT -o $OUTPUT\n\n// This example shows how to combine reusable re2c blocks: two blocks\n// ('colors' and 'fish') are merged into one. The 'salmon' rule occurs\n// in both blocks; the 'fish' block takes priority because it is used\n// earlier. Default rule * occurs in all three blocks; the local (not\n// inherited) definition takes priority.\n\n/*!rules:re2c:colors\n    *                            { throw new IllegalArgumentException(\"ah\"); }\n    \"red\" | \"salmon\" | \"magenta\" { return Ans.COLOR; }\n*/\n\n/*!rules:re2c:fish\n    *                            { throw new IllegalArgumentException(\"oh\"); }\n    \"haddock\" | \"salmon\" | \"eel\" { return Ans.FISH; }\n*/\n\nclass Main {\n    enum Ans {COLOR, FISH, DUNNO};\n\n    static Ans lex(String yyinput) { // no-throw, as '*' rules are overridden\n        int yycursor = 0;\n        int yymarker = 0;\n\n        /*!re2c\n            re2c:yyfill:enable = 0;\n            re2c:YYCTYPE = \"char\";\n            re2c:YYPEEK = \"yyinput.charAt(yycursor)\";\n\n            !use:fish;\n            !use:colors;\n            * { return Ans.DUNNO; } // overrides inherited '*' rules\n        */\n    }\n\n    public static void main(String []args) {\n        assert lex(\"salmon\") == Ans.FISH;\n        assert lex(\"what?\") == Ans.DUNNO;\n    }\n};\n",
      "extraCommandLineArguments": ""
    },
    "headers/header.re": {
      "content": "// re2java $INPUT -o $OUTPUT --header lexer/state.java\n\npackage headers;\n\nimport headers.lexer.State;\n\n/*!header:re2c:on*/\npackage headers.lexer;\n\npublic class State {\n    public String yyinput;\n    public int yycursor;\n    /*!stags:re2c format = \"public int @@;\\n\"; */\n\n    public State(String str) {\n        yyinput = str;\n        yycursor = 0;\n        /*!stags:re2c format = \"@@ = 0;\\n\"; */\n    }\n};\n/*!header:re2c:off*/\n\nclass Main {\n    static int lex(String str) {\n        State yyrecord = new State(str);\n        int t;\n        /*!re2c\n            re2c:api = record;\n            re2c:tags = 1;\n            re2c:yyfill:enable = 0;\n            re2c:YYCTYPE = \"char\";\n            re2c:YYPEEK = \"yyrecord.yyinput.charAt(yyrecord.yycursor)\";\n            re2c:header = \"lexer/state.java\";\n\n            [a]* @t [b]* { return t; }\n        */\n    }\n\n    public static void main(String []args) {\n        assert lex(\"ab\\0\") == 1;\n    }\n};\n",
      "extraCommandLineArguments": "--header lexer/state.java"
    }
  },
  "python": {
    "01_basic.re": {
      "content": "# re2py $INPUT -o $OUTPUT\n\ndef lex(yyinput):\n    yycursor = 0\n%{\n    re2c:yyfill:enable = 0;\n    re2c:indent:top = 1;\n\n    [1-9][0-9]* { return True }\n    *           { return False }\n%}\n\nassert lex(b\"1234\\0\")\n",
      "extraCommandLineArguments": ""
    },
    "fill/01_fill.re": {
      "content": "# re2py $INPUT -o $OUTPUT\n\nfrom enum import Enum\nimport os\n\nBUFSIZE = 4096\n\nclass State:\n    def __init__(self, fname):\n        self.file = open(fname, \"rb\")\n        self.yyinput = bytearray(BUFSIZE)\n        self.yylimit = BUFSIZE - 1 # exclude terminating null\n        self.yycursor = self.yylimit\n        self.yymarker = self.yylimit\n        self.token = self.yylimit\n        self.eof = False\n\n    def __del__(self):\n        self.file.close()\n\nclass Status(Enum):\n    OK = 0\n    EOF = 1\n    LONG_LEXEME = 2\n\ndef fill(st):\n    if st.eof:\n        return Status.EOF\n\n    # Error: lexeme too long. In real life could reallocate a larger buffer.\n    if st.token < 1:\n        return Status.LONG_LEXEME\n\n    # Shift buffer contents (discard everything up to the current token).\n    st.yyinput = st.yyinput[st.token:st.yylimit]\n    st.yycursor -= st.token;\n    st.yymarker -= st.token;\n    st.yylimit -= st.token;\n    st.token = 0;\n\n    # Fill free space at the end of buffer with new data from file.\n    bytes = st.file.read(BUFSIZE - st.yylimit - 1) # -1 for sentinel\n    if not bytes:\n        st.eof = True # end of file\n    else:\n        st.yylimit += len(bytes);\n        st.yyinput += bytes\n\n    st.yyinput += b'\\0' # append sentinel\n\n    return Status.OK\n\ndef lex(yyrecord, count):\n    while True:\n        yyrecord.token = yyrecord.yycursor\n    %{\n        re2c:api = record;\n        re2c:define:YYFILL = \"fill(yyrecord) == Status.OK\";\n        re2c:eof = 0;\n        re2c:indent:top = 2;\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        *    { return -1 }\n        $    { return count }\n        [ ]+ { break }\n        str  {\n            count += 1\n            break\n        }\n    %}\n\ndef main():\n    fname = \"input\"\n\n    # Prepare input file.\n    f = open(fname, \"w\")\n    for i in range(BUFSIZE):\n        f.write(\"'qu\\0tes' 'are' 'fine: \\\\'' \")\n    f.close()\n\n    # Run lexer on the prepared file.\n    st = State(fname)\n    assert lex(st, 0) == 3 * BUFSIZE\n\n    # Cleanup.\n    os.remove(fname)\n\nif __name__ == '__main__':\n    main()\n",
      "extraCommandLineArguments": ""
    },
    "fill/02_fill.re": {
      "content": "# re2py $INPUT -o $OUTPUT\n\nfrom enum import Enum\nimport os\n\nBUFSIZE = 4096\n%{max %}\n\nclass State:\n    def __init__(self, fname):\n        self.file = open(fname, \"rb\")\n        self.yyinput = bytearray(BUFSIZE)\n        self.yylimit = BUFSIZE - YYMAXFILL\n        self.yycursor = self.yylimit\n        self.yymarker = self.yylimit\n        self.token = self.yylimit\n        self.eof = False\n\n    def __del__(self):\n        self.file.close()\n\nclass Status(Enum):\n    OK = 0\n    EOF = 1\n    LONG_LEXEME = 2\n\ndef fill(st, need):\n    if st.eof:\n        return Status.EOF\n\n    # Error: lexeme too long. In real life could reallocate a larger buffer.\n    if st.token < need:\n        return Status.LONG_LEXEME\n\n    # Shift buffer contents (discard everything up to the current token).\n    st.yyinput = st.yyinput[st.token:st.yylimit]\n    st.yycursor -= st.token;\n    st.yymarker -= st.token;\n    st.yylimit -= st.token;\n    st.token = 0;\n\n    # Fill free space at the end of buffer with new data from file.\n    bytes = st.file.read(BUFSIZE - st.yylimit - 1) # -1 for sentinel\n    if not bytes:\n        st.eof = True # end of file\n        st.yylimit += YYMAXFILL\n        st.yyinput += b\"\\0\" * YYMAXFILL\n    else:\n        st.yylimit += len(bytes);\n        st.yyinput += bytes\n\n    return Status.OK\n\ndef lex(yyrecord):\n    count = 0\n    while True:\n        yyrecord.token = yyrecord.yycursor\n    %{\n        re2c:api = record;\n        re2c:YYFILL = \"if fill(yyrecord, @@) != Status.OK: return -1\";\n        re2c:indent:top = 2;\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        [\\x00] {\n            # Check that it is the sentinel, not some unexpected null.\n            return count if yyrecord.token == yyrecord.yylimit - YYMAXFILL else -1\n        }\n        str {\n            count += 1\n            break\n        }\n        [ ]+ { break }\n        *    { return -1 }\n    %}\n\ndef main():\n    fname = \"input\"\n\n    # Prepare input file.\n    f = open(fname, \"w\")\n    for i in range(BUFSIZE):\n        f.write(\"'qu\\0tes' 'are' 'fine: \\\\'' \")\n    f.close()\n\n    # Run lexer on the prepared file.\n    st = State(fname)\n    assert lex(st) == 3 * BUFSIZE\n\n    # Cleanup.\n    os.remove(fname)\n\nif __name__ == '__main__':\n    main()\n",
      "extraCommandLineArguments": ""
    },
    "conditions/parse_u32_conditions.re": {
      "content": "# re2py $INPUT -o $OUTPUT -c\n\n%{conditions %}\n\ndef parse_u32(yyinput):\n    yycursor = 0\n    yycond = YYC_INIT\n    num = 0\n\n    while True: %{\n        re2c:yyfill:enable = 0;\n        re2c:indent:top = 2;\n\n        <INIT> '0b' / [01]        :=> BIN\n        <INIT> \"0\"                :=> OCT\n        <INIT> \"\" / [1-9]         :=> DEC\n        <INIT> '0x' / [0-9a-fA-F] :=> HEX\n        <INIT> * { return None }\n\n        <BIN> [01] {\n            num = num * 2 + (yyinput[yycursor - 1] - 48)\n            break\n        }\n        <OCT> [0-7] {\n            num = num * 8 + (yyinput[yycursor - 1] - 48)\n            break\n        }\n        <DEC> [0-9] {\n            num = num * 10 + (yyinput[yycursor - 1] - 48)\n            break\n        }\n        <HEX> [0-9] {\n            num = num * 16 + (yyinput[yycursor - 1] - 48)\n            break\n        }\n        <HEX> [a-f] {\n            num = num * 16 + (yyinput[yycursor - 1] - 87)\n            break\n        }\n        <HEX> [A-F] {\n            num = num * 16 + (yyinput[yycursor - 1] - 55)\n            break\n        }\n\n        <BIN, OCT, DEC, HEX> * { return num }\n    %}\n\nassert parse_u32(b\"\\0\") == None\nassert parse_u32(b\"1234567890\\0\") == 1234567890\nassert parse_u32(b\"0b1101\\0\") == 13\nassert parse_u32(b\"0x7Fe\\0\") == 2046\nassert parse_u32(b\"0644\\0\") == 420\nassert parse_u32(b\"9999999999\\0\") == 9999999999\n",
      "extraCommandLineArguments": "-c"
    },
    "conditions/parse_u32_blocks.re": {
      "content": "# re2py $INPUT -o $OUTPUT\n\nclass State:\n    def __init__(self, str):\n        self.yyinput = str\n        self.yycursor = 0\n        self.yymarker = 0\n\n# Common re2c definitions shared between all functions.\n%{\n    re2c:api = record;\n    re2c:yyrecord = st;\n    re2c:yyfill:enable = 0;\n    re2c:indent:top = 2;\n%}\n\ndef parse_u32(str):\n    st = State(str)\n%{local\n    re2c:indent:top = 1;\n\n    '0b' / [01]        { return parse_bin(st) }\n    \"0\"                { return parse_oct(st) }\n    \"\" / [1-9]         { return parse_dec(st) }\n    '0x' / [0-9a-fA-F] { return parse_hex(st) }\n    *                  { return None }\n%}\n\ndef parse_bin(st):\n    n = 0\n    while True: %{\n        [01] {\n            n = n * 2 + (st.yyinput[st.yycursor - 1] - 48)\n            break\n        }\n        * { return n }\n    %}\n\ndef parse_oct(st):\n    n = 0\n    while True: %{\n        [0-7] {\n            n = n * 8 + (st.yyinput[st.yycursor - 1] - 48)\n            break\n        }\n        * { return n }\n    %}\n\ndef parse_dec(st):\n    n = 0\n    while True: %{\n        [0-9] {\n            n = n * 10 + (st.yyinput[st.yycursor - 1] - 48)\n            break\n        }\n        * { return n }\n    %}\n\ndef parse_hex(st):\n    n = 0\n    while True: %{\n        [0-9] {\n            n = n * 16 + (st.yyinput[st.yycursor - 1] - 48)\n            break\n        }\n        [a-f] {\n            n = n * 16 + (st.yyinput[st.yycursor - 1] - 87)\n            break\n        }\n        [A-F] {\n            n = n * 16 + (st.yyinput[st.yycursor - 1] - 55)\n            break\n        }\n        * { return n }\n    %}\n\nassert parse_u32(b\"\\0\") == None\nassert parse_u32(b\"1234567890\\0\") == 1234567890\nassert parse_u32(b\"0b1101\\0\") == 13\nassert parse_u32(b\"0x7Fe\\0\") == 2046\nassert parse_u32(b\"0644\\0\") == 420\nassert parse_u32(b\"9999999999\\0\") == 9999999999\n",
      "extraCommandLineArguments": ""
    },
    "state/push.re": {
      "content": "# re2py $INPUT -o $OUTPUT -f\n\nfrom enum import Enum\nimport os\n\n# Use a small buffer to cover the case when a lexeme doesn't fit.\n# In real world use a larger buffer.\nBUFSIZE = 10\nDEBUG = False\n\nclass State:\n    def __init__(self, file):\n        self.file = file\n        self.yyinput = bytearray(BUFSIZE)\n        self.yylimit = BUFSIZE - 1 # exclude terminating null\n        self.yycursor = self.yylimit\n        self.yymarker = self.yylimit\n        self.token = self.yylimit\n        self.yystate = -1\n\nclass Status(Enum):\n    END = 0\n    READY = 1\n    WAITING = 2\n    BIG_PACKET = 3\n    BAD_PACKET = 4\n\ndef fill(st):\n    # Error: lexeme too long. In real life could reallocate a larger buffer.\n    if st.token < 1:\n        return Status.BIG_PACKET\n\n    # Shift buffer contents (discard everything up to the current token).\n    st.yyinput = st.yyinput[st.token:st.yylimit]\n    st.yycursor -= st.token;\n    st.yymarker -= st.token;\n    st.yylimit -= st.token;\n    st.token = 0;\n\n    # Fill free space at the end of buffer with new data from file.\n    bytes = st.file.read(BUFSIZE - st.yylimit - 1) # -1 for sentinel\n    if bytes:\n        st.yylimit += len(bytes);\n        st.yyinput += bytes\n\n    st.yyinput += b'\\0' # append sentinel\n\n    return Status.READY\n\ndef lex(yyrecord, recv):\n    while True:\n        yyrecord.token = yyrecord.yycursor\n    %{\n        re2c:api = record;\n        re2c:YYFILL = \"return Status.WAITING, recv\";\n        re2c:eof = 0;\n        re2c:indent:top = 2;\n\n        packet = [a-z]+[;];\n\n        *      { return Status.BAD_PACKET, recv }\n        $      { return Status.END, recv }\n        packet {\n            recv += 1\n            break\n        }\n    %}\n\ndef test(packets, expect):\n    # Create a pipe (open the same file for reading and writing).\n    fname = \"pipe\"\n    fw = open(fname, \"wb\")\n    fr = open(fname, \"rb\")\n\n    # Initialize lexer state\n    st = State(fr)\n\n    # Main loop. The buffer contains incomplete data which appears packet by\n    # packet. When the lexer needs more input it saves its internal state and\n    # returns to the caller which should provide more input and resume lexing.\n    send = 0\n    recv = 0\n    while True:\n        status, recv = lex(st, recv)\n\n        if status == Status.END:\n            if DEBUG: print(\"done: got {} packets\".format(recv))\n            break\n\n        elif status == Status.WAITING:\n            if DEBUG: print(\"waiting...\");\n\n            if send < len(packets):\n                if DEBUG: print(\"sent packet {}: {}\".format(send, packets[send]))\n                fw.write(packets[send])\n                fw.flush()\n                send += 1\n\n            status = fill(st)\n            if DEBUG: print(\"queue: '{}', status: {}\".format(st.yyinput, status))\n            if status == Status.BIG_PACKET:\n                if DEBUG: print(\"error: packet too big\")\n                break\n\n            assert status == Status.READY\n\n        else:\n            assert status == Status.BAD_PACKET\n            if DEBUG: print(\"error: ill-formed packet\")\n            break\n\n    # Check results.\n    assert status == expect\n    if status == Status.END:\n        assert recv == send\n\n    # Cleanup: remove input file.\n    fr.close()\n    fw.close()\n    os.remove(fname)\n\ndef main():\n    test([], Status.END)\n    test([b\"zero;\", b\"one;\", b\"two;\", b\"three;\", b\"four;\"], Status.END)\n    test([b\"zer0;\"], Status.BAD_PACKET)\n    test([b\"goooooooooogle;\"], Status.BIG_PACKET)\n\nif __name__ == '__main__':\n    main()\n",
      "extraCommandLineArguments": "-f"
    },
    "submatch/02_mtags.re": {
      "content": "# re2py $INPUT -o $OUTPUT\n\nNONE = -1\n\ndef parse(yyinput):\n    yycursor = 0\n    %{mtags format = '\\n    @@ = []'; %} # autogenerated tag variables\n\n%{\n    re2c:YYMTAGP = \"@@.append(yycursor)\";\n    re2c:YYMTAGN = \"\"; // do nothing\n    re2c:yyfill:enable = 0;\n    re2c:tags = 1;\n    re2c:indent:top = 1;\n\n    num = [0-9]+;\n\n    @t1 num @t2 (\".\" #t3 num #t4)* [\\x00] {\n        vers = [int(yyinput[t1:t2])]\n        for i in range(len(t3)):\n            vers.append(int(yyinput[t3[i]:t4[i]]))\n        return vers\n    }\n    * { return None }\n%}\n\nassert parse(b\"1\\0\") == [1]\nassert parse(b\"1.2.3.4.5.6.7\\0\") == [1, 2, 3, 4, 5, 6, 7]\nassert parse(b\"1.2.\\0\") == None\n",
      "extraCommandLineArguments": ""
    },
    "submatch/04_posix_captures.re": {
      "content": "# re2py $INPUT -o $OUTPUT\n\nfrom collections import namedtuple\n\nSemVer = namedtuple('SemVer', 'major minor patch')\n\n# Maximum number of capturing groups among all rules.\n%{maxnmatch %}\nNONE = -1\n\ndef parse(yyinput):\n    yycursor = 0\n\n    # A list for capturing parentheses (twice the number of groups).\n    yypmatch = [None] * (YYMAXNMATCH * 2)\n\n%{\n    re2c:yyfill:enable = 0;\n    re2c:posix-captures = 1;\n    re2c:indent:top = 1;\n\n    num = [0-9]+;\n\n    (num) \".\" (num) (\".\" num)? [\\x00] {\n        # `yynmatch` is the number of capturing groups\n        assert yynmatch == 4\n\n        # Even `yypmatch` values are for opening parentheses, odd values\n        # are for closing parentheses, the first group is the whole match.\n        major = int(yyinput[yypmatch[2]:yypmatch[3]])\n        minor = int(yyinput[yypmatch[4]:yypmatch[5]])\n        patch = 0 if yypmatch[6] == NONE else int(yyinput[yypmatch[6] + 1:yypmatch[7]])\n        return SemVer(major, minor, patch)\n    }\n    * { return None }\n%}\n\nassert parse(b\"23.34\\0\") == SemVer(23, 34, 0)\nassert parse(b\"1.2.99999\\0\") == SemVer(1, 2, 99999)\nassert parse(b\"1.a\\0\") == None\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags.re": {
      "content": "# re2py $INPUT -o $OUTPUT\n\nfrom collections import namedtuple\n\nSemVer = namedtuple('SemVer', 'major minor patch')\n\nNONE = -1\n\ndef parse(yyinput):\n    yycursor = 0\n%{\n    re2c:yyfill:enable = 0;\n    re2c:tags = 1;\n    re2c:indent:top = 1;\n\n    num = [0-9]+;\n\n    @t1 num @t2 \".\" @t3 num @t4 (\".\" @t5 num)? [\\x00] {\n        major = int(yyinput[t1:t2])\n        minor = int(yyinput[t3:t4])\n        patch = int(yyinput[t5:yycursor - 1]) if t5 != NONE else 0\n        return SemVer(major, minor, patch)\n    }\n    * { return None }\n%}\n\nassert parse(b\"23.34\\0\") == SemVer(23, 34, 0)\nassert parse(b\"1.2.99999\\0\") == SemVer(1, 2, 99999)\nassert parse(b\"1.a\\0\") == None\n",
      "extraCommandLineArguments": ""
    },
    "submatch/03_captures.re": {
      "content": "# re2py $INPUT -o $OUTPUT\n\nfrom collections import namedtuple\n\nSemVer = namedtuple('SemVer', 'major minor patch')\n\nNONE = -1\n\ndef parse(yyinput):\n    yycursor = 0\n%{\n    re2c:yyfill:enable = 0;\n    re2c:captvars = 1;\n    re2c:indent:top = 1;\n\n    num = [0-9]+;\n\n    (num) \".\" (num) (\".\" num)? [\\x00] {\n        major = int(yyinput[yytl1:yytr1])\n        minor = int(yyinput[yytl2:yytr2])\n        patch = 0 if yytl3 == NONE else int(yyinput[yytl3 + 1:yytr3])\n        return SemVer(major, minor, patch)\n    }\n    * { return None }\n%}\n\nassert parse(b\"23.34\\0\") == SemVer(23, 34, 0)\nassert parse(b\"1.2.99999\\0\") == SemVer(1, 2, 99999)\nassert parse(b\"1.a\\0\") == None\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags_fill.re": {
      "content": "# re2py $INPUT -o $OUTPUT\n\nfrom collections import namedtuple\nfrom enum import Enum\nimport os\n\nBUFSIZE = 4096\n\nSemVer = namedtuple('SemVer', 'major minor patch')\n\nclass State:\n    def __init__(self, fname):\n        self.file = open(fname, \"rb\")\n        self.yyinput = bytearray(BUFSIZE)\n        self.yylimit = BUFSIZE - 1 # exclude terminating null\n        self.yycursor = self.yylimit\n        self.yymarker = self.yylimit\n        self.token = self.yylimit\n        self.eof = False\n        %{stags format = \"\\n        self.@@ = -1\"; %}\n\n    def __del__(self):\n        self.file.close()\n\nclass Status(Enum):\n    OK = 0\n    EOF = 1\n    LONG_LEXEME = 2\n\ndef fill(st):\n    if st.eof:\n        return Status.EOF\n\n    # Error: lexeme too long. In real life could reallocate a larger buffer.\n    if st.token < 1:\n        return Status.LONG_LEXEME\n\n    # Shift buffer contents (discard everything up to the current token).\n    st.yyinput = st.yyinput[st.token:st.yylimit]\n    st.yycursor -= st.token;\n    st.yymarker -= st.token;\n    st.yylimit -= st.token;\n    %{stags format = \"\\n    if st.@@ != -1: st.@@ -= st.token\"; %}\n    st.token = 0;\n\n    # Fill free space at the end of buffer with new data from file.\n    bytes = st.file.read(BUFSIZE - st.yylimit - 1) # -1 for sentinel\n    if not bytes:\n        st.eof = True # end of file\n    else:\n        st.yylimit += len(bytes);\n        st.yyinput += bytes\n\n    st.yyinput += b'\\0' # append sentinel\n\n    return Status.OK\n\ndef lex(st, count):\n    vers = []\n    while True:\n        st.token = st.yycursor\n    %{\n        re2c:api = record;\n        re2c:yyrecord = st;\n        re2c:YYFILL = \"fill(st) == Status.OK\";\n        re2c:eof = 0;\n        re2c:indent:top = 2;\n        re2c:tags = 1;\n\n        num = [0-9]+;\n\n        num @t1 \".\" @t2 num @t3 (\".\" @t4 num)? [\\n] {\n            major = int(st.yyinput[st.token:t1])\n            minor = int(st.yyinput[t2:t3])\n            patch = int(st.yyinput[t4:st.yycursor - 1]) if t4 != -1 else 0\n            vers.append(SemVer(major, minor, patch))\n            break\n        }\n        $ { return vers }\n        * { return None }\n    %}\n\ndef main():\n    fname = \"input\"\n    verstr = b\"1.22.333\\n\"\n    expect = [SemVer(1, 22, 333)] * BUFSIZE\n\n    # Prepare input file.\n    f = open(fname, \"wb\")\n    for i in range(BUFSIZE):\n        f.write(verstr)\n    f.close()\n\n    # Run lexer on the prepared file.\n    st = State(fname)\n    assert lex(st, 0) == expect\n\n    # Cleanup.\n    os.remove(fname)\n\nif __name__ == '__main__':\n    main()\n",
      "extraCommandLineArguments": ""
    },
    "eof/03_eof_rule.re": {
      "content": "# re2py $INPUT -o $OUTPUT\n\n# expect a null-terminated string\ndef lex(yyinput):\n    yycursor = 0\n    yylimit = len(yyinput) - 1 # terminating null not included\n    count = 0\n\n    while True: %{\n        re2c:yyfill:enable = 0;\n        re2c:eof = 0;\n        re2c:indent:top = 2;\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        *    { return -1 }\n        $    { return count }\n        [ ]+ { break }\n        str  {\n            count += 1\n            break\n        }\n    %}\n\ndef test(str, count):\n    # termunating null not included in `lim`\n    assert count == lex(str)\n\ntest(b\"\\0\", 0);\ntest(b\"'qu\\0tes' 'are' 'fine: \\\\'' \\0\", 3);\ntest(b\"'unterminated\\\\'\\0\", -1)\n",
      "extraCommandLineArguments": ""
    },
    "eof/04_fake_sentinel.re": {
      "content": "# re2py $INPUT -o $OUTPUT\n\n# expect a string without terminating null\ndef lex(str):\n    cur = 0\n    lim = len(str)\n    count = 0\n\n    while True: %{\n        re2c:api = generic;\n        re2c:YYPEEK = \"str[cur] if cur < lim else 0\";\n        re2c:YYSKIP = \"cur += 1\";\n        re2c:yyfill:enable = 0;\n        re2c:indent:top = 2;\n\n        *      { return -1 }\n        [\\x00] { return count }\n        [ ]+   { break }\n        [a-z]+ {\n            count += 1\n            break\n        }\n    %}\n\nassert lex(b\"\") == 0\nassert lex(b\"one two three\") == 3\nassert lex(b\"f0ur\") == -1\n",
      "extraCommandLineArguments": ""
    },
    "eof/02_bounds_checking.re": {
      "content": "# re2py $INPUT -o $OUTPUT\n\n%{max %}\n\ndef lex(yyinput):\n    yycursor = 0\n    yylimit = len(yyinput)\n    count = 0\n\n    while True: %{\n        re2c:YYFILL = \"return -1\";\n        re2c:indent:top = 2;\n\n        str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n        [\\x00] {\n            # check that it is the sentinel, not some unexpected null\n            return count if yycursor == yylimit - YYMAXFILL + 1 else -1\n        }\n        str {\n            count += 1\n            break\n        }\n        [ ]+ { break }\n        *    { return -1 }\n    %}\n\ndef test(str, count):\n    padded_str = str + (b\"\\0\" * YYMAXFILL)\n    assert lex(padded_str) == count\n\ntest(b\"\", 0)\ntest(b\"'unterminated\\\\'\", -1)\ntest(b\"'qu\\x00tes' 'are' 'fine: \\\\'' \", 3)\ntest(b\"'unexpected \\x00 null\", -1)\n",
      "extraCommandLineArguments": ""
    },
    "eof/01_sentinel.re": {
      "content": "# re2py $INPUT -o $OUTPUT\n\n# expect a null-terminated string\ndef lex(yyinput):\n    yycursor = 0\n    count = 0\n\n    while True: %{\n        re2c:yyfill:enable = 0;\n        re2c:indent:top = 2;\n\n        *      { return -1 }\n        [\\x00] { return count }\n        [ ]+   { break }\n        [a-z]+ {\n            count += 1\n            break\n        }\n    %}\n\nassert lex(b\"\\0\") == 0\nassert lex(b\"one two three\\0\") == 3\nassert lex(b\"f0ur\\0\") == -1\n",
      "extraCommandLineArguments": ""
    },
    "includes/include.re": {
      "content": "# re2py $INPUT -o $OUTPUT\n\n%{include \"definitions.py\" %}\n\ndef lex(yyinput):\n    yycursor = 0\n%{\n    re2c:yyfill:enable = 0;\n    re2c:indent:top = 1;\n\n    *      { return Num.NAN }\n    number { return Num.INT }\n    !include \"extra_rules.re.inc\";\n%}\n\nassert lex(b\"123\\0\") == Num.INT\nassert lex(b\"123.4567\\0\") == Num.FLOAT\n",
      "extraCommandLineArguments": ""
    },
    "encodings/unicode_identifier.re": {
      "content": "# re2py $INPUT -o $OUTPUT --utf8\n\n%{include \"unicode_categories.re\" %}\n\ndef lex(yyinput):\n    yycursor = 0\n%{\n    re2c:yyfill:enable = 0;\n    re2c:indent:top = 1;\n\n    // Simplified \"Unicode Identifier and Pattern Syntax\"\n    // (see https://unicode.org/reports/tr31)\n    id_start    = L | Nl | [$_];\n    id_continue = id_start | Mn | Mc | Nd | Pc | [\\u200D\\u05F3];\n    identifier  = id_start id_continue*;\n\n    identifier { return True }\n    *          { return False }\n%}\n\nassert lex(bytes(\"_\u042b\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\\0\", \"utf-8\"))\n",
      "extraCommandLineArguments": "--utf8"
    },
    "reuse/reuse.re": {
      "content": "# re2py $INPUT -o $OUTPUT --input-encoding utf8\n\n# This example supports multiple input encodings: UTF-8 and UTF-32.\n# Both lexers are generated from the same rules block, and the use\n# blocks add only encoding-specific configurations.\n%{rules\n    re2c:yyfill:enable = 0;\n    re2c:indent:top = 1;\n\n    \"\u2200x \u2203y\" { return yycursor }\n    *       { return None }\n%}\n\ndef lex_utf8(yyinput):\n    yycursor = 0\n    %{use\n        re2c:encoding:utf8 = 1;\n    %}\n\ndef lex_utf32(yyinput):\n    yycursor = 0\n    %{use\n        re2c:encoding:utf32 = 1;\n    %}\n\ns8 = [0xe2, 0x88, 0x80, 0x78, 0x20, 0xe2, 0x88, 0x83, 0x79]\nassert lex_utf8(s8) == len(s8)\n\ns32 = [0x2200, 0x78, 0x20, 0x2203, 0x79]\nassert lex_utf32(s32) == len(s32)\n",
      "extraCommandLineArguments": "--input-encoding utf8"
    },
    "reuse/usedir.re": {
      "content": "# re2py $INPUT -o $OUTPUT\n\n# This example shows how to combine reusable re2c blocks: two blocks\n# ('colors' and 'fish') are merged into one. The 'salmon' rule occurs\n# in both blocks; the 'fish' block takes priority because it is used\n# earlier. Default rule * occurs in all three blocks; the local (not\n# inherited) definition takes priority.\n\nfrom enum import Enum\n\nclass Ans(Enum):\n    COLOR = 1\n    FISH = 2\n    DUNNO = 3\n\n%{rules:colors\n    *                            { raise \"ah\" }\n    \"red\" | \"salmon\" | \"magenta\" { return Ans.COLOR }\n%}\n\n%{rules:fish\n    *                            { raise \"oh\" }\n    \"haddock\" | \"salmon\" | \"eel\" { return Ans.FISH }\n%}\n\ndef lex(yyinput):\n    yycursor = 0\n%{\n    re2c:yyfill:enable = 0;\n    re2c:indent:top = 1;\n\n    !use:fish;\n    !use:colors;\n    * { return Ans.DUNNO } // overrides inherited '*' rules\n%}\n\nassert lex(b\"salmon\") == Ans.FISH\nassert lex(b\"what?\") == Ans.DUNNO\n",
      "extraCommandLineArguments": ""
    },
    "headers/header.re": {
      "content": "# re2py $INPUT -o $OUTPUT --header lexer/state.py\n\nfrom lexer.state import State\n\n%{header:on %}\nclass State:\n    def __init__(self, str):\n        self.yyinput = str\n        self.yycursor = 0\n        %{stags format = \"\\n        self.@@ = 0\"; %}\n%{header:off %}\n\ndef lex(yyrecord):\n%{\n    re2c:api = record;\n    re2c:tags = 1;\n    re2c:yyfill:enable = 0;\n    re2c:indent:top = 1;\n    re2c:header = \"lexer/state.py\";\n\n    [a]* @t [b]* { return t }\n%}\n\nassert lex(State(b\"ab\\0\")) == 1\n",
      "extraCommandLineArguments": "--header lexer/state.py"
    }
  },
  "zig": {
    "01_basic.re": {
      "content": "// re2zig $INPUT -o $OUTPUT\n\nconst std = @import(\"std\");\n\nfn lex(yyinput: [:0]const u8) bool {\n    var yycursor: u32 = 0;\n    %{\n        re2c:yyfill:enable = 0;\n\n        [1-9][0-9]* { return true; }\n        *           { return false; }\n    %}\n}\n\ntest {\n    try std.testing.expect(lex(\"1234\"));\n}\n",
      "extraCommandLineArguments": ""
    },
    "fill/01_fill.re": {
      "content": "// re2zig $INPUT -o $OUTPUT\n\nconst std = @import(\"std\");\n\nconst bufsize = 4095;\n\nconst State = struct {\n    yyinput: [bufsize + 1]u8,\n    yycursor: usize,\n    yymarker: usize,\n    yylimit: usize,\n    token: usize,\n    eof: bool\n};\n\nfn fill(st: *State, file: anytype) i32 {\n    if (st.eof) { return -1; } // unexpected EOF\n\n    // Error: lexeme too long. In real life can reallocate a larger buffer.\n    if (st.token < 1) { return -2; }\n\n    // Shift buffer contents (discard everything up to the current token).\n    std.mem.copyBackwards(\n        u8, st.yyinput[0..st.yylimit - st.token], st.yyinput[st.token..st.yylimit]);\n    st.yycursor -= st.token;\n    st.yymarker = @subWithOverflow(st.yymarker, st.token)[0];\n    st.yylimit -= st.token;\n    st.token = 0;\n\n    // Fill free space at the end of buffer with new data from file.\n    st.yylimit += file.read(st.yyinput[st.yylimit..bufsize]) catch 0;\n    st.yyinput[st.yylimit] = 0; // append sentinel symbol\n\n    // If read less than expected, this is the end of input.\n    st.eof = st.yylimit < bufsize;\n\n    return 0;\n}\n\nfn lex(yyrecord: *State, file: anytype) i32 {\n    var count: i32 = 0;\n    loop: while (true) {\n        yyrecord.token = yyrecord.yycursor;\n        %{\n            re2c:api = record;\n            re2c:eof = 0;\n            re2c:YYFILL = \"fill(yyrecord, file) == 0\";\n\n            str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n            *    { return -1; }\n            $    { return count; }\n            str  { count += 1; continue :loop; }\n            [ ]+ { continue :loop; }\n        %}\n    }\n}\n\ntest {\n    const fname = \"input\";\n    const content = \"'qu\\x00tes' 'are' 'fine: \\\\'' \" ** bufsize;\n    const count = 3 * bufsize; // number of quoted strings written to file\n\n    // Prepare input file: a few times the size of the buffer, containing\n    // strings with zeroes and escaped quotes.\n    var fw = try std.fs.cwd().createFile(fname, .{});\n    try fw.writeAll(content);\n    fw.close();\n\n    // Prepare lexer state: all offsets are at the end of buffer.\n    var fr = try std.fs.cwd().openFile(fname, .{ .mode = .read_only});\n    // Normally file would be part of the state struct, but BufferedReader type is unclear.\n    var br = std.io.bufferedReader(fr.reader());\n    var st = State{\n        .yyinput = undefined,\n        .yycursor = bufsize,\n        .yymarker = bufsize,\n        .yylimit = bufsize,\n        .token = bufsize,\n        .eof = false,\n    };\n    // Sentinel at `yylimit` offset is set to zero, which triggers YYFILL.\n    st.yyinput[st.yylimit] = 0;\n\n    // Run the lexer.\n    try std.testing.expectEqual(lex(&st, &br), count);\n\n    // Cleanup: remove input file.\n    fr.close();\n    try std.fs.cwd().deleteFile(fname);\n}\n",
      "extraCommandLineArguments": ""
    },
    "fill/02_fill.re": {
      "content": "// re2zig $INPUT -o $OUTPUT\n\nconst std = @import(\"std\");\n\n%{max %}\nconst bufsize = 4096;\n\nconst State = struct {\n    yyinput: [bufsize + yymaxfill]u8,\n    yycursor: usize,\n    yymarker: usize,\n    yylimit: usize,\n    token: usize,\n    eof: bool\n};\n\nfn fill(st: *State, need: usize, file: anytype) i32 {\n    if (st.eof) { return -1; } // unexpected EOF\n\n    // Error: lexeme too long. In real life can reallocate a larger buffer.\n    if (st.token < need) { return -2; }\n\n    // Shift buffer contents (discard everything up to the current token).\n    std.mem.copyBackwards(\n        u8, st.yyinput[0..st.yylimit - st.token], st.yyinput[st.token..st.yylimit]);\n    st.yycursor -= st.token;\n    st.yymarker = @subWithOverflow(st.yymarker, st.token)[0];\n    st.yylimit -= st.token;\n    st.token = 0;\n\n    // Fill free space at the end of buffer with new data from file.\n    st.yylimit += file.read(st.yyinput[st.yylimit..bufsize]) catch 0;\n\n    // If read less than expected, this is the end of input.\n    if (st.yylimit < bufsize) {\n        st.eof = true;\n        @memset(st.yyinput[st.yylimit..st.yylimit + yymaxfill], 0);\n        st.yylimit += yymaxfill;\n    }\n\n    return 0;\n}\n\nfn lex(yyrecord: *State, file: anytype) i32 {\n    var count: i32 = 0;\n    loop: while (true) {\n        yyrecord.token = yyrecord.yycursor;\n        %{\n            re2c:api = record;\n            re2c:YYFILL = \"{ if (fill(yyrecord, @@, file) != 0) return -2; }\";\n\n            str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n            [\\x00] {\n                // Check that it is the sentinel, not some unexpected null.\n                return if (yyrecord.token == yyrecord.yylimit - yymaxfill) count else -1;\n            }\n            str  { count += 1; continue :loop; }\n            [ ]+ { continue :loop; }\n            *    { return -1; }\n        %}\n    }\n}\n\ntest {\n    const fname = \"input\";\n    const content = \"'qu\\x00tes' 'are' 'fine: \\\\'' \" ** bufsize;\n    const count = 3 * bufsize; // number of quoted strings written to file\n\n    // Prepare input file: a few times the size of the buffer, containing\n    // strings with zeroes and escaped quotes.\n    var fw = try std.fs.cwd().createFile(fname, .{});\n    try fw.writeAll(content);\n    fw.close();\n\n    // Prepare lexer state: all offsets are at the end of buffer.\n    // This immediately triggers YYFILL, as the YYLESSTHAN condition is true.\n    var fr = try std.fs.cwd().openFile(fname, .{ .mode = .read_only});\n    // Normally file would be part of the state struct, but BufferedReader type is unclear.\n    var br = std.io.bufferedReader(fr.reader());\n    var st = State{\n        .yyinput = undefined,\n        .yycursor = bufsize,\n        .yymarker = bufsize,\n        .yylimit = bufsize,\n        .token = bufsize,\n        .eof = false,\n    };\n    @memset(st.yyinput[st.yylimit..st.yylimit + yymaxfill], 0); // zero-padding at the end\n\n    // Run the lexer.\n    try std.testing.expectEqual(lex(&st, &br), count);\n\n    // Cleanup: remove input file.\n    fr.close();\n    try std.fs.cwd().deleteFile(fname);\n}\n",
      "extraCommandLineArguments": ""
    },
    "conditions/parse_u32_conditions.re": {
      "content": "// re2zig $INPUT -o $OUTPUT -c\n\nconst std = @import(\"std\");\n\n%{conditions %}\n\nconst ERROR: u64 = @as(u64, std.math.maxInt(u32)) + 1; // overflow\n\n// Add digit with the given base, checking for overflow.\nfn add(num: *u64, str: [:0]const u8, cur: usize, offs: u8, base: u64) void {\n    num.* = @min(num.* * base + (str[cur - 1] - offs), ERROR);\n}\n\nfn parse_u32(yyinput: [:0]const u8) ?u32 {\n    var yycursor: usize = 0;\n    var yymarker: usize = 0;\n    var yycond = yycinit;\n    var num: u64 = 0; // Store number in u64 to simplify overflow checks.\n\n    loop: while(true) {\n    %{\n        re2c:yyfill:enable = 0;\n\n        <init> '0b' / [01]        :=> bin\n        <init> \"0\"                :=> oct\n        <init> \"\" / [1-9]         :=> dec\n        <init> '0x' / [0-9a-fA-F] :=> hex\n        <init> * { return null; }\n\n        <bin> [01]  { add(&num, yyinput, yycursor, 48, 2);  continue :loop; }\n        <oct> [0-7] { add(&num, yyinput, yycursor, 48, 8);  continue :loop; }\n        <dec> [0-9] { add(&num, yyinput, yycursor, 48, 10); continue :loop; }\n        <hex> [0-9] { add(&num, yyinput, yycursor, 48, 16); continue :loop; }\n        <hex> [a-f] { add(&num, yyinput, yycursor, 87, 16); continue :loop; }\n        <hex> [A-F] { add(&num, yyinput, yycursor, 55, 16); continue :loop; }\n\n        <bin, oct, dec, hex> * {\n            return if (num < ERROR) @intCast(num) else null;\n        }\n    %}}\n}\n\ntest {\n    try std.testing.expectEqual(parse_u32(\"\"), null);\n    try std.testing.expectEqual(parse_u32(\"1234567890\"), 1234567890);\n    try std.testing.expectEqual(parse_u32(\"0b1101\"), 13);\n    try std.testing.expectEqual(parse_u32(\"0x7Fe\"), 2046);\n    try std.testing.expectEqual(parse_u32(\"0644\"), 420);\n    try std.testing.expectEqual(parse_u32(\"9999999999\"), null);\n}\n",
      "extraCommandLineArguments": "-c"
    },
    "conditions/parse_u32_blocks.re": {
      "content": "// re2zig $INPUT -o $OUTPUT\n\nconst std = @import(\"std\");\n\n// Store u32 number in u64 during parsing to simplify overflow hadling.\nconst State = struct {\n    yyinput: [:0]const u8,\n    yycursor: usize,\n    yymarker: usize,\n    num: u64,\n};\n\n// Common re2c definitions shared between all functions.\n%{\n    re2c:api = record;\n    re2c:yyrecord = st;\n    re2c:yyfill:enable = 0;\n%}\n\nconst ERROR: u64 = @as(u64, std.math.maxInt(u32)) + 1; // overflow\n\n// Add digit with the given base, checking for overflow.\nfn add(st: *State, offs: u8, base: u64) void {\n    const digit = st.yyinput[st.yycursor - 1] - offs;\n    st.num = @min(st.num * base + digit, ERROR);\n}\n\n// Convert u64 to optional u32 (null meaning overflow or parse error).\nfn maybeU32(num: u64) ?u32 {\n    return if (num < ERROR) @intCast(num) else null;\n}\n\nfn parse_u32(s: [:0]const u8) ?u32 {\n    var st = State {.yyinput = s, .yycursor = 0, .yymarker = 0, .num = 0};\n    %{\n        '0b' / [01]        { return parse_bin(&st); }\n        \"0\"                { return parse_oct(&st); }\n        \"\" / [1-9]         { return parse_dec(&st); }\n        '0x' / [0-9a-fA-F] { return parse_hex(&st); }\n        *                  { return null; }\n    %}\n}\n\nfn parse_bin(st: *State) ?u32 {\n    bin: while (true) {%{\n        [01] { add(st, 48, 2); continue :bin; }\n        *    { return maybeU32(st.num); }\n    %}}\n}\n\nfn parse_oct(st: *State) ?u32 {\n    oct: while (true) {%{\n        [0-7] { add(st, 48, 8); continue :oct; }\n        *     { return maybeU32(st.num); }\n    %}}\n}\n\nfn parse_dec(st: *State) ?u32 {\n    dec: while (true) {%{\n        [0-9] { add(st, 48, 10); continue :dec; }\n        *     { return maybeU32(st.num); }\n    %}}\n}\n\nfn parse_hex(st: *State) ?u32 {\n    hex: while (true) {%{\n        [0-9] { add(st, 48, 16); continue :hex; }\n        [a-f] { add(st, 87, 16); continue :hex; }\n        [A-F] { add(st, 55, 16); continue :hex; }\n        *     { return maybeU32(st.num); }\n    %}}\n}\n\ntest {\n    try std.testing.expectEqual(parse_u32(\"\"), null);\n    try std.testing.expectEqual(parse_u32(\"1234567890\"), 1234567890);\n    try std.testing.expectEqual(parse_u32(\"0b1101\"), 13);\n    try std.testing.expectEqual(parse_u32(\"0x7Fe\"), 2046);\n    try std.testing.expectEqual(parse_u32(\"0644\"), 420);\n    try std.testing.expectEqual(parse_u32(\"9999999999\"), null);\n}\n",
      "extraCommandLineArguments": ""
    },
    "state/push.re": {
      "content": "// re2zig $INPUT -o $OUTPUT -f\n\nconst std = @import(\"std\");\n\nconst Status = enum {\n    end,\n    ready,\n    waiting,\n    bad_packet,\n    big_packet\n};\n\n// Use a small buffer to cover the case when a lexeme doesn't fit.\n// In real world use a larger buffer.\nconst bufsize = 10;\n\nconst State = struct {\n    yyinput: [bufsize + 1]u8,\n    yycursor: usize,\n    yymarker: usize,\n    yylimit: usize,\n    token: usize,\n    yystate: i32,\n    received: usize,\n};\n\nfn fill(st: *State, file: anytype) Status {\n    // Error: lexeme too long. In real life can reallocate a larger buffer.\n    if (st.token < 1) { return Status.big_packet; }\n\n    // Shift buffer contents (discard everything up to the current token).\n    std.mem.copyBackwards(\n        u8, st.yyinput[0..st.yylimit - st.token], st.yyinput[st.token..st.yylimit]);\n    st.yycursor -= st.token;\n    st.yymarker = @subWithOverflow(st.yymarker, st.token)[0];\n    st.yylimit -= st.token;\n    st.token = 0;\n\n    // Fill free space at the end of buffer with new data from file.\n    st.yylimit += file.read(st.yyinput[st.yylimit..bufsize]) catch 0;\n    st.yyinput[st.yylimit] = 0; // append sentinel symbol\n\n    return Status.ready;\n}\n\nfn lex(yyrecord: *State) Status {\n    var yych: u8 = 0;\n    loop: while (true) {\n        yyrecord.token = yyrecord.yycursor;\n        %{\n            re2c:api = record;\n            re2c:eof = 0;\n            re2c:YYFILL = \"return Status.waiting;\";\n\n            packet = [a-z]+[;];\n\n            *      { return Status.bad_packet; }\n            $      { return Status.end; }\n            packet { yyrecord.received += 1; continue :loop; }\n        %}\n    }\n}\n\nfn run(expect: Status, packets: []const []const u8) !void {\n    // Create a \"pipe\" (open the same file for reading and writing).\n    const fname = \"input\";\n    var fw = try std.fs.cwd().createFile(fname, .{});\n    var fr = try std.fs.cwd().openFile(fname, .{ .mode = .read_only});\n\n    // Initialize lexer state: `state` value is -1, all offsets are at the end\n    // of buffer. Normally file would be part of the state, but BufferedReader\n    // type is unclear.\n    var br = std.io.bufferedReader(fr.reader());\n    var st = State{\n        .yyinput = undefined,\n        .yycursor = bufsize,\n        .yymarker = bufsize,\n        .yylimit = bufsize,\n        .token = bufsize,\n        .yystate = -1,\n        .received = 0,\n    };\n    // Sentinel at `yylimit` offset is set to zero, which triggers YYFILL.\n    st.yyinput[st.yylimit] = 0;\n\n    // Main loop. The buffer contains incomplete data which appears packet by\n    // packet. When the lexer needs more input it saves its internal state and\n    // returns to the caller which should provide more input and resume lexing.\n    var status = Status.ready;\n    var send: usize = 0;\n    while (true) {\n        status = lex(&st);\n        if (status == Status.end) {\n            break;\n        } else if (status == Status.waiting) {\n            if (send < packets.len) {\n                std.log.debug(\"sending packet {}\", .{send});\n                try fw.writeAll(packets[send]);\n                send += 1;\n            }\n            status = fill(&st, &br);\n            std.log.debug(\"filled buffer [{s}], status {}\", .{st.yyinput, status});\n            if (status != Status.ready) {\n                break;\n            }\n        } else if (status == Status.bad_packet) {\n            break;\n        }\n    }\n\n    // Check results.\n    try std.testing.expectEqual(status, expect);\n    if (status == Status.end) { try std.testing.expectEqual(st.received, send); }\n\n    // Cleanup: remove input file.\n    fw.close();\n    fr.close();\n    try std.fs.cwd().deleteFile(fname);\n}\n\ntest {\n    try run(Status.end, &[_][]const u8{});\n    try run(Status.end, &[_][]const u8{\"zero;\", \"one;\", \"two;\", \"three;\", \"four;\"});\n    try run(Status.bad_packet, &[_][]const u8{\"??;\"});\n    try run(Status.big_packet, &[_][]const u8{\"looooooooooooong;\"});\n}\n",
      "extraCommandLineArguments": "-f"
    },
    "submatch/02_mtags.re": {
      "content": "// re2zig $INPUT -o $OUTPUT\n\nconst std = @import(\"std\");\n\nconst none = std.math.maxInt(usize);\nconst mtag_root = none - 1;\n\nconst err = error.SyntaxError;\n\n// An m-tag tree is a way to store histories with an O(1) copy operation.\n// Histories naturally form a tree, as they have common start and fork at some\n// point. The tree is stored as an array of pairs (tag value, link to parent).\n// An m-tag is represented with a single link in the tree (array index).\nconst MtagElem = struct {\n    elem: usize, // tag value\n    pred: usize, // index of the predecessor node or root\n};\n\n// Append a single value to an m-tag history.\nfn add_mtag(trie: *std.ArrayList(MtagElem), mtag: usize, value: usize) !usize {\n    try trie.append(MtagElem{.elem = value, .pred = mtag});\n    return trie.items.len - 1;\n}\n\n// Recursively unwind tag histories and collect version components.\nfn unwind(trie: *std.ArrayList(MtagElem),\n          x: usize,\n          y: usize,\n          str: []const u8,\n          ver: *std.ArrayList(u32)) !void {\n    // Reached the root of the m-tag tree, stop recursion.\n    if (x == mtag_root and y == mtag_root) return;\n\n    // Unwind history further.\n    try unwind(trie, trie.items[x].pred, trie.items[y].pred, str, ver);\n\n    // Get tag values. Tag histories must have equal length.\n    std.debug.assert(x != mtag_root and y != mtag_root);\n    var ex = trie.items[x].elem;\n    var ey = trie.items[y].elem;\n\n    if (ex != none and ey != none) {\n        // Both tags are valid string indices, extract component.\n        try ver.append(s2n(str[ex..ey]));\n    } else {\n        // Both tags are none (this corresponds to zero repetitions).\n        std.debug.assert(ex == none and ey == none);\n    }\n}\n\nfn s2n(str: []const u8) u32 { // convert a pre-parsed string to a number\n    var n: u32 = 0;\n    for (str) |c| { n = n * 10 + (c - 48); }\n    return n;\n}\n\nfn parse(yyinput: [:0]const u8) !std.ArrayList(u32) {\n    var yycursor: usize = 0;\n    var yymarker: usize = 0;\n    var mt = std.ArrayList(MtagElem).init(std.testing.allocator);\n    defer mt.deinit();\n\n    // Final tag variables available in semantic action.\n    %{svars format = \"var @@: usize = none;\"; %}\n    %{mvars format = \"var @@: usize = mtag_root;\"; %}\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    %{stags format = \"var @@: usize = none;\"; %}\n    %{mtags format = \"var @@: usize = mtag_root;\"; %}\n\n    %{\n        re2c:YYMTAGP = \"@@ = add_mtag(&mt, @@, yycursor) catch none;\";\n        re2c:YYMTAGN = \"@@ = add_mtag(&mt, @@, none) catch none;\";\n        re2c:yyfill:enable = 0;\n        re2c:tags = 1;\n\n        num = [0-9]+;\n\n        @t1 num @t2 (\".\" #t3 num #t4)* [\\x00] {\n            var ver = std.ArrayList(u32).init(std.testing.allocator);\n            try ver.append(s2n(yyinput[t1..t2]));\n            try unwind(&mt, t3, t4, yyinput, &ver);\n            return ver;\n        }\n        * { return error.SyntaxError; }\n    %}\n}\n\ntest {\n    var result = try parse(\"1\");\n    var expect = std.ArrayList(u32).init(std.testing.allocator);\n    try expect.appendSlice(&[_]u32{1});\n    try std.testing.expectEqualDeep(result, expect);\n    expect.deinit();\n    result.deinit();\n}\n\ntest {\n    var result = try parse(\"1.2.3.4.5.6.7\");\n    var expect = std.ArrayList(u32).init(std.testing.allocator);\n    try expect.appendSlice(&[_]u32{1, 2, 3, 4, 5, 6, 7});\n    try std.testing.expectEqualDeep(result, expect);\n    expect.deinit();\n    result.deinit();\n}\n\ntest {\n    var result = parse(\"1.2.\") catch null;\n    try std.testing.expectEqualDeep(result, null);\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/04_posix_captures.re": {
      "content": "// re2zig $INPUT -o $OUTPUT\n\nconst std = @import(\"std\");\n\n// Maximum number of capturing groups among all rules.\n%{maxnmatch %}\nconst none = std.math.maxInt(usize);\n\nconst SemVer = struct {\n    major: u32,\n    minor: u32,\n    patch: u32,\n};\n\nfn s2n(str: []const u8) u32 { // convert pre-parsed string to a number\n    var n: u32 = 0;\n    for (str) |c| { n = n * 10 + (c - 48); }\n    return n;\n}\n\nfn parse(yyinput: [:0]const u8) ?SemVer {\n    var yycursor: usize = 0;\n    var yymarker: usize = 0;\n\n    // Allocate memory for capturing parentheses (twice the number of groups).\n    var yynmatch: usize = 0;\n    var yypmatch: [yymaxnmatch * 2]usize = undefined;\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    %{stags format = \"var @@: usize = none;\"; %}\n\n    %{\n        re2c:yyfill:enable = 0;\n        re2c:posix-captures = 1;\n\n        num = [0-9]+;\n\n        (num) \".\" (num) (\".\" num)? [\\x00] {\n            // `yynmatch` is the number of capturing groups\n            std.debug.assert(yynmatch == 4);\n\n            // Even `yypmatch` values are for opening parentheses, odd values\n            // are for closing parentheses, the first group is the whole match.\n            return SemVer {\n                .major = s2n(yyinput[yypmatch[2]..yypmatch[3]]),\n                .minor = s2n(yyinput[yypmatch[4]..yypmatch[5]]),\n                .patch = if (yypmatch[6] == none) 0 else s2n(yyinput[yypmatch[6] + 1..yypmatch[7]])\n            };\n        }\n        * { return null; }\n    %}\n}\n\ntest {\n    try std.testing.expectEqual(parse(\"23.34\"), SemVer{.major = 23, .minor = 34, .patch = 0});\n    try std.testing.expectEqual(parse(\"1.2.99999\"), SemVer{.major = 1, .minor = 2, .patch = 99999});\n    try std.testing.expectEqual(parse(\"1.a\"), null);\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags.re": {
      "content": "// re2zig $INPUT -o $OUTPUT\n\nconst std = @import(\"std\");\n\nconst SemVer = struct {\n    major: u32,\n    minor: u32,\n    patch: u32,\n};\n\nconst none = std.math.maxInt(usize);\n\nfn s2n(str: []const u8) u32 { // convert a pre-parsed string to a number\n    var n: u32 = 0;\n    for (str) |c| { n = n * 10 + (c - 48); }\n    return n;\n}\n\nfn parse(yyinput: [:0]const u8) ?SemVer {\n    var yycursor: usize = 0;\n    var yymarker: usize = 0;\n\n    // Final tag variables available in semantic action.\n    %{svars format = \"var @@: usize = none;\"; %}\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    %{stags format = \"var @@: usize = none;\"; %}\n\n    %{\n        re2c:yyfill:enable = 0;\n        re2c:tags = 1;\n\n        num = [0-9]+;\n\n        @t1 num @t2 \".\" @t3 num @t4 (\".\" @t5 num)? [\\x00] {\n            return SemVer {\n                .major = s2n(yyinput[t1..t2]),\n                .minor = s2n(yyinput[t3..t4]),\n                .patch = if (t5 == none) 0 else s2n(yyinput[t5..yycursor - 1]),\n            };\n        }\n        * { return null; }\n    %}\n}\n\ntest {\n    try std.testing.expectEqual(parse(\"23.34\"), SemVer{.major = 23, .minor = 34, .patch = 0});\n    try std.testing.expectEqual(parse(\"1.2.99999\"), SemVer{.major = 1, .minor = 2, .patch = 99999});\n    try std.testing.expectEqual(parse(\"1.a\"), null);\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/03_captures.re": {
      "content": "// re2zig $INPUT -o $OUTPUT\n\nconst std = @import(\"std\");\n\nconst none = std.math.maxInt(usize);\n\nconst SemVer = struct {\n    major: u32,\n    minor: u32,\n    patch: u32,\n};\n\nfn s2n(str: []const u8) u32 { // convert pre-parsed string to a number\n    var n: u32 = 0;\n    for (str) |c| { n = n * 10 + (c - 48); }\n    return n;\n}\n\nfn parse(yyinput: [:0]const u8) ?SemVer {\n    var yycursor: usize = 0;\n    var yymarker: usize = 0;\n\n    // Final tag variables available in semantic action.\n    %{svars format = \"var @@: usize = none;\"; %}\n\n    // Intermediate tag variables used by the lexer (must be autogenerated).\n    %{stags format = \"var @@: usize = none;\"; %}\n\n    %{\n        re2c:yyfill:enable = 0;\n        re2c:captvars = 1;\n\n        num = [0-9]+;\n\n        (num) \".\" (num) (\".\" num)? [\\x00] {\n            return SemVer {\n                .major = s2n(yyinput[yytl1..yytr1]),\n                .minor = s2n(yyinput[yytl2..yytr2]),\n                .patch = if (yytl3 == none) 0 else s2n(yyinput[yytl3 + 1..yytr3])\n            };\n        }\n        * { return null; }\n    %}\n}\n\ntest {\n    try std.testing.expectEqual(parse(\"23.34\"), SemVer{.major = 23, .minor = 34, .patch = 0});\n    try std.testing.expectEqual(parse(\"1.2.99999\"), SemVer{.major = 1, .minor = 2, .patch = 99999});\n    try std.testing.expectEqual(parse(\"1.a\"), null);\n}\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags_fill.re": {
      "content": "// re2zig $INPUT -o $OUTPUT\n\nconst std = @import(\"std\");\n\nconst bufsize = 4095;\nconst none = std.math.maxInt(usize);\n\nconst err = error.SyntaxError;\n\nconst SemVer = struct {\n    major: u32,\n    minor: u32,\n    patch: u32,\n};\n\nfn s2n(str: []const u8) u32 { // convert a pre-parsed string to a number\n    var n: u32 = 0;\n    for (str) |c| { n = n * 10 + (c - 48); }\n    return n;\n}\n\nconst State = struct {\n    yyinput: [bufsize + 1]u8,\n    yycursor: usize,\n    yymarker: usize,\n    yylimit: usize,\n    token: usize,\n    // Intermediate tag variables must be part of the lexer state passed to YYFILL.\n    // They don't correspond to tags and should be autogenerated by re2c.\n    %{stags format = \"@@: usize,\\n\"; %}\n    eof: bool\n};\n\nfn fill(st: *State, file: anytype) i32 {\n    if (st.eof) { return -1; } // unexpected EOF\n\n    // Error: lexeme too long. In real life can reallocate a larger buffer.\n    if (st.token < 1) { return -2; }\n\n    // Shift buffer contents (discard everything up to the current token).\n    std.mem.copyBackwards(\n        u8, st.yyinput[0..st.yylimit - st.token], st.yyinput[st.token..st.yylimit]);\n    st.yycursor -= st.token;\n    st.yymarker = @subWithOverflow(st.yymarker, st.token)[0];\n    st.yylimit -= st.token;\n    // Tag variables need to be shifted like other input positions. The check\n    // for NONE is only needed if some tags are nested inside of alternative or\n    // repetition, so that they can have NONE value.\n    %{stags format = \"if (st.@@ != none) st.@@ = @subWithOverflow(st.@@, st.token)[0];\\n\"; %}\n    st.token = 0;\n\n    // Fill free space at the end of buffer with new data from file.\n    st.yylimit += file.read(st.yyinput[st.yylimit..bufsize]) catch 0;\n    st.yyinput[st.yylimit] = 0; // append sentinel symbol\n\n    // If read less than expected, this is the end of input.\n    st.eof = st.yylimit < bufsize;\n\n    return 0;\n}\n\nfn parse(st: *State, file: anytype) !std.ArrayList(SemVer) {\n    var vers = std.ArrayList(SemVer).init(std.testing.allocator);\n\n    // Final tag variables available in semantic action.\n    %{svars format = \"var @@: usize = 0;\\n\"; %}\n\n    loop: while (true) {\n        st.token = st.yycursor;\n        %{\n            re2c:api = record;\n            re2c:eof = 0;\n            re2c:tags = 1;\n            re2c:yyrecord = st;\n            re2c:YYFILL = \"fill(st, file) == 0\";\n\n            num = [0-9]+;\n\n            num @t1 \".\" @t2 num @t3 (\".\" @t4 num)? [\\n] {\n                try vers.append(SemVer {\n                    .major = s2n(st.yyinput[st.token..t1]),\n                    .minor = s2n(st.yyinput[t2..t3]),\n                    .patch = if (t4 == none) 0 else s2n(st.yyinput[t4..st.yycursor - 1]),\n                });\n                continue :loop;\n            }\n            $ { return vers; }\n            * { return error.SyntaxError; }\n        %}\n    }\n}\n\ntest {\n    const fname = \"input\";\n    const content = \"1.22.333\\n\" ** bufsize;\n\n    // Prepare input file: a few times the size of the buffer, containing\n    // strings with zeroes and escaped quotes.\n    var fw = try std.fs.cwd().createFile(fname, .{});\n    try fw.writeAll(content);\n    fw.close();\n\n    // Prepare lexer state: all offsets are at the end of buffer.\n    var fr = try std.fs.cwd().openFile(fname, .{ .mode = .read_only});\n    // Normally file would be part of the state struct, but BufferedReader type is unclear.\n    var br = std.io.bufferedReader(fr.reader());\n    var st = State{\n        .yyinput = undefined,\n        .yycursor = bufsize,\n        .yymarker = bufsize,\n        .yylimit = bufsize,\n        .token = bufsize,\n        %{stags format = \".@@ = none,\\n\"; %}\n        .eof = false,\n    };\n    // Sentinel at `yylimit` offset is set to zero, which triggers YYFILL.\n    st.yyinput[st.yylimit] = 0;\n\n    // Manually construct expected result.\n    var expect = std.ArrayList(SemVer).init(std.testing.allocator);\n    for (0..bufsize) |_| try expect.append(SemVer{.major = 1, .minor = 22, .patch = 333});\n\n    // Run the lexer.\n    var result = try parse(&st, &br);\n    try std.testing.expectEqualDeep(result, expect);\n\n    // Cleanup: free memory and remove input file.\n    expect.deinit();\n    result.deinit();\n    fr.close();\n    try std.fs.cwd().deleteFile(fname);\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/03_eof_rule.re": {
      "content": "// re2zig $INPUT -o $OUTPUT\n\nconst std = @import(\"std\");\n\n// Expects a null-terminated string.\nfn lex(yyinput: [:0]const u8) i32 {\n    var yycursor: usize = 0;\n    var yymarker: usize = 0;\n    const yylimit: usize = yyinput.len; // points at the terminating null\n    var count: i32 = 0;\n\n    loop: while (true) {\n        %{\n            re2c:yyfill:enable = 0;\n            re2c:eof = 0;\n\n            str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n            *    { return -1; }\n            $    { return count; }\n            str  { count += 1; continue :loop; }\n            [ ]+ { continue :loop; }\n        %}\n    }\n}\n\ntest {\n    try std.testing.expectEqual(lex(\"\"), 0);\n    try std.testing.expectEqual(lex(\"'qu\\x00tes' 'are' 'fine: \\\\'' \"), 3);\n    try std.testing.expectEqual(lex(\"'unterminated\\\\'\"), -1);\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/04_fake_sentinel.re": {
      "content": "// re2zig $INPUT -o $OUTPUT\n\nconst std = @import(\"std\");\n\n// Expects a string without terminating null.\nfn lex(str: []const u8) i32 {\n    var cur: usize = 0;\n    var count: i32 = 0;\n\n    loop: while (true) {\n        %{\n            re2c:api = generic;\n            re2c:yyfill:enable = 0;\n            // YYPEEK returns \"fake\" terminating null if cursor has reached limit.\n            re2c:YYPEEK = \"if (cur >= str.len) 0 else str[cur]\";\n            re2c:YYSKIP = \"cur += 1;\";\n\n            *      { return -1; }\n            [\\x00] { return count; }\n            [a-z]+ { count += 1; continue :loop; }\n            [ ]+   { continue :loop; }\n        %}\n    }\n}\n\ntest {\n    try std.testing.expectEqual(lex(\"\"), 0);\n    try std.testing.expectEqual(lex(\"one two three\"), 3);\n    try std.testing.expectEqual(lex(\"f0ur\"), -1);\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/02_bounds_checking.re": {
      "content": "// re2zig $INPUT -o $OUTPUT\n\nconst std = @import(\"std\");\n\n%{max %}\n\nfn lex(str: []const u8) !i32 {\n    // Create a copy of the input string padded with yymaxfill zeroes at the end.\n    var yyinput = try std.testing.allocator.alloc(u8, str.len + yymaxfill);\n    defer std.testing.allocator.free(yyinput);\n    std.mem.copy(u8, yyinput[0..], str);\n    std.mem.copy(u8, yyinput[str.len..], &[_]u8{0} ** yymaxfill); // zero padding\n\n    var yycursor: usize = 0;\n    var yylimit: usize = yyinput.len;\n    var count: i32 = 0;\n\n    loop: while (true) {\n        %{\n            re2c:YYFILL = \"return -1;\";\n\n            str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n            [\\x00] {\n                // Check that it is the sentinel, not some unexpected null.\n                return if (yycursor - 1 == str.len) count else -1;\n            }\n            str  { count += 1; continue :loop; }\n            [ ]+ { continue :loop; }\n            *    { return -1; }\n        %}\n    }\n}\n\ntest {\n    try std.testing.expectEqual(lex(\"\"), 0);\n    try std.testing.expectEqual(lex(\"'qu\\x00tes' 'are' 'fine: \\\\'' \"), 3);\n    try std.testing.expectEqual(lex(\"'unterminated\\\\'\"), -1);\n    try std.testing.expectEqual(lex(\"'unexpected \\x00 null\\\\'\"), -1);\n}\n",
      "extraCommandLineArguments": ""
    },
    "eof/01_sentinel.re": {
      "content": "// re2zig $INPUT -o $OUTPUT\n\nconst std = @import(\"std\");\n\n// Expects a null-terminated string.\nfn lex(yyinput: [:0]const u8) i32 {\n    var yycursor: u32 = 0;\n    var count: i32 = 0;\n\n    loop: while (true) {\n        %{\n            re2c:yyfill:enable = 0;\n\n            *      { return -1; }\n            [\\x00] { return count; }\n            [a-z]+ { count += 1; continue :loop; }\n            [ ]+   { continue :loop; }\n        %}\n    }\n}\n\ntest {\n    try std.testing.expectEqual(lex(\"\"), 0);\n    try std.testing.expectEqual(lex(\"one two three\"), 3);\n    try std.testing.expectEqual(lex(\"f0ur\"), -1);\n}\n",
      "extraCommandLineArguments": ""
    },
    "includes/include.re": {
      "content": "// re2zig $INPUT -o $OUTPUT\n\nconst std = @import(\"std\");\n\n%{include \"definitions.zig\" %}\n\nfn lex(yyinput: [:0]const u8) Num {\n    var yycursor: u32 = 0;\n    var yymarker: u32 = 0;\n    %{\n        re2c:yyfill:enable = 0;\n\n        *      { return Num.nan; }\n        number { return Num.integer; }\n        !include \"extra_rules.re.inc\";\n    %}\n}\n\ntest {\n    try std.testing.expectEqual(lex(\"123\"), Num.integer);\n    try std.testing.expectEqual(lex(\"123.4567\"), Num.floating);\n}\n",
      "extraCommandLineArguments": ""
    },
    "encodings/unicode_identifier.re": {
      "content": "// re2zig $INPUT -o $OUTPUT --utf8\n\nconst std = @import(\"std\");\n\n%{include \"unicode_categories.re\" %}\n\nfn lex(yyinput: [:0]const u8) bool {\n    var yycursor: u32 = 0;\n    var yymarker: u32 = 0;\n\n    %{\n        re2c:yyfill:enable = 0;\n\n        // Simplified \"Unicode Identifier and Pattern Syntax\"\n        // (see https://unicode.org/reports/tr31)\n        id_start    = L | Nl | [$_];\n        id_continue = id_start | Mn | Mc | Nd | Pc | [\\u200D\\u05F3];\n        identifier  = id_start id_continue*;\n\n        identifier { return true; }\n        *          { return false; }\n    %}\n}\n\ntest {\n    try std.testing.expect(lex(\"_\u042b\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\"));\n}\n",
      "extraCommandLineArguments": "--utf8"
    },
    "reuse/reuse.re": {
      "content": "// re2zig $INPUT -o $OUTPUT --input-encoding utf8\n\n// This example supports multiple input encodings: UTF-8 and UTF-32.\n// Both lexers are generated from the same rules block, and the use\n// blocks add only encoding-specific configurations.\n\nconst std = @import(\"std\");\n\n%{rules\n    re2c:yyfill:enable = 0;\n\n    \"\u2200x \u2203y\" { return yycursor; }\n    *       { return null; }\n%}\n\nfn lex_utf8(yyinput: []const u8) ?usize {\n    var yycursor: usize = 0;\n    var yymarker: usize = 0;\n    %{use\n        re2c:encoding:utf8 = 1;\n        re2c:YYCTYPE = u8; // the default\n    %}\n}\n\nfn lex_utf32(yyinput: []const u32) ?usize {\n    var yycursor: usize = 0;\n    var yymarker: usize = 0;\n    %{use\n        re2c:encoding:utf32 = 1;\n        re2c:YYCTYPE = u32;\n    %}\n}\n\ntest {\n    const s8 = [_]u8{0xe2, 0x88, 0x80, 0x78, 0x20, 0xe2, 0x88, 0x83, 0x79};\n    try std.testing.expectEqual(lex_utf8(&s8), s8.len);\n\n    const s32 = [_]u32{0x2200, 0x78, 0x20, 0x2203, 0x79};\n    try std.testing.expectEqual(lex_utf32(&s32), s32.len);\n}\n",
      "extraCommandLineArguments": "--input-encoding utf8"
    },
    "reuse/usedir.re": {
      "content": "// re2zig $INPUT -o $OUTPUT\n\n// This example shows how to combine reusable re2c blocks: two blocks\n// ('colors' and 'fish') are merged into one. The 'salmon' rule occurs\n// in both blocks; the 'fish' block takes priority because it is used\n// earlier. Default rule * occurs in all three blocks; the local (not\n// inherited) definition takes priority.\n\nconst std = @import(\"std\");\n\nconst Ans = enum {color, fish, dunno};\n\n%{rules:colors\n    *                            { @panic(\"ah\"); }\n    \"red\" | \"salmon\" | \"magenta\" { return Ans.color; }\n%}\n\n%{rules:fish\n    *                            { @panic(\"oh\"); }\n    \"haddock\" | \"salmon\" | \"eel\" { return Ans.fish; }\n%}\n\nfn lex(yyinput: [:0]const u8) Ans {\n    var yycursor: usize = 0;\n    var yymarker: usize = 0;\n    %{\n        re2c:yyfill:enable = 0;\n\n        !use:fish;\n        !use:colors;\n        * { return Ans.dunno; } // overrides inherited '*' rules\n    %}\n}\n\ntest {\n    try std.testing.expectEqual(lex(\"salmon\"), Ans.fish);\n    try std.testing.expectEqual(lex(\"what?\"), Ans.dunno);\n}\n",
      "extraCommandLineArguments": ""
    },
    "headers/header.re": {
      "content": "// re2zig $INPUT -o $OUTPUT --header lexer/state.zig\n\nconst std = @import(\"std\");\nconst state = @import(\"lexer/state.zig\"); // the module is generated by re2c\n\n%{header:on %}\npub const State = struct {\n    yyinput: [:0]const u8,\n    yycursor: usize,\n    %{stags format = \"@@: usize,\"; %}\n};\n%{header:off %}\n\nfn lex(yyrecord: *state.State) usize {\n    var t: usize = 0;\n    %{\n        re2c:header = \"lexer/state.zig\";\n        re2c:api = record;\n        re2c:yyfill:enable = 0;\n        re2c:tags = 1;\n\n        [a]* @t [b]* { return t; }\n    %}\n}\n\ntest {\n    var st = state.State {\n        .yyinput = \"ab\",\n        .yycursor = 0,\n        %{stags format = \".@@ = 0,\"; %}\n    };\n    try std.testing.expectEqual(lex(&st), 1);\n}\n",
      "extraCommandLineArguments": "--header lexer/state.zig"
    }
  },
  "ocaml": {
    "01_basic.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT -i *)\n\nopen String\n\ntype state = {\n    yyinput: string;\n    mutable yycursor: int;\n}\n\n%{\n    re2c:YYFN = [\"lex;bool\", \"yyrecord;state\"];\n    re2c:yyfill:enable = 0;\n\n    [1-9][0-9]* { true }\n    *           { false }\n%}\n\nlet main () =\n    let st = {yyinput = \"1234\\x00\"; yycursor = 0}\n    in if not (lex st) then raise (Failure \"error\")\n\nlet _ = main ()\n",
      "extraCommandLineArguments": "-i "
    },
    "fill/01_fill.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT *)\n\nopen Bytes\n\nlet bufsize = 4096\n\ntype state = {\n    file: in_channel;\n    yyinput: bytes;\n    mutable yycursor: int;\n    mutable yymarker: int;\n    mutable yylimit: int;\n    mutable token: int;\n    mutable eof: bool;\n}\n\ntype status = Ok | Eof | LongLexeme\n\nlet fill(st: state) : status =\n    if st.eof then Eof else\n\n    (* Error: lexeme too long. In real life could reallocate a larger buffer. *)\n    if st.token < 1 then LongLexeme else (\n\n    (* Shift buffer contents (discard everything up to the current token). *)\n    blit st.yyinput st.token st.yyinput 0 (st.yylimit - st.token);\n    st.yycursor <- st.yycursor - st.token;\n    st.yymarker <- st.yymarker - st.token;\n    st.yylimit <- st.yylimit - st.token;\n    st.token <- 0;\n\n    (* Fill free space at the end of buffer with new data from file. *)\n    let n = input st.file st.yyinput st.yylimit (bufsize - st.yylimit - 1) in (* -1 for sentinel *)\n    st.yylimit <- st.yylimit + n;\n    if n = 0 then\n        st.eof <- true; (* end of file *)\n        set st.yyinput st.yylimit '\\x00'; (* append sentinel *)\n\n    Ok)\n\n%{\n    re2c:YYFN = [\"lex;int\", \"yyrecord;state\", \"count;int\"];\n    re2c:YYFILL = \"fill yyrecord = Ok\";\n    re2c:eof = 0;\n\n    str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n    *    { -1 }\n    $    { count }\n    str  { lex_loop yyrecord (count + 1) }\n    [ ]+ { lex_loop yyrecord count }\n%}\n\nand lex_loop st count =\n    st.token <- st.yycursor;\n    lex st count\n\nlet main () =\n    let fname = \"input\" in\n\n    (* Prepare input file. *)\n    Out_channel.with_open_bin fname\n        (fun oc -> for i = 1 to bufsize do\n            output_string oc \"'qu\\x00tes' 'are' 'fine: \\\\'' \"\n        done);\n\n    (* Run lexer on the prepared file. *)\n    In_channel.with_open_bin fname\n        (fun ic ->\n            let yylimit = bufsize - 1 in\n            let st = {\n                file = ic;\n                yyinput = create bufsize;\n                yycursor = yylimit;\n                yymarker = yylimit;\n                yylimit = yylimit;\n                token = yylimit;\n                eof = false;\n            } in if not (lex_loop st 0 = 3 * bufsize) then\n                raise (Failure \"error\"));\n\n    (* Cleanup. *)\n    Sys.remove fname\n\nlet _ = main ()\n",
      "extraCommandLineArguments": ""
    },
    "fill/02_fill.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT *)\n\nopen Bytes\n\n%{max %}\nlet bufsize = 4096\n\nexception Fill\n\ntype state = {\n    file: in_channel;\n    yyinput: bytes;\n    mutable yycursor: int;\n    mutable yymarker: int;\n    mutable yylimit: int;\n    mutable token: int;\n    mutable eof: bool;\n}\n\ntype status = Ok | Eof | LongLexeme\n\nlet fill (st: state) (need: int) : status =\n    if st.eof then Eof else\n\n    (* Error: lexeme too long. In real life could reallocate a larger buffer. *)\n    if st.token < need then LongLexeme else (\n\n    (* Shift buffer contents (discard everything up to the current token). *)\n    blit st.yyinput st.token st.yyinput 0 (st.yylimit - st.token);\n    st.yycursor <- st.yycursor - st.token;\n    st.yymarker <- st.yymarker - st.token;\n    st.yylimit <- st.yylimit - st.token;\n    st.token <- 0;\n\n    (* Fill free space at the end of buffer with new data from file. *)\n    let n = input st.file st.yyinput st.yylimit (bufsize - st.yylimit - 1) in (* -1 for sentinel *)\n    st.yylimit <- st.yylimit + n;\n\n    (* If read zero characters, this is end of input => add zero padding\n       so that the lexer can access characters at the end of buffer. *)\n    if n = 0 then\n        st.eof <- true; (* end of file *)\n        for i = 0 to (yymaxfill - 1) do\n            set st.yyinput (st.yylimit + i) '\\x00';\n            st.yylimit <- st.yylimit + yymaxfill\n        done;\n\n    Ok)\n\n%{\n    re2c:YYFN = [\"lex;int\", \"yyrecord;state\", \"count;int\"];\n    re2c:YYFILL = \"if not (fill yyrecord @@ = Ok) then raise Fill;\";\n\n    str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n    [\\x00] {\n        (* check that it is the sentinel, not some unexpected null *)\n        if yyrecord.token = yyrecord.yylimit - yymaxfill then count else -1\n    }\n    str  { lex_loop yyrecord (count + 1) }\n    [ ]+ { lex_loop yyrecord count }\n    *    { -1 }\n%}\n\nand lex_loop st count =\n    st.token <- st.yycursor;\n    try lex st count with Fill -> -1\n\nlet main () =\n    let fname = \"input\" in\n\n    (* Prepare input file. *)\n    Out_channel.with_open_bin fname\n        (fun oc -> for i = 1 to bufsize do\n            output_string oc \"'qu\\x00tes' 'are' 'fine: \\\\'' \"\n        done);\n\n    (* Run lexer on the prepared file. *)\n    In_channel.with_open_bin fname\n        (fun ic ->\n            let yylimit = bufsize - yymaxfill in\n            let st = {\n                file = ic;\n                yyinput = create bufsize;\n                yycursor = yylimit;\n                yymarker = yylimit;\n                yylimit = yylimit;\n                token = yylimit;\n                eof = false;\n            } in if not (lex_loop st 0 = 3 * bufsize) then\n                raise (Failure \"error\"));\n\n    (* Cleanup. *)\n    Sys.remove fname\n\nlet _ = main ()\n",
      "extraCommandLineArguments": ""
    },
    "conditions/parse_u32_conditions.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT -ci *)\n\nopen Int64\nopen Option\nopen String\n\n%{conditions %}\n\ntype state = {\n    yyinput: string;\n    mutable yycursor: int;\n    mutable yymarker: int;\n    mutable yycond: yycondtype;\n} \n\nlet add (num: int option) (dgt: int) (base: int) : int option =\n    match num with\n        | None -> None\n        | Some n ->\n            let n' = add (mul (of_int n) (of_int base)) (of_int dgt)\n            in if n' > (of_int32 Int32.max_int) then None else Some (to_int n')\n\n%{\n    re2c:YYFN = [\"parse;int option\", \"st;state\", \"num;int option\"];\n    re2c:yyrecord = \"st\";\n    re2c:yyfill:enable = 0;\n\n    <init> '0b' / [01]        :=> bin\n    <init> \"0\"                :=> oct\n    <init> \"\" / [1-9]         :=> dec\n    <init> '0x' / [0-9a-fA-F] :=> hex\n    <init> * { None }\n\n    <bin> [01]  { yyfnbin st (add num (Char.code st.yyinput.[st.yycursor - 1] - 48) 2) }\n    <oct> [0-7] { yyfnoct st (add num (Char.code st.yyinput.[st.yycursor - 1] - 48) 8) }\n    <dec> [0-9] { yyfndec st (add num (Char.code st.yyinput.[st.yycursor - 1] - 48) 10) }\n    <hex> [0-9] { yyfnhex st (add num (Char.code st.yyinput.[st.yycursor - 1] - 48) 16) }\n    <hex> [a-f] { yyfnhex st (add num (Char.code st.yyinput.[st.yycursor - 1] - 87) 16) }\n    <hex> [A-F] { yyfnhex st (add num (Char.code st.yyinput.[st.yycursor - 1] - 55) 16) }\n\n    <bin, oct, dec, hex> * { num }\n%}\n\nlet test (yyinput: string) (result: int option) =\n    let st = {yyinput = yyinput; yycursor = 0; yymarker = 0; yycond = YYC_init} in\n    if not (parse st (Some 0) = result) then raise (Failure \"error\")\n\nlet main () =\n    test \"\\x00\" None;\n    test \"1234567890\\x00\" (Some 1234567890);\n    test \"0b1101\\x00\" (Some 13);\n    test \"0x7Fe\\x00\" (Some 2046);\n    test \"0644\\x00\" (Some 420);\n    test \"9999999999\\x00\" None\n\nlet _ = main ()\n",
      "extraCommandLineArguments": "-ci "
    },
    "conditions/parse_u32_blocks.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT -i *)\n\nopen Int64\nopen Option\nopen String\n\ntype state = {\n    yyinput: string;\n    mutable yycursor: int;\n    mutable yymarker: int;\n} \n\nlet add (num: int option) (dgt: int) (base: int) : int option =\n    match num with\n        | None -> None\n        | Some n ->\n            let n' = add (mul (of_int n) (of_int base)) (of_int dgt)\n            in if n' > (of_int32 Int32.max_int) then None else Some (to_int n')\n\n%{\n    re2c:yyrecord = \"st\";\n    re2c:yyfill:enable = 0;\n%}\n\n%{local\n    re2c:YYFN = [\"parse_bin;int option\", \"st;state\", \"num;int option\"];\n    [01] { parse_bin st (add num (Char.code st.yyinput.[st.yycursor - 1] - 48) 2) }\n    *    { num }\n%}\n\n%{local\n    re2c:YYFN = [\"parse_oct;int option\", \"st;state\", \"num;int option\"];\n    [0-7] { parse_oct st (add num (Char.code st.yyinput.[st.yycursor - 1] - 48) 8) }\n    *     { num }\n%}\n\n%{local\n    re2c:YYFN = [\"parse_dec;int option\", \"st;state\", \"num;int option\"];\n    [0-9] { parse_dec st (add num (Char.code st.yyinput.[st.yycursor - 1] - 48) 10) }\n    *     { num }\n%}\n\n%{local\n    re2c:YYFN = [\"parse_hex;int option\", \"st;state\", \"num;int option\"];\n    [0-9] { parse_hex st (add num (Char.code st.yyinput.[st.yycursor - 1] - 48) 16) }\n    [a-f] { parse_hex st (add num (Char.code st.yyinput.[st.yycursor - 1] - 87) 16) }\n    [A-F] { parse_hex st (add num (Char.code st.yyinput.[st.yycursor - 1] - 55) 16) }\n    *     { num }\n%}\n\n%{local\n    re2c:YYFN = [\"parse;int option\", \"st;state\"];\n    '0b' / [01]        { parse_bin st (Some 0) }\n    \"0\"                { parse_oct st (Some 0) }\n    \"\" / [1-9]         { parse_dec st (Some 0) }\n    '0x' / [0-9a-fA-F] { parse_hex st (Some 0) }\n    *                  { None }\n%}\n\nlet test (yyinput: string) (result: int option) =\n    let st = {yyinput = yyinput; yycursor = 0; yymarker = 0} in\n    if not (parse st = result) then raise (Failure \"error\")\n\nlet main () =\n    test \"\\x00\" None;\n    test \"1234567890\\x00\" (Some 1234567890);\n    test \"0b1101\\x00\" (Some 13);\n    test \"0x7Fe\\x00\" (Some 2046);\n    test \"0644\\x00\" (Some 420);\n    test \"9999999999\\x00\" None\n\nlet _ = main ()\n",
      "extraCommandLineArguments": "-i "
    },
    "state/push.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT -fi *)\n\nopen Bytes\n\n(* Use a small buffer to cover the case when a lexeme doesn't fit.\n   In real world use a larger buffer. *)\nlet bufsize = 10\n\nlet debug = false\nlet log format = (if debug then Printf.eprintf else Printf.ifprintf stderr) format\n\ntype state = {\n    file: in_channel;\n    yyinput: bytes;\n    mutable yycursor: int;\n    mutable yymarker: int;\n    mutable yylimit: int;\n    mutable token: int;\n    mutable yystate: int;\n    mutable recv: int;\n}\n\ntype status = End | Ready | Waiting | BadPacket | BigPacket\n\nlet fill(st: state) : status =\n    (* Error: lexeme too long. In real life could reallocate a larger buffer. *)\n    if st.token < 1 then BigPacket else (\n\n    (* Shift buffer contents (discard everything up to the current token). *)\n    blit st.yyinput st.token st.yyinput 0 (st.yylimit - st.token);\n    st.yycursor <- st.yycursor - st.token;\n    st.yymarker <- st.yymarker - st.token;\n    st.yylimit <- st.yylimit - st.token;\n    st.token <- 0;\n\n    (* Fill free space at the end of buffer with new data from file. *)\n    let n = In_channel.input st.file st.yyinput st.yylimit (bufsize - st.yylimit - 1) in\n    st.yylimit <- st.yylimit + n;\n    set st.yyinput st.yylimit '\\x00'; (* append sentinel *)\n\n    Ready)\n\n%{\n    re2c:YYFN = [\"lex;status\", \"yyrecord;state\"];\n    re2c:YYFILL = \"Waiting\";\n    re2c:eof = 0;\n\n    packet = [a-z]+[;];\n\n    *      { BadPacket }\n    $      { End }\n    packet { yyrecord.recv <- yyrecord.recv + 1; lex_loop yyrecord }\n%}\n\nand lex_loop st =\n    st.token <- st.yycursor;\n    lex st\n\nlet test (packets: string list) (sts: status) =\n    let fname = \"pipe\" in\n\n    let oc = Out_channel.open_bin fname in\n    let ic = In_channel.open_bin fname in\n\n    let yylimit = bufsize - 1 in\n    let st = {\n        file = ic;\n        (* Sentinel (at `yylimit` offset) is set to null, which triggers YYFILL. *)\n        yyinput = create bufsize;\n        yycursor = yylimit;\n        yymarker = yylimit;\n        yylimit = yylimit;\n        token = yylimit;\n        yystate = -1;\n        recv = 0;\n    } in\n\n    let rec loop packets = match lex_loop st with\n        | End ->\n            log \"done: got %d packets\\n\" st.recv;\n            End\n        | Waiting ->\n            log \"waiting...\\n\";\n            let packets' = match packets with\n                | [] -> []\n                | p :: ps ->\n                    log \"sent packet '%s'\\n\" p;\n                    Out_channel.output_string oc p;\n                    Out_channel.flush oc; (* without `flush` write happens too late *)\n                    ps\n            in (match fill st with\n                | BigPacket ->\n                    log \"error: packet too big\\n\";\n                    BigPacket\n                | Ready -> loop packets'\n                | _ -> raise (Failure \"unexpected status after fill\"))\n        | BadPacket ->\n            log \"error: ill-formed packet\\n\";\n            BadPacket\n        | _ -> raise (Failure \"unexpected status\")\n\n    in if not (loop packets = sts) then\n        raise (Failure \"error\");\n\n    In_channel.close ic;\n    Out_channel.close oc;\n    Sys.remove fname\n\nlet main () =\n    test [] End;\n    test [\"zero;\"; \"one;\"; \"two;\"; \"three;\"; \"four;\"] End;\n    test [\"zer0;\"] BadPacket;\n    test [\"goooooooooogle;\"] BigPacket\n\nlet _ = main ()\n",
      "extraCommandLineArguments": "-fi "
    },
    "submatch/02_mtags.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT *)\n\nopen String\n\ntype state = {\n    yyinput: string;\n    mutable yycursor: int;\n    mutable yymarker: int;\n    (* Final tag variables available in semantic action. *)\n    %{svars format = \"\\n\\tmutable @@{tag}: int;\"; %}\n    %{mvars format = \"\\n\\tmutable @@{tag}: int list;\"; %}\n    (* Intermediate tag variables used by the lexer (must be autogenerated). *)\n    %{stags format = \"\\n\\tmutable @@{tag}: int;\"; %}\n    %{mtags format = \"\\n\\tmutable @@{tag}: int list;\"; %}\n}\n\nlet s2n (str: string) (i1: int) (i2: int) : int =\n    let rec f s i j n =\n        if i >= j then n else f s (i + 1) j (n * 10 + Char.code s.[i] - 48)\n    in f str i1 i2 0\n\n%{local\n    re2c:YYFN = [\"parse;(int list) option\", \"st;state\"];\n    re2c:YYMTAGP = \"@@ <- st.yycursor :: @@;\";\n    re2c:YYMTAGN = \"\"; // alternatively could add `-1` to the list\n    re2c:yyrecord = \"st\";\n    re2c:tags = 1;\n    re2c:yyfill:enable = 0;\n\n    num = [0-9]+;\n\n    @t1 num @t2 (\".\" #t3 num #t4)* [\\x00] {\n        let x = s2n st.yyinput st.t1 st.t2 in\n        let xs = List.rev (List.map2 (fun x y -> s2n st.yyinput x y) st.t3 st.t4) in\n        Some (x :: xs)\n    }\n    * { None }\n%}\n\nlet test (str: string) (result: (int list) option) =\n    let st = {\n        yyinput = str;\n        yycursor = 0;\n        yymarker = 0;\n        %{svars format = \"\\n\\t\\t@@{tag} = -1;\"; %}\n        %{mvars format = \"\\n\\t\\t@@{tag} = [];\"; %}\n        %{stags format = \"\\n\\t\\t@@{tag} = -1;\"; %}\n        %{mtags format = \"\\n\\t\\t@@{tag} = [];\"; %}\n    }\n    in if not (parse st = result) then raise (Failure \"error\")\n\nlet main () =\n    test \"1\\x00\" (Some [1]);\n    test \"1.2.3.4.5.6.7\\x00\" (Some [1; 2; 3; 4; 5; 6; 7;]);\n    test \"1.2.\\x00\" None\n\nlet _ = main ()\n",
      "extraCommandLineArguments": ""
    },
    "submatch/04_posix_captures.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT *)\n\nopen String\n\n(* Maximum number of capturing groups among all rules. *)\n%{maxnmatch %}\n\ntype state = {\n    yyinput: string;\n    mutable yycursor: int;\n    mutable yymarker: int;\n    mutable yynmatch: int; (* number of capturing groups *)\n    mutable yypmatch: int array; (* memory for capturing parentheses *)\n    (* Intermediate tag variables used by the lexer (must be autogenerated). *)\n    %{stags format = \"\\n\\tmutable @@{tag}: int;\"; %}\n}\n\ntype semver = {\n    major: int;\n    minor: int;\n    patch: int;\n}\n\nlet s2n (str: string) (i1: int) (i2: int) : int =\n    let rec f s i j n =\n        if i >= j then n else f s (i + 1) j (n * 10 + Char.code s.[i] - 48)\n    in f str i1 i2 0\n\n%{local\n    re2c:YYFN = [\"parse;semver option\", \"st;state\"];\n    re2c:yyrecord = \"st\";\n    re2c:posix-captures = 1;\n    re2c:yyfill:enable = 0;\n\n    num = [0-9]+;\n\n    (num) \".\" (num) (\".\" num)? [\\x00] {\n        (* Even `yypmatch` values are for opening parentheses, odd values\n           are for closing parentheses, the first group is the whole match. *)\n        Some {\n            major = s2n st.yyinput st.yypmatch.(2) st.yypmatch.(3);\n            minor = s2n st.yyinput st.yypmatch.(4) st.yypmatch.(5);\n            patch = if st.yypmatch.(6) = -1 then 0\n                else s2n st.yyinput (st.yypmatch.(6) + 1) st.yypmatch.(7)\n        }\n    }\n    * { None }\n%}\n\nlet test (str: string) (result: semver option) =\n    let st = {\n        yyinput = str;\n        yycursor = 0;\n        yymarker = 0;\n        yynmatch = 0;\n        yypmatch = Array.make (2 * yymaxnmatch) (-1);\n        %{stags format = \"\\n\\t\\t@@{tag} = -1;\"; %}\n    }\n    in if not (parse st = result) then raise (Failure \"error\")\n\nlet main () =\n    test \"23.34\\x00\" (Some {major = 23; minor = 34; patch = 0});\n    test \"1.2.99999\\x00\" (Some {major = 1; minor = 2; patch = 99999});\n    test \"1.a\\x00\" None\n\nlet _ = main ()\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT *)\n\nopen String\n\ntype state = {\n    yyinput: string;\n    mutable yycursor: int;\n    mutable yymarker: int;\n    (* Final tag variables available in semantic action. *)\n    %{svars format = \"\\n\\tmutable @@{tag}: int;\"; %}\n    (* Intermediate tag variables used by the lexer (must be autogenerated). *)\n    %{stags format = \"\\n\\tmutable @@{tag}: int;\"; %}\n}\n\ntype semver = {\n    major: int;\n    minor: int;\n    patch: int;\n}\n\nlet s2n (str: string) (i1: int) (i2: int) : int =\n    let rec f s i j n =\n        if i >= j then n else f s (i + 1) j (n * 10 + Char.code s.[i] - 48)\n    in f str i1 i2 0\n\n%{local\n    re2c:YYFN = [\"parse;semver option\", \"st;state\"];\n    re2c:yyrecord = \"st\";\n    re2c:tags = 1;\n    re2c:yyfill:enable = 0;\n\n    num = [0-9]+;\n\n    @t1 num @t2 \".\" @t3 num @t4 (\".\" @t5 num)? [\\x00] {\n        Some {\n            major = s2n st.yyinput st.t1 st.t2;\n            minor = s2n st.yyinput st.t3 st.t4;\n            patch = if st.t5 = -1 then 0 else s2n st.yyinput st.t5 (st.yycursor - 1)\n        }\n    }\n    * { None }\n%}\n\nlet test (str: string) (result: semver option) =\n    let st = {\n        yyinput = str;\n        yycursor = 0;\n        yymarker = 0;\n        %{svars format = \"\\n\\t\\t@@{tag} = -1;\"; %}\n        %{stags format = \"\\n\\t\\t@@{tag} = -1;\"; %}\n    }\n    in if not (parse st = result) then raise (Failure \"error\")\n\nlet main () =\n    test \"23.34\\x00\" (Some {major = 23; minor = 34; patch = 0});\n    test \"1.2.99999\\x00\" (Some {major = 1; minor = 2; patch = 99999});\n    test \"1.a\\x00\" None\n\nlet _ = main ()\n",
      "extraCommandLineArguments": ""
    },
    "submatch/03_captures.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT *)\n\nopen String\n\ntype state = {\n    yyinput: string;\n    mutable yycursor: int;\n    mutable yymarker: int;\n    (* Final tag variables available in semantic action. *)\n    %{svars format = \"\\n\\tmutable @@{tag}: int;\"; %}\n    (* Intermediate tag variables used by the lexer (must be autogenerated). *)\n    %{stags format = \"\\n\\tmutable @@{tag}: int;\"; %}\n}\n\ntype semver = {\n    major: int;\n    minor: int;\n    patch: int;\n}\n\nlet s2n (str: string) (i1: int) (i2: int) : int =\n    let rec f s i j n =\n        if i >= j then n else f s (i + 1) j (n * 10 + Char.code s.[i] - 48)\n    in f str i1 i2 0\n\n%{local\n    re2c:YYFN = [\"parse;semver option\", \"st;state\"];\n    re2c:yyrecord = \"st\";\n    re2c:captvars = 1;\n    re2c:yyfill:enable = 0;\n\n    num = [0-9]+;\n\n    (num) \".\" (num) (\".\" num)? [\\x00] {\n        Some {\n            major = s2n st.yyinput st.yytl1 st.yytr1;\n            minor = s2n st.yyinput st.yytl2 st.yytr2;\n            patch = if st.yytl3 = -1 then 0 else s2n st.yyinput (st.yytl3 + 1) st.yytr3\n        }\n    }\n    * { None }\n%}\n\nlet test (str: string) (result: semver option) =\n    let st = {\n        yyinput = str;\n        yycursor = 0;\n        yymarker = 0;\n        %{svars format = \"\\n\\t\\t@@{tag} = -1;\"; %}\n        %{stags format = \"\\n\\t\\t@@{tag} = -1;\"; %}\n    }\n    in if not (parse st = result) then raise (Failure \"error\")\n\nlet main () =\n    test \"23.34\\x00\" (Some {major = 23; minor = 34; patch = 0});\n    test \"1.2.99999\\x00\" (Some {major = 1; minor = 2; patch = 99999});\n    test \"1.a\\x00\" None\n\nlet _ = main ()\n",
      "extraCommandLineArguments": ""
    },
    "submatch/01_stags_fill.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT *)\n\nopen Bytes\n\nlet bufsize = 4096\n\ntype state = {\n    file: in_channel;\n    yyinput: bytes;\n    mutable yycursor: int;\n    mutable yymarker: int;\n    mutable yylimit: int;\n    mutable token: int;\n    mutable eof: bool;\n    (* Final tag variables available in semantic action. *)\n    %{svars format = \"\\n\\tmutable @@{tag}: int;\"; %}\n    (* Intermediate tag variables used by the lexer (must be autogenerated). *)\n    %{stags format = \"\\n\\tmutable @@{tag}: int;\"; %}\n}\n\ntype status = Ok | Eof | LongLexeme\n\ntype semver = {\n    major: int;\n    minor: int;\n    patch: int;\n}\n\nlet s2n (str: bytes) (i1: int) (i2: int) : int =\n    let rec f s i j n =\n        if i >= j then n else f s (i + 1) j (n * 10 + Char.code (get s i) - 48)\n    in f str i1 i2 0\n\nlet fill(st: state) : status =\n    if st.eof then Eof else\n\n    (* Error: lexeme too long. In real life could reallocate a larger buffer. *)\n    if st.token < 1 then LongLexeme else (\n\n    (* Shift buffer contents (discard everything up to the current token). *)\n    blit st.yyinput st.token st.yyinput 0 (st.yylimit - st.token);\n    st.yycursor <- st.yycursor - st.token;\n    st.yymarker <- st.yymarker - st.token;\n    st.yylimit <- st.yylimit - st.token;\n    %{stags format = \"\\n\\tst.@@ <- if st.@@ = -1 then -1 else st.@@ - st.token;\"; %}\n    st.token <- 0;\n\n    (* Fill free space at the end of buffer with new data from file. *)\n    let n = input st.file st.yyinput st.yylimit (bufsize - st.yylimit - 1) in (* -1 for sentinel *)\n    st.yylimit <- st.yylimit + n;\n    if n = 0 then\n        st.eof <- true; (* end of file *)\n        set st.yyinput st.yylimit '\\x00'; (* append sentinel *)\n\n    Ok)\n\n%{\n    re2c:YYFN = [\"lex;(semver list) option\", \"st;state\", \"vers;semver list\"];\n    re2c:YYFILL = \"fill st = Ok\";\n    re2c:yyrecord = \"st\";\n    re2c:tags = 1;\n    re2c:eof = 0;\n\n    num = [0-9]+;\n\n    @t1 num @t2 \".\" @t3 num @t4 (\".\" @t5 num)? [\\n] {\n        let ver = {\n            major = s2n st.yyinput st.t1 st.t2;\n            minor = s2n st.yyinput st.t3 st.t4;\n            patch = if st.t5 = -1 then 0 else s2n st.yyinput st.t5 (st.yycursor - 1)\n        } in lex_loop st (ver :: vers)\n    }\n    $ { Some (List.rev vers) }\n    * { None }\n%}\n\nand lex_loop st vers =\n    st.token <- st.yycursor;\n    lex st vers\n\nlet main () =\n    let fname = \"input\" in\n\n    (* Prepare input file. *)\n    Out_channel.with_open_bin fname\n        (fun oc -> for i = 1 to bufsize do\n            output_string oc \"1.22.333\\n\"\n        done);\n\n    (* Construct the expected result to compare against. *)\n    let expect = Some (List.init bufsize\n            (fun _ -> {major = 1; minor = 22; patch = 333;})) in\n\n    (* Run lexer on the prepared file. *)\n    In_channel.with_open_bin fname\n        (fun ic ->\n            let yylimit = bufsize - 1 in\n            let st = {\n                file = ic;\n                yyinput = create bufsize;\n                yycursor = yylimit;\n                yymarker = yylimit;\n                yylimit = yylimit;\n                token = yylimit;\n                eof = false;\n                %{svars format = \"\\n\\t\\t@@{tag} = -1;\"; %}\n                %{stags format = \"\\n\\t\\t@@{tag} = -1;\"; %}\n            } in if (lex_loop st [] <> expect) then\n                raise (Failure \"error\"));\n\n    (* Cleanup. *)\n    Sys.remove fname\n\nlet _ = main ()\n",
      "extraCommandLineArguments": ""
    },
    "eof/03_eof_rule.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT *)\n\nopen String\n\ntype state = {\n    yyinput: string;\n    mutable yycursor: int;\n    mutable yymarker: int;\n    yylimit: int;\n}\n\n(* expect a null-terminated string *)\n%{\n    re2c:YYFN = [\"lex;int\", \"yyrecord;state\", \"count;int\"];\n    re2c:yyfill:enable = 0;\n    re2c:eof = 0;\n\n    str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n    *    { -1 }\n    $    { count }\n    str  { lex yyrecord (count + 1) }\n    [ ]+ { lex yyrecord count }\n%}\n\nlet test(str, count) =\n    let st = {\n        yyinput = str;\n        yycursor = 0;\n        yymarker = 0;\n        yylimit = length str - 1; (* terminating null not included *)\n    }\n    in if not (lex st 0 = count) then raise (Failure \"error\")\n\nlet main () =\n    test(\"\\x00\", 0);\n    test(\"'qu\\x00tes' 'are' 'fine: \\\\'' \\x00\", 3);\n    test(\"'unterminated\\\\'\\x00\", -1)\n\nlet _ = main ()\n",
      "extraCommandLineArguments": ""
    },
    "eof/04_fake_sentinel.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT *)\n\ntype state = {\n    str: string;\n    mutable cur: int;\n    lim: int;\n}\n\n(* expect a string without terminating null *)\n%{\n    re2c:api = generic;\n    re2c:YYFN = [\"lex;int\", \"st;state\", \"count;int\"];\n    re2c:YYPEEK = \"if st.cur < st.lim then st.str.[st.cur] else '\\\\x00'\";\n    re2c:YYSKIP = \"st.cur <- st.cur + 1;\";\n    re2c:yyfill:enable = 0;\n\n    *      { -1 }\n    [\\x00] { count }\n    [a-z]+ { lex st (count + 1) }\n    [ ]+   { lex st count }\n%}\n\nlet test(str, count) =\n    let st = {str = str; cur = 0; lim = String.length str}\n    in if not (lex st 0 = count) then raise (Failure \"error\")\n\nlet main () =\n    test(\"\", 0);\n    test(\"one two three\", 3);\n    test(\"f0ur\", -1)\n\nlet _ = main ()\n",
      "extraCommandLineArguments": ""
    },
    "eof/02_bounds_checking.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT *)\n\nopen String\n\nexception Fill\n\ntype state = {\n    yyinput: string;\n    mutable yycursor: int;\n    yylimit: int;\n}\n\n%{max %}\n%{\n    re2c:YYFN = [\"lex;int\", \"yyrecord;state\", \"count;int\"];\n    re2c:YYFILL = \"raise Fill;\";\n\n    str = ['] ([^'\\\\] | [\\\\][^])* ['];\n\n    [\\x00] {\n        (* check that it is the sentinel, not some unexpected null *)\n        if yyrecord.yycursor = length yyrecord.yyinput - yymaxfill + 1 then count else -1\n    }\n    str  { lex yyrecord (count + 1) }\n    [ ]+ { lex yyrecord count }\n    *    { -1 }\n%}\n\nlet test(str, count) =\n    let buf = cat str (make yymaxfill '\\x00') in\n    let st = {yyinput = buf; yycursor = 0; yylimit = length buf} in\n    let result = try lex st 0 with Fill -> -1 in\n    if not (result = count) then raise (Failure \"error\")\n\nlet main () =\n    test(\"\", 0);\n    test(\"'unterminated\\\\'\", -1);\n    test(\"'qu\\x00tes' 'are' 'fine: \\\\'' \", 3);\n    test(\"'unexpected \\x00 null\", -1)\n\nlet _ = main ()\n",
      "extraCommandLineArguments": ""
    },
    "eof/01_sentinel.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT *)\n\nopen String\n\ntype state = {\n    yyinput: string;\n    mutable yycursor: int;\n}\n\n(* expect a null-terminated string *)\n%{\n    re2c:YYFN = [\"lex;int\", \"yyrecord;state\", \"count;int\"];\n    re2c:yyfill:enable = 0;\n\n    *      { -1 }\n    [\\x00] { count }\n    [a-z]+ { lex yyrecord (count + 1) }\n    [ ]+   { lex yyrecord count }\n%}\n\nlet test(yyinput, count) =\n    let st = {yyinput = yyinput; yycursor = 0}\n    in if not (lex st 0 = count) then raise (Failure \"error\")\n\nlet main () =\n    test(\"\\x00\", 0);\n    test(\"one two three\\x00\", 3);\n    test(\"f0ur\\x00\", -1)\n\nlet _ = main ()\n",
      "extraCommandLineArguments": ""
    },
    "includes/include.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT -i *)\n\nopen String\n\n%{include \"definitions.ml\" %}\n\ntype state = {\n    yyinput: string;\n    mutable yycursor: int;\n    mutable yymarker: int;\n    mutable yyaccept: int;\n}\n\n%{\n    re2c:YYFN = [\"lex;number\", \"yyrecord;state\"];\n    re2c:yyfill:enable = 0;\n\n    *      { NaN }\n    number { Int }\n    !include \"extra_rules.re.inc\";\n%}\n\nlet test(str, num) =\n    let st = {yyinput = str; yycursor = 0; yymarker = 0; yyaccept = 0}\n    in if not (lex st = num) then raise (Failure \"error\")\n\nlet main () =\n    test(\"123\\x00\", Int);\n    test(\"123.4567\\x00\", Float)\n\nlet _ = main ()\n",
      "extraCommandLineArguments": "-i "
    },
    "encodings/unicode_identifier.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT --utf8 -i *)\n\nopen String\n\n%{include \"unicode_categories.re\" %}\n\ntype state = {\n    yyinput: string;\n    mutable yycursor: int;\n    mutable yymarker: int;\n    mutable yyaccept: int;\n}\n\n%{\n    re2c:YYFN = [\"lex;bool\", \"yyrecord;state\"];\n    re2c:yyfill:enable = 0;\n\n    // Simplified \"Unicode Identifier and Pattern Syntax\"\n    // (see https://unicode.org/reports/tr31)\n    id_start    = L | Nl | [$_];\n    id_continue = id_start | Mn | Mc | Nd | Pc | [\\u200D\\u05F3];\n    identifier  = id_start id_continue*;\n\n    identifier { true }\n    *          { false }\n%}\n\nlet main () =\n    let st = {\n        yyinput = \"_\u042b\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\\x00\";\n        yycursor = 0;\n        yymarker = 0;\n        yyaccept = 0;\n    }\n    in if not (lex st) then raise (Failure \"error\")\n\nlet _ = main ()\n",
      "extraCommandLineArguments": "--utf8 -i "
    },
    "reuse/reuse.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT --input-encoding utf8 *)\n(* This example supports multiple input encodings: UTF-8 and UTF-32.\n   Both lexers are generated from the same rules block, and the use\n   blocks add only encoding-specific configurations. *)\n\nopen Array\n\ntype 'a state = {\n    yyinput: 'a array;\n    mutable yycursor: int;\n    mutable yymarker: int;\n}\n\n%{rules\n    re2c:yyfill:enable = 0;\n\n    \"\u2200x \u2203y\" { Some yyrecord.yycursor }\n    *       { None }\n%}\n\n%{use\n    re2c:YYFN = [\"lex8;int option\", \"yyrecord;char state\"];\n    re2c:encoding:utf8 = 1;\n%}\n\n%{use\n    re2c:YYFN = [\"lex32;int option\", \"yyrecord;int state\"];\n    re2c:encoding:utf32 = 1;\n%}\n\nlet main() =\n    let st8 = {\n        yyinput = [|'\\xe2'; '\\x08'; '\\x80'; '\\x78'; '\\x20'; '\\xe2'; '\\x88'; '\\x83'; '\\x79'|];\n        yycursor = 0;\n        yymarker = 0;\n    } in if not (lex8 st8 = Some (Array.length st8.yyinput)) then raise (Failure \"error\");\n\n    let st32 = {\n        yycursor = 0;\n        yymarker = 0;\n        yyinput = [|0x2200; 0x78; 0x20; 0x2203; 0x79|];\n    } in if not (lex32 st32 = Some (Array.length st32.yyinput)) then raise (Failure \"error\");\n",
      "extraCommandLineArguments": "--input-encoding utf8 "
    },
    "reuse/usedir.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT *)\n(* This example shows how to combine reusable re2c blocks: two blocks\n   ('colors' and 'fish') are merged into one. The 'salmon' rule occurs\n   in both blocks; the 'fish' block takes priority because it is used\n   earlier. Default rule * occurs in all three blocks; the local (not\n   inherited) definition takes priority. *)\n\nopen String\n\ntype answer = Color | Fish | Dunno\n\ntype state = {\n    yyinput: string;\n    mutable yycursor: int;\n    mutable yymarker: int;\n}\n\n%{rules:colors\n    *                            { raise (Failure \"ah\"); }\n    \"red\" | \"salmon\" | \"magenta\" { Color }\n%}\n\n%{rules:fish\n    *                            { raise (Failure \"oh\"); }\n    \"haddock\" | \"salmon\" | \"eel\" { Fish }\n%}\n\n%{\n    re2c:YYFN = [\"lex;answer\", \"yyrecord;state\"];\n    re2c:yyfill:enable = 0;\n\n    !use:fish;\n    !use:colors;\n    * { Dunno } // overrides inherited '*' rules\n%}\n\nlet test(str, ans) =\n    let st = {yyinput = str; yycursor = 0; yymarker = 0}\n    in if not (lex st = ans) then raise (Failure \"error\")\n\nlet main () =\n    test(\"salmon\", Fish);\n    test(\"what?\", Dunno)\n\nlet _ = main ()\n",
      "extraCommandLineArguments": ""
    },
    "headers/header.re": {
      "content": "(* re2ocaml $INPUT -o $OUTPUT --header lexer/state.ml -i *)\n\nopen State\nopen String\n\n%{header:on %}\ntype state = {\n    yyinput: string;\n    mutable yycursor: int;\n    mutable tag: int;\n    %{stags format = \"mutable @@: int;\"; %}\n}\n%{header:off %}\n\n%{\n    re2c:YYFN = [\"lex;int\", \"yyrecord;State.state\"];\n    re2c:tags = 1;\n    re2c:yyfill:enable = 0;\n    re2c:header = \"lexer/state.ml\";\n\n    [a]* @tag [b]* { yyrecord.tag }\n%}\n\nlet main () =\n    let st = {\n        yyinput = \"ab\\x00\";\n        yycursor = 0;\n        tag = 0;\n        %{stags format = \"\\n\\t@@ = 0;\"; %}\n    }\n    in if not (lex st = 1) then raise (Failure \"error\")\n\nlet _ = main ()\n",
      "extraCommandLineArguments": "--header lexer/state.ml -i "
    }
  }
}